<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Lukan&#39;s Blog</title>
  
  <subtitle>记录点滴成长</subtitle>
  <link href="https://lukan217.github.io/atom.xml" rel="self"/>
  
  <link href="https://lukan217.github.io/"/>
  <updated>2023-05-28T12:46:00.167Z</updated>
  <id>https://lukan217.github.io/</id>
  
  <author>
    <name>Lukan</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Bert文本分类提分trick大全</title>
    <link href="https://lukan217.github.io/2023/05/28/Bert%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E6%8F%90%E5%88%86trick%E5%A4%A7%E5%85%A8/"/>
    <id>https://lukan217.github.io/2023/05/28/Bert%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E6%8F%90%E5%88%86trick%E5%A4%A7%E5%85%A8/</id>
    <published>2023-05-28T12:43:58.158Z</published>
    <updated>2023-05-28T12:46:00.167Z</updated>
    
    <content type="html"><![CDATA[<p>作为一个0基础的小白，在过去的一年我也参加了若干场nlp相关的比赛，期间也学习了很多的trick，这些trick其实都有很多单独的文章介绍了，这里的话我主要做一个整合工作，结合自己比赛时的使用经验分享给大家，希望能够对大家的比赛或工作能够有帮助，这些trick并不局限于文本分类任务，对于一些更广泛的nlp场景，或者多模态和cv任务有的也都能够有不错的效果。</p><h1 id="模型选型">模型选型</h1><p>如今huggingface上已经挂载了各式各样的bert，在做自己的任务的时候，选择哪个bert作为自己模型的backbone是非常重要的，因为这些bert它本身预训练的训练语料是多种多样的，可能和自己所需要做的任务天差地别，因此在做自己的文本分类任务的时候，首先一个就需要了解自己所做的任务是哪个领域的？是金融的、电商的还是UGC内容、新闻等等，然后还要了解自己的文本是中文、英文或者多语言，根据这些信息来选择合适的bert：</p><ol type="1"><li>如果是中文文本，可以优先考虑哈工大开源的两个模型：hfl/chinese-roberta-wwm-ext以及hfl/chinese-macbert-base，这两个在中文上的效果都非常不错</li><li>如果是英文文本，可以直接考虑microsoft/deberta-v3-base，没啥好说的，kaggle最近的几个feedback比赛都是用的这个模型</li><li>如果是一些垂直领域的任务，可以去搜一下huggingface上有没有相关的模型，如金融领域的finbert等，由于是在垂直领域的语料上进行训练，和自己的任务较为相近，因此一般来说效果都会比通用性的要好一点</li></ol><p>另外，如果算力足够的话，可以考虑使用对应模型的large，一般来说也可以带来不错的收益。</p><h1 id="预训练">预训练</h1><p>bert是在大规模语料上进行预训练的，尽管这种预训练学习到了一些通用的能力，但是在自己的任务上表现还是差强人意，那么如何能够让bert更加适合自己的任务呢？答案就是领域内预训练，这里说的领域内预训练，就是在自己的训练集文本上执行预训练，训练结束后模型便更贴合自己的任务了，在训练的时候收敛速度加快，效果一般来说也能带来百分位点的提升，至于预训练的任务，那就分很多种了：</p><ol type="1"><li>mlm预训练</li></ol><p>也就是原生bert预训练两个任务（mlm与nsp）之一，一般也只做mlm，当然nsp任务在某些场景下可能也是有用的（个人还没试过），mlm任务做的就是完形填空，随机按照比例mask掉一些词，然后预测这个词可能是词表中某个词的概率，可以自己实现，不过如果单纯只做文本分类的话可以直接用huggingface提供的脚本：<a href="https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py">https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py</a><br />把这个脚本下载下来，然后准备好训练数据，写个训练脚本，就可以在本地得到预训练好的模型，直接引用即可。 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">export CUDA_VISIBLE_DEVICES=0</span><br><span class="line">NUM_GPU=1</span><br><span class="line">PORT_ID=$(expr $RANDOM + 1000)</span><br><span class="line">python -m torch.distributed.launch --nproc_per_node $NUM_GPU --master_port $PORT_ID  run_mlm.py \</span><br><span class="line">    --model_name_or_path hfl/chinese-roberta-wwm-ext \</span><br><span class="line">    --num_train_epochs 20 \</span><br><span class="line">    --train_file ./data/train_pretrain.txt \</span><br><span class="line">    --validation_file ./data/test_pretrain.txt \</span><br><span class="line">    --per_device_train_batch_size 32 \</span><br><span class="line">    --per_device_eval_batch_size 32 \</span><br><span class="line">    --do_train \</span><br><span class="line">    --do_eval \</span><br><span class="line">    --output_dir ./save/pretrain_model \</span><br><span class="line">    --line_by_line \</span><br><span class="line">    --eval_steps 500  \</span><br><span class="line">    --logging_steps 50 \</span><br><span class="line">    --evaluation_strategy steps \</span><br><span class="line">    --load_best_model_at_end \</span><br><span class="line">    --overwrite_output_dir \</span><br><span class="line">    --max_seq_length 512 \</span><br><span class="line">    --save_total_limit 0 \</span><br><span class="line">    &quot;$@&quot;</span><br></pre></td></tr></table></figure></p><ol start="2" type="1"><li>simcse预训练</li></ol><p>这个预训练任务使用对比学习的方式，将一个句子过两次bert，由于dropout的存在得到的两个向量不完全一致，可以作为正样本，然后batch内其他向量作为负样本，使用infoCSE损失进行训练，也见到比赛里面一些大佬用过，具体训练方式可以参考：<a href="https://github.com/princeton-nlp/SimCSE">https://github.com/princeton-nlp/SimCSE</a></p><ol start="3" type="1"><li>多模态预训练</li></ol><p>这个其实跟文本分类没啥关系了，主要是做多模态任务会将文本和图片/视频等其他模态的数据对齐，一般会用image text match，image text contrastive等损失，具体可以参考2022年微信大数据挑战赛的方案：<a href="https://zhuanlan.zhihu.com/p/567648297">2022微信大数据挑战赛Top方案总结</a>。</p><h1 id="对抗训练">对抗训练</h1><p>对抗训练，也算是nlp和cv里面一种比较常用的提高模型鲁棒性的方法了，所谓对抗，就必须要有攻击和防守，通过对模型不断进行攻击，模型在防守的同时便能够提升自己的抗噪能力，也就是提高泛化能力。传统上对模型的攻击方式一般是通过制造对抗样本进行攻击，比如nlp可以通过对句子的某个词进行随机插入删除替换，cv可以对图片进行旋转裁剪缩放等操作，对样本进行扰动，以这种数据增强的方式来使得模型的鲁棒性得到提高。<br />而这里我们要讲的对抗训练的方式是对输入的embedding进行攻击，这样的好处便是不用自己再人为制定策略来对数据进行增强，而可以在训练过程中让攻击和防守自然而然的发生，具体的做法是这样的：</p><ol type="1"><li>攻击：在输入的embedding上进行梯度上升，使得loss变大</li><li>防守：在参数上进行梯度下降，使得loss减少</li></ol><p>这一过程会贯穿每一个训练step，因此便使得对抗的过程自然而然的发生，模型也会训练的越来越强，而具体的做法就有很多种了，如FGM,PGD, 还有最近在kaggle上比较流行的AWP，这里只介绍FGM的实现，因为比较简单，实战里用FGM也就足够了，一般来说也能够带来一到两个百分位点的提升： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">class FGM():</span><br><span class="line">    def __init__(self, model):</span><br><span class="line">        self.model = model</span><br><span class="line">        self.backup = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    def attack(self, epsilon=1., emb_name=&#x27;emb.&#x27;):</span><br><span class="line">        # emb_name这个参数要换成你模型中embedding的参数名</span><br><span class="line">        for name, param in self.model.named_parameters():</span><br><span class="line">            if param.requires_grad and emb_name in name:</span><br><span class="line">                self.backup[name] = param.data.clone()</span><br><span class="line">                norm = torch.norm(param.grad)</span><br><span class="line">                if norm != 0 and not torch.isnan(norm):</span><br><span class="line">                    r_at = epsilon * param.grad / norm</span><br><span class="line">                    param.data.add_(r_at)</span><br><span class="line"></span><br><span class="line">    def restore(self, emb_name=&#x27;emb.&#x27;):</span><br><span class="line">        # emb_name这个参数要换成你模型中embedding的参数名</span><br><span class="line">        for name, param in self.model.named_parameters():</span><br><span class="line">            if param.requires_grad and emb_name in name: </span><br><span class="line">                assert name in self.backup</span><br><span class="line">                param.data = self.backup[name]</span><br><span class="line">        self.backup = &#123;&#125;</span><br><span class="line"># 初始化</span><br><span class="line">fgm = FGM(model)</span><br><span class="line">for batch_input, batch_label in data:</span><br><span class="line">    # 正常训练</span><br><span class="line">    loss = model(batch_input, batch_label)</span><br><span class="line">    loss.backward() # 反向传播，得到正常的grad</span><br><span class="line">    # 对抗训练</span><br><span class="line">    fgm.attack() # 在embedding上添加对抗扰动</span><br><span class="line">    loss_adv = model(batch_input, batch_label)</span><br><span class="line">    loss_adv.backward() # 反向传播，并在正常的grad基础上，累加对抗训练的梯度</span><br><span class="line">    fgm.restore() # 恢复embedding参数</span><br><span class="line">    # 梯度下降，更新参数</span><br><span class="line">    optimizer.step()</span><br><span class="line">    model.zero_grad()</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><h1 id="r-drop">R-DROP</h1><p>bert里面是加了dropout的，有隐藏层的dropout，也有attention的dropout，这些都会在微调时为模型带来一定的扰动，由于存在训练和预测时的不一致性，往往都会影响模型效果，因此就有论文想要通过给模型添加扰动，但是又使得这个扰动不那么大，这个就是R-Drop（Regularized Dropout for Neural Networks），论文的思想也很简单，就是把输入过两次神经网络，由于dropout的存在，最终输出的logits是不一样的，我们想要让他输出的logits更相似一点，就在损失函数里面再加一部分衡量两次输出logits相似度的kl散度：<br /><span class="math inline">\(\begin{aligned} \mathcal{L}^i=\mathcal{L}^i_{NLL}+\alpha\cdot\mathcal{L}^i_{KL}&amp; =-\log\mathcal{P}_1^w(y_i|x_i)-\log\mathcal{P}_2^w(y_i|x_i) \\ &amp;+\frac{\alpha}{2}[\mathcal{D}_{KL}(\mathcal{P}_1^w(y_i|x_i)||\mathcal{P}_2^w(y_i|x_i))+\mathcal{D}_{KL}(\mathcal{P}_2^w(y_i|x_i)||\mathcal{P}_1^w(y_i|x_i))], \end{aligned}\)</span><br /><img src="https://cdn.nlark.com/yuque/0/2023/png/764062/1685213138940-47e5bda5-44b6-40ae-a9a4-229a8c890392.png#averageHue=%23eae7e5&amp;clientId=u006289c1-9ad5-4&amp;from=paste&amp;height=328&amp;id=u861031ed&amp;originHeight=656&amp;originWidth=1485&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=147077&amp;status=done&amp;style=none&amp;taskId=ub05d2f68-6d62-49b0-9bab-739fad667a5&amp;title=&amp;width=742.5" alt="image.png" /><br />原文也提供了代码实现，不过由于要过两次bert，因此训练时长和显存占用也要变多。 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">model = TaskModel()</span><br><span class="line"></span><br><span class="line">def compute_kl_loss(self, p, q, pad_mask=None):</span><br><span class="line">    </span><br><span class="line">    p_loss = F.kl_div(F.log_softmax(p, dim=-1), F.softmax(q, dim=-1), reduction=&#x27;none&#x27;)</span><br><span class="line">    q_loss = F.kl_div(F.log_softmax(q, dim=-1), F.softmax(p, dim=-1), reduction=&#x27;none&#x27;)</span><br><span class="line">    </span><br><span class="line">    # pad_mask is for seq-level tasks</span><br><span class="line">    if pad_mask is not None:</span><br><span class="line">        p_loss.masked_fill_(pad_mask, 0.)</span><br><span class="line">        q_loss.masked_fill_(pad_mask, 0.)</span><br><span class="line"></span><br><span class="line">    # You can choose whether to use function &quot;sum&quot; and &quot;mean&quot; depending on your task</span><br><span class="line">    p_loss = p_loss.sum()</span><br><span class="line">    q_loss = q_loss.sum()</span><br><span class="line"></span><br><span class="line">    loss = (p_loss + q_loss) / 2</span><br><span class="line">    return loss</span><br><span class="line"></span><br><span class="line"># keep dropout and forward twice</span><br><span class="line">logits = model(x)</span><br><span class="line"></span><br><span class="line">logits2 = model(x)</span><br><span class="line"></span><br><span class="line"># cross entropy loss for classifier</span><br><span class="line">ce_loss = 0.5 * (cross_entropy_loss(logits, label) + cross_entropy_loss(logits2, label))</span><br><span class="line"></span><br><span class="line">kl_loss = compute_kl_loss(logits, logits2)</span><br><span class="line"></span><br><span class="line"># carefully choose hyper-parameters</span><br><span class="line">loss = ce_loss + α * kl_loss</span><br></pre></td></tr></table></figure></p><h1 id="multi-sample-dropout">Multi Sample Dropout</h1><p>R-Drop的实现虽然能够缓解DropOut带来的问题，但是要去改损失函数，并且可能还要调个合适的超参，Multi Sample Dropout就带来了一种相对优雅的实现方式，就是在输出层先多次dropout，再过线性层，然后把输出的logits和loss取平均，相比于R-Drop就不用去改损失函数加上KL散度了，而是直接暴力取平均<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/764062/1685216210275-18b35f2d-76cd-4425-8499-0e38d574c92c.png#averageHue=%23f8f6f6&amp;clientId=u006289c1-9ad5-4&amp;from=paste&amp;height=387&amp;id=u9f5ff9b4&amp;originHeight=774&amp;originWidth=1368&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=120083&amp;status=done&amp;style=none&amp;taskId=ud92ade1a-1997-419b-8345-75c26544f55&amp;title=&amp;width=684" alt="image.png" /><br />这里我提供一种只把logits取平均的做法（这里没有把loss取平均，嫌麻烦），可以直接替换成输出层，即插即用 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">class MultiSampleClassifier(nn.Module):</span><br><span class="line">    def __init__(self, input_dim, num_labels, dropout=0.2, num=5):</span><br><span class="line">        super(MultiSampleClassifier, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(input_dim, num_labels)</span><br><span class="line">        self.num = num</span><br><span class="line">        self.dropout_ops = nn.ModuleList([</span><br><span class="line">            nn.Dropout(dropout) for _ in range(num)</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        logits = None</span><br><span class="line">        for i, dropout_op in enumerate(self.dropout_ops):</span><br><span class="line">            if i == 0:</span><br><span class="line">                out = dropout_op(x)</span><br><span class="line">                logits = self.linear(out)</span><br><span class="line">            else:</span><br><span class="line">                temp_out = dropout_op(x)</span><br><span class="line">                temp_logits = self.linear(temp_out)</span><br><span class="line">                logits += temp_logits</span><br><span class="line">        # 相加还是取平均</span><br><span class="line">        # if self.args.ms_average:</span><br><span class="line">        logits = logits / self.num</span><br><span class="line">        return logits</span><br></pre></td></tr></table></figure></p><h1 id="去掉dropout">去掉DropOut</h1><p>前面提到的两种方法，无论是R-Drop还是Multi Sample Dropout，都是为了解决微调时DropOut训练和测试存在不一致的问题，这个问题我之前在一篇文章里面讲过，在回归问题会有比较大的偏差，最近我在分类问题中也观察到了这样的情况，怪不得这两种方法会那么流行。<br />回归问题的本质，先思考一下DropOut为什么在bert微调时有问题？我个人的猜测是DropOut虽然是一种缓解过拟合的方法，但是可能并不适合bert微调的场景，首先是因为网络层数比较深了，bert在每层上面都加了dropout，每一层都带有扰动的话，经过逐层放大，这样就会导致最终的输出非常不稳定，其次，bert因为是预训练过的，一般来说只需要用较小的学习率微调几轮很快便收敛了，而dropout可能更适合那种需要训练较多轮才能发挥它的作用，因此DropOut在bert文本分类场景下可能并不好用。<br />那么既然dropout会存在问题，为什么还需要用r-drop，Multi Sample Dropout这种花里胡哨的方法来缓解他呢？直接在训练时去掉不行吗？经过我最近一次实验的尝试，去掉dropout，确实也能够在分类问题上得到提升，不过这个结论有待进一步验证，目前去掉dropout给我带来的就是网络收敛更快了，而且效果上也好上一两个点，比r-drop和Multi Sample Dropout效果要更好，而具体实现方式就非常简单了，只需要两行代码，所以非常建议大家也去试下，看看这个结论是否可靠： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">self.config = AutoConfig.from_pretrained(args.bert_dir)</span><br><span class="line">self.config.hidden_dropout_prob = 0.</span><br><span class="line">self.config.attention_probs_dropout_prob = 0.</span><br><span class="line">self.bert = AutoModel.from_pretrained(args.bert_dir,config=self.config)</span><br></pre></td></tr></table></figure> 中间两行就是关键代码，直接把bert的dropout在训练时都关闭了</p><h1 id="学习率相关">学习率相关</h1><p>bert对学习率是非常敏感的，稍微大一点模型就训不起来了，一般学习率区间设置在1e-5~5e-5就可以了，这是全局的学习率设置，对所有层都一视同仁，然而由于bert是一个深层的在大规模语料上训练过的模型，因此，bert的底层其实已经学到了一些通用的能力，这部分学习率就不需要设置的那么高，而在bert顶层，这部分是task specific的，就需要设置比较大的学习率，因此便可以使用不同层不同学习率的方式，比如输出层用5e-5，而bert使用2e-5，也有一些比较花的设置，学习率逐层递减，不同层设置不同学习率，也可以带来一点点的提升。<br />除了学习率的设置，学习率的调度也可以带来一点提升，个人比较常用的调度器是CosineAnnealingWarmRestarts，因为学习率是周期变化的，就不需要太考虑一些超参数，比如要训练多少步这种，用起来比较方便，并且在大部分场景下都可以得到不错的效果：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/764062/1685264235675-5b5acfb9-7828-49b5-9d16-a39eba66afe1.png#averageHue=%23f9f9f9&amp;clientId=u006289c1-9ad5-4&amp;from=paste&amp;id=u6befcb62&amp;originHeight=360&amp;originWidth=720&amp;originalType=url&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=34917&amp;status=done&amp;style=none&amp;taskId=ub71960c9-1a20-4056-9180-ef398d4120d&amp;title=" alt="image.png" /></p><h1 id="长文本处理">长文本处理</h1><p>实践中经常要对一些篇章级的文本进行处理，但是大部分bert的输入最多只能支持512个字符，而篇章级的文本往往都是上千个字符，因此就需要一些手段来处理这种长文本输入，处理好了往往能够带来几个点的提升，具体的处理方法我可以分为三种吧：</p><ol type="1"><li>从文本中提取最关键的信息作为输入，既然bert只能限制512个字符，那么就从文本中挑选出512个来就好了，这个具体的处理方式就是task specific的了，一般来说，对于一个文章分类，你把他的标题、第一段内容、最后一段内容作为输入便可以得到比较好的效果，因为标题和首尾一般来说都会含有比较关键的信息，这个也是个人实践中提点最快的方法</li><li>选择可以处理长文本的模型，比如LongFormer，BigBird，deberta等，这些模型都可以突破512个字符的限制，不过说实话带来的提升较为有限，甚至是副作用，因为主流比较强的模型还是仅支持输入512个字符的模型</li><li>拆分句子多次过bert，思想很简单，既然只能处理512个字符，那么我就把句子拆开，0-512送进bert得到一个隐藏层向量，512-1024再送进bert得到另一个向量，依此类推，最后再pooling一下，不过这种方法的缺点是会损失位置编码的信息</li></ol><h1 id="pooling方式">Pooling方式</h1><p>前面说的长文本处理有一部分可以说是选择什么样的输入进入到bert编码器中，但是经过bert编码之后得到的输出是形状[batch_size,seq_len,hidden_size]，需要把seq_len这个维度去掉再接输出层，这时候面临的问题是选择一个什么样的输出接输出层，也就是我们说的Pooling池化，传统bert是直接把第一个位置，也就是[CLS]对应的向量作为输出，这样做其实很不好，尤其是在文本分类上，只用第一个位置字符的输出损失了相当多的信息，实践中用这种方式也会比其他方法低几个点，所以一般最好使用MeanPooling获取全局的语义信息，或者使用MaxPooling获取关键信息，最近我在一个任务上尝试了Attention Pooling，也就是为每个位置算一个Attention权重，然后对每个位置进行加权得到最后的输出，这种方式在我的任务上效果非常不错，收敛也很快，实现如下： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class AttentionPooling(nn.Module):</span><br><span class="line">    def __init__(self, in_dim):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.attention = nn.Sequential(</span><br><span class="line">        nn.Linear(in_dim, in_dim),</span><br><span class="line">        nn.LayerNorm(in_dim),</span><br><span class="line">        nn.GELU(),</span><br><span class="line">        nn.Linear(in_dim, 1),</span><br><span class="line">        )</span><br><span class="line">    def forward(self, last_hidden_state, attention_mask):</span><br><span class="line">        w = self.attention(last_hidden_state).float()</span><br><span class="line">        w[attention_mask==0]=float(&#x27;-inf&#x27;)</span><br><span class="line">        w = torch.softmax(w,1)</span><br><span class="line">        attention_embeddings = torch.sum(w * last_hidden_state, dim=1)</span><br><span class="line">        return attention_embeddings</span><br></pre></td></tr></table></figure></p><h1 id="ema">EMA</h1><p>Exponential Moving Average（指数移动平均），主要思想是对模型进行“自融合”，自己和自己融合的意思，融合方式是通过对模型不同训练step时的模型参数取加权平均，加权的权重如何设置呢？就是用指数移动平均的方式，对近期的参数取较高的权重，而对以前的权重取较低的权重，经过加权平均后，模型的参数更容易落在全局最优点，泛化性更高，具体实现如下，也是即插即用的，不过对于训练step比较少的场景，不一定能够带来提升，并且，最好不要在训练开始的时候就用ema，因为这样训练前期的收敛很慢，可以等快要收敛的时候才开始ema <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">class EMA():</span><br><span class="line">    def __init__(self, model, decay):</span><br><span class="line">        self.model = model</span><br><span class="line">        self.decay = decay</span><br><span class="line">        self.shadow = &#123;&#125;</span><br><span class="line">        self.backup = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    def register(self):</span><br><span class="line">        for name, param in self.model.named_parameters():</span><br><span class="line">            if param.requires_grad:</span><br><span class="line">                self.shadow[name] = param.data.clone()</span><br><span class="line"></span><br><span class="line">    def update(self):</span><br><span class="line">        for name, param in self.model.named_parameters():</span><br><span class="line">            if param.requires_grad:</span><br><span class="line">                assert name in self.shadow</span><br><span class="line">                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]</span><br><span class="line">                self.shadow[name] = new_average.clone()</span><br><span class="line"></span><br><span class="line">    def apply_shadow(self):</span><br><span class="line">        for name, param in self.model.named_parameters():</span><br><span class="line">            if param.requires_grad:</span><br><span class="line">                assert name in self.shadow</span><br><span class="line">                self.backup[name] = param.data</span><br><span class="line">                param.data = self.shadow[name]</span><br><span class="line"></span><br><span class="line">    def restore(self):</span><br><span class="line">        for name, param in self.model.named_parameters():</span><br><span class="line">            if param.requires_grad:</span><br><span class="line">                assert name in self.backup</span><br><span class="line">                param.data = self.backup[name]</span><br><span class="line">        self.backup = &#123;&#125;</span><br><span class="line"></span><br><span class="line"># 初始化</span><br><span class="line">ema = EMA(model, 0.999)</span><br><span class="line">ema.register()</span><br><span class="line"></span><br><span class="line"># 训练过程中，更新完参数后，同步update shadow weights</span><br><span class="line">def train():</span><br><span class="line">    optimizer.step()</span><br><span class="line">    ema.update()</span><br><span class="line"></span><br><span class="line"># eval前，apply shadow weights；eval之后，恢复原来模型的参数</span><br><span class="line">def evaluate():</span><br><span class="line">    ema.apply_shadow()</span><br><span class="line">    # evaluate</span><br><span class="line">    ema.restore()</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><h1 id="伪标签">伪标签</h1><p>伪标签在很多比赛的top方案上也出现过，好像最后也能提一两个点，需要模型能够具有较高的预测精度了再使用效果才比较好，主要思想也比较简单：</p><ol type="1"><li>在训练集上训练模型，并预测测试集的标签</li><li>取测试集中预测置信度较高的样本（如预测为1的概率大于0.95），加入到训练集中</li><li>使用新的训练集重新训练一个模型，并预测测试集的标签</li><li>重复执行2和3步骤若干次（一至两次即可）</li></ol><p>自己之前用过一次没效果，后面就没再用了，没啥成功的经验，下面贴一段chatgpt的实现： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"># 准备已标记和未标记的数据集</span><br><span class="line">labeled_dataset = ...  # 已标记数据集</span><br><span class="line">unlabeled_dataset = ...  # 未标记数据集</span><br><span class="line"></span><br><span class="line"># 创建数据加载器</span><br><span class="line">labeled_dataloader = DataLoader(labeled_dataset, batch_size=32, shuffle=True)</span><br><span class="line">unlabeled_dataloader = DataLoader(unlabeled_dataset, batch_size=32, shuffle=True)</span><br><span class="line"></span><br><span class="line"># 初始化模型</span><br><span class="line">model = MyModel()</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=0.001)</span><br><span class="line"></span><br><span class="line"># 初始训练，使用已标记数据</span><br><span class="line">model.train()</span><br><span class="line">for epoch in range(5):  # 初始训练若干轮</span><br><span class="line">    for inputs, labels in labeled_dataloader:</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line"># 使用伪标签进行训练</span><br><span class="line">model.train()</span><br><span class="line">for epoch in range(5):  # 使用伪标签训练若干轮</span><br><span class="line">    pseudo_labels = []</span><br><span class="line">    unlabeled_data = []</span><br><span class="line">    for inputs, _ in unlabeled_dataloader:</span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        pseudo_labels.extend(torch.argmax(outputs, dim=1).tolist())</span><br><span class="line">        unlabeled_data.append(inputs)</span><br><span class="line"></span><br><span class="line">    # 将伪标签与未标记数据合并，形成新的标记数据集</span><br><span class="line">    pseudo_labeled_dataset = torch.utils.data.TensorDataset(torch.cat(unlabeled_data, dim=0), torch.tensor(pseudo_labels))</span><br><span class="line">    pseudo_labeled_dataloader = DataLoader(pseudo_labeled_dataset, batch_size=32, shuffle=True)</span><br><span class="line"></span><br><span class="line">    for (inputs, labels), (pseudo_inputs, pseudo_labels) in zip(labeled_dataloader, pseudo_labeled_dataloader):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        labeled_outputs = model(inputs)</span><br><span class="line">        pseudo_labeled_outputs = model(pseudo_inputs)</span><br><span class="line">        labeled_loss = criterion(labeled_outputs, labels)</span><br><span class="line">        pseudo_labeled_loss = criterion(pseudo_labeled_outputs, pseudo_labels)</span><br><span class="line">        loss = labeled_loss + pseudo_labeled_loss</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br></pre></td></tr></table></figure></p><h1 id="模型融合">模型融合</h1><p>模型融合，算是比赛上分的最后手段了，具体可以有单模型融合和多模型融合：</p><ol type="1"><li>单模型融合：也就是五折交叉融合，同一个模型，在五折的数据上训练，然后将预测结果进行融合，由于每一折的数据都不太一样，所以给预测结果带来了一定的差异性，融合可以上一点点分</li><li>多模型融合：在不同的模型上进行训练，然后将预测结果再进行融合，这里需要注重模型的差异性要足够大，才能够带来足够的提升，具体做法可以是在模型选型上（roberta，roberta large，macbert等），pooling方式上（max/mean/attention pooling），文本输入上（不同阶段方式）等进行排列组合，最后top分数之间的差异很可能就是融合的模型数量的差异，因为基本的东西大家都做的差不多，最后就是拼算力，看谁能搞出足够多的模型来融合。</li></ol><p>具体到融合的手段，可以按照概率融合也可以按照投票融合，两者应该是没有显著的差异的，概率融合的话更方便为比较好的模型赋予更高的权重。</p><h1 id="参考">参考</h1><ol type="1"><li><a href="https://zhuanlan.zhihu.com/p/91269728">【炼丹技巧】功守道：NLP中的对抗训练 + PyTorch实现</a></li><li><a href="https://arxiv.org/abs/2106.14448">R-Drop: Regularized Dropout for Neural Networks</a></li><li><a href="https://arxiv.org/abs/1905.09788">Multi-Sample Dropout for Accelerated Training and Better Generalization</a></li><li><a href="https://zhuanlan.zhihu.com/p/68748778">【炼丹技巧】指数移动平均（EMA）的原理及PyTorch实现</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;作为一个0基础的小白，在过去的一年我也参加了若干场nlp相关的比赛，期间也学习了很多的trick，这些trick其实都有很多单独的文章介绍了，这里的话我主要做一个整合工作，结合自己比赛时的使用经验分享给大家，希望能够对大家的比赛或工作能够有帮助，这些trick并不局限于文本分类任务，对于一些更广泛的nlp场景，或者多模态和cv任务有的也都能够有不错的效果。&lt;/p&gt;</summary>
    
    
    
    <category term="深度学习" scheme="https://lukan217.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="自然语言处理" scheme="https://lukan217.github.io/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    <category term="深度学习" scheme="https://lukan217.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Transformer原理： Attention is All you need</title>
    <link href="https://lukan217.github.io/2023/05/03/Transformer%E5%8E%9F%E7%90%86%EF%BC%9A%20Attention%20is%20All%20you%20need/"/>
    <id>https://lukan217.github.io/2023/05/03/Transformer%E5%8E%9F%E7%90%86%EF%BC%9A%20Attention%20is%20All%20you%20need/</id>
    <published>2023-05-02T16:37:27.818Z</published>
    <updated>2023-05-02T16:41:20.455Z</updated>
    
    <content type="html"><![CDATA[<p>transformer自诞生以来，基本上在每个领域都取得了非常大的成功，如nlp领域的Bert、GPT，cv领域的ViT，swin transformer，推荐系统领域的autoint，behavior sequence transformer，还有时序里面的tft、informer，以及强化学习也搞了个Decision Transformer，而这些都源自于谷歌团队在2017年提出的这篇文章《Attention is All you Need》，本着阅读经典，顺便复习面经的精神，这次我们就来阅读transformer这篇论文，深入到每一个细节之中，确保对这个模型知根知底，当然，具体在写的时候不会严格按照原文来，而是按照我自己的想法来进行组织的。</p><h1 id="背景">背景</h1><p>在传统的序列建模任务（如语言模型，机器翻译）中，一般使用的模型架构都是循环神经网络（LSTM和GRU），并且都是一个encoder-decoder的架构。这种基于RNN的模型结构不管在输入或者输出一个序列的时候都是把当前隐状态<span class="math inline">\(h_t\)</span>建模成一个关于当前输入以及上一时刻隐状态的函数，即<span class="math inline">\(h_t = f(h_{t-1},X_t)\)</span>，这种自回归式的建模方法意味着他只能串行计算，而没办法并行处理，如果序列的长度很长的话，计算就会很慢，除了通过把batch_size增大来提高运算速度之外好像也没别的方法，并且这么做对于内存要求还比较高。由于在序列这个维度上只能进行串行计算，这也成了模型计算速度的瓶颈所在。<br />有一些工作想要突破RNN这个无法并行的问题，比如Extended Neural GPU，ByteNet，ConvS2S等，但是这些网络都是用CNN作为模型的一部分，因为CNN是可以实现并行计算的，但是在长序列问题上还是存在问题，CNN很难捕捉序列上两个离得很远的点的依赖关系。<br />注意力机制是可以实现并行的，而且他对于远距离的两个点的依赖关系建模的也比较好，也被运用在了nlp的各种任务中，但是更多的是和RNN进行结合使用，增强RNN的效果，起到锦上添花的作用，还是突破不了RNN的局限性。<br />因此，这篇文章提出的Transformer就是想要用一个纯粹的注意力机制来解决机器翻译问题，当然也是采用encoder-decoder的架构，不过encoder和decoder都是基于自注意力，这么做的优点有以下三个：</p><ol type="1"><li>长序列建模，可以捕捉长序列之间的依赖关系</li><li>可以并行计算, 在工业界应用比较友好</li><li>效果好，在一系列任务上吊打其他模型</li></ol><h1 id="模型结构">模型结构</h1><p>基本上所有的序列建模模型都是采用encoder-decoder的架构，encoder负责把输入的序列表征<span class="math inline">\((x_1,...,x_n)\)</span>编码成另一个序列<span class="math inline">\((z_1,...,z_n)\)</span>，然后decoder再把编码好的<span class="math inline">\((z_1,...,z_n)\)</span>解码成输出<span class="math inline">\((y_1,...,y_n)\)</span>, 但是编码器和解码器的具体实现方式不同，以RNN系列的模型举例，都是在每个时间步<span class="math inline">\(t\)</span>上都采用自回归的方式，把当前时间步的输入分为两个，一个是当前时间步的输入以及上一个时间步的hidden state，如对于编码器<span class="math inline">\(z_t = f_{encoder}(z_{t-1},x_t)\)</span>, 而对于解码器<span class="math inline">\(y_t = f_{decoder}(y_{t-1},z_t)\)</span>。<br />这里的transformer整体上也是采用同样的encoder-decoder架构，不过编码器和解码器的函数换成了纯注意力机制。来看一下他整体的架构，整体的结构还是encoder+decoder的方式，encoder接收来自一个句子的每个词embedding，为了表征每一个词的位置信息，先把句子的每个词的embedding加上一个位置编码（positional embedding），这是因为transformer的自注意力机制计算时不像RNN那样有先后顺序，对所有词向量都是一视同仁的，而decoder这边接收的则是要翻译的目标句子的词embedding，同样也加上位置编码，同时也接受来自encoder的输入，最后用softmax输出每一个位置上每个词元可能的概率。接下来再说一下encoder和decoder的一些细节。</p><figure><img src="https://cdn.nlark.com/yuque/0/2023/png/764062/1682947966354-94b238d6-2831-40e1-8261-d089d31f2ea9.png#averageHue=%23e8d8b1&amp;clientId=ucb8551b1-5e38-4&amp;from=paste&amp;height=665&amp;id=bSmYE&amp;originHeight=1329&amp;originWidth=973&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=158965&amp;status=done&amp;style=none&amp;taskId=u46468e17-f1e6-4414-9043-8d82622cb05&amp;title=&amp;width=486.5" alt="image.png" /><figcaption aria-hidden="true">image.png</figcaption></figure><h2 id="encoder">Encoder</h2><p>首先看encoder这边，encoder由6个相同的层组成，每个层都有两个子层，第一个子层是多头注意力层，第二个子层是一个基于位置的前馈神经网络层，这两个子层之间使用了残差连接和layer normalization，用公式来说明的话就是，对每个子层的输出做了这样一个操作：<br /><span class="math inline">\(LayerNorm(x+Sublayer(x))\\\)</span><br />这边的<span class="math inline">\(x\)</span>就是子层的输入，<span class="math inline">\(Sublayer(x)\)</span>就是子层的输出，把输入和输出加起来，就是一个残差连接，然后再使用LayerNorm对输出进行层归一化。</p><h2 id="decoder">Decoder</h2><p>再来看decoder这边，decoder同样由6个相同的层组成，每个层由三个子层组成，其中，两个子层和encoder的结构类似，多头注意力层和基于位置的前馈神经网络层，但是这个多头注意力层采用了mask的方式，这里的mask是指把当前词元之后的词元mask掉，不参与注意力的计算，这是因为对于翻译任务来说，训练时你能知道完整目标句子的输入，但是在预测时词元只能一个个生成，没办法看到后面的词，所以需要在训练时也把后面的词也给屏蔽掉。然后decoder在这两个子层之间又插入了一个子层，用来接收encoder的输入做注意力的计算，这个子层也是一个多头注意力层，细节之后展开。</p><h2 id="注意力机制">注意力机制</h2><p>首先说一下注意力机制的一些基本概念，注意力机制其实就是一个加权函数，要加权的东西，我们把它称为Value，既然是加权，权重如何计算呢？在注意力机制里面，我们一般是通过计算Query和Key的相似度得到的权重，每个Key和Value都是一一对应的，假设有n个key和value对，我们就可以通过一个query分别计算和key的相似度，得到n个相似度，这个就可以当作权重，然后乘到value里面，就可以得到加权后的输出。<br />这里的Query、Key、Value也就是注意力机制的三个要素，俗称QKV，<strong>一句话概括注意力机制就是使用Q和K计算相似度作为权重来对V进行加权</strong>，根据不同的相似度计算方法我们就有不同的注意力函数，transformer用的是缩放点积注意力。</p><h3 id="缩放点积注意力">缩放点积注意力</h3><p>衡量向量相似度的一个方式就是计算他们的点积，因此点积便可以作为一种注意力函数，transformer使用的缩放点积注意力公式如下：<br /><span class="math inline">\(\operatorname{Atention}(Q,K,V)=\operatorname{softmax}(\dfrac{QK^T}{\sqrt{d_k}})V\)</span><br />这里的Q和K和V都是一个矩阵，Q之所以是个矩阵是因为transformer中输出都是多个位置的，每个Query对应一个位置，所以直接用矩阵的方式计算便可以并行计算，加快效率，这也是transformer的优势所在。<br />对输出的相似度使用了softmax可以把每个query下的相似度归一化，加起来正好是1。<br />这里点积还进行了一个缩放操作，即除以<span class="math inline">\(\sqrt{d_k}\)</span>, 为什么要进行这样一个操作呢？具体来说，如果我们仅仅做点积操作，当向量的维度<span class="math inline">\(d_k\)</span>很大时，点积的结果也会变大。因为点积操作本身就是将两个向量的对应元素相乘后再求和，如果向量的维度增大，点积的结果会相应地增大。这会导致点积注意力计算softmax时，输入值过大可能会导致梯度消失问题。因为softmax函数的输出是一个概率分布，而其梯度在其输入值非常大或非常小的时候会变得非常小。这种情况下，在反向传播中梯度就会消失，影响模型的学习。为了避免这个问题，我们需要对点积的结果进行缩放，即除以<span class="math inline">\(\sqrt{d_{k}}\)</span>。这样做的主要目的是使得点积的结果的范围不会随着d_k的增大而变得过大，从而避免梯度消失的问题，使得模型能够更好地学习和优化。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/764062/1683021721901-d303b0e5-a809-4a92-ab0f-6ad41b23c984.png#averageHue=%23e8e8e7&amp;clientId=ucb8551b1-5e38-4&amp;from=paste&amp;height=260&amp;id=u101479f6&amp;originHeight=520&amp;originWidth=396&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=27728&amp;status=done&amp;style=none&amp;taskId=u1132fe2a-d878-4dd6-80c3-6cd48b056dd&amp;title=&amp;width=198" alt="image.png" /></p><h3 id="多头注意力">多头注意力</h3><p>在transformer中，为了进一步增强模型的表征能力，会使用多个注意力头，也就是多头注意力，来对整个序列进行加权，具体的做法是分别使用h个线性层把Q、K、V从原始的维度<span class="math inline">\(d_{model}\)</span>映射到<span class="math inline">\(d_k\)</span>，就能得到h个Q, K, V，然后分别计算h次attention，最后把这些拼接起来，过一个线性层再映射回原来的维度<span class="math inline">\(d_{model}\)</span>，如下图所示：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/764062/1683037323640-aa425494-682d-4127-a367-a1ecc87dd961.png#averageHue=%23faf9f9&amp;clientId=ucb8551b1-5e38-4&amp;from=paste&amp;height=177&amp;id=udd39dd4b&amp;originHeight=354&amp;originWidth=1651&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=84594&amp;status=done&amp;style=none&amp;taskId=ud449b069-d10a-4758-b0d0-a23aa0ec9bd&amp;title=&amp;width=825.5" alt="image.png" /><br /><img src="https://cdn.nlark.com/yuque/0/2023/png/764062/1683021827190-b7a9efc7-f27b-4748-b26c-18844199c7e5.png#averageHue=%23f1f1f0&amp;clientId=ucb8551b1-5e38-4&amp;from=paste&amp;height=332&amp;id=u8a8476ea&amp;originHeight=664&amp;originWidth=760&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=61201&amp;status=done&amp;style=none&amp;taskId=u960fc399-b110-4089-bcea-f30efd47dde&amp;title=&amp;width=380" alt="image.png" /><br />具体到论文里面的细节，transformer使用了8个注意力头，<span class="math inline">\(d_{model}\)</span>为512，<span class="math inline">\(d_k\)</span>设置为<span class="math inline">\(d_{model}/8=64\)</span>，虽然多头注意力多了一些权重矩阵，但是由于每个注意力头的维度只有64，并且是可以并行计算的，因此计算成本和不使用多头注意力是差不多的。而使用了多头注意力可以使得每个注意力头关注序列不同部分的信息，进而捕捉到不同的语义信息，比如有的注意力头可能关注语法，而有的关注句子结构等，从而有效地提高模型的性能。</p><h3 id="注意力机制在模型中的应用">注意力机制在模型中的应用</h3><p>说完了Attention的计算方式，再回到transformer模型中，这里有三种不同的attention，主要的区别就是Q, K, V的不同：</p><ol type="1"><li>encoder中的自注意力，在encoder的自注意力层中，所有的Q, K, V都是来自于输入的序列，所以称为自注意力，具体来说，要得到当前位置的自注意力输出，会使用当前位置的词元表征作为query，然后整个序列的词元作为key和value，然后进行多头注意力的计算，最终得到当前位置的输出。</li><li>decoder的自注意力，与encoder的自注意力相似，所有的Q, K, V都是来源于输入的序列，不过由于是翻译任务，在预测时的时候需要以自回归的方式一个个生成词元，因此在训练时需要屏蔽当前词元之后的词元，这里的具体做法就是在送入softmax之前，把当前词元的query和之后词元的key的缩放点积置为负无穷，这样，他们进入softmax计算得到的相似度就是0，通过这种方式来进行屏蔽。</li><li>decoder中的encoder-decoder注意力，注意这里的QKV就不是都来源于输入的序列了，而是Q来源于上一个decoder的输入序列，而K和V来源于encoder的输出序列，一般的seq2seq模型使用注意力机制也都是这么做的。</li></ol><h2 id="残差连接与layernorm">残差连接与LayerNorm</h2><p>残差连接是来源于ResNet, 为了解决深度神经网络中的梯度消失和梯度爆炸问题, 我们这里的transformer由于网络深度也非常深, 因此也引入了残差连接<br />而LayerNorm与BatchNorm类似, 都是一种归一化的方法, 不过归一化的维度不同, BatchNorm在mini-batch中对每个特征维度进行归一化，使得得到值的均值和方差都接近于0和1, 计算的维度是特征这个维度, 假设有C个特征会得到C个特征的统计值, 而LayerNorm则是对每个样本的特征维度进行归一化，使得每个样本上的每个特征的均值和方差接近于0和1, 计算的维度是样本这个维度, 有N个样本的话就会得到N个样本的统计值<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/764062/1683044251788-9270e9f2-b90c-4b86-b94f-4050f1767ddb.png#averageHue=%237e7e77&amp;clientId=ucb8551b1-5e38-4&amp;from=paste&amp;height=230&amp;id=u30d76700&amp;originHeight=170&amp;originWidth=296&amp;originalType=url&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=13441&amp;status=done&amp;style=none&amp;taskId=u5d211bc2-3472-4122-ac3d-1c5d2af708b&amp;title=&amp;width=400" alt="image.png" /><br />那么为什么在transformer里面要用LayerNorm而不用BatchNorm呢, 虽然 BatchNorm 可以在训练过程中缓解内部协变量移位的问题，但在处理序列数据时却存在一些问题。因为序列数据的长度通常是变化的，因此每个 mini-batch 的大小也是变化的。这意味着在训练过程中，每个 mini-batch 的统计信息可能会变化，从而导致 BatchNorm 的效果变差, 并且在测试时还需要维护均值和方差<br />相比之下，LayerNorm 是一种对每个样本中的每个特征维度进行归一化的技术，不受 mini-batch 大小的影响，因此更适合处理变长序列数据。另外，LayerNorm 不需要维护 mini-batch 统计信息，因此可以减少模型训练时的内存消耗，并且可以在测试时使用相同的归一化参数，从而避免了训练和测试时的不一致性。<br />在 Transformer 中，每个编码器和解码器层中的子层之间都使用了 LayerNorm，包括多头自注意力层和前馈网络层。这使得 Transformer 在处理序列数据时更加稳定和高效，并且可以在不同的任务中进行共享，提高了模型的泛化能力。因此，使用 LayerNorm 而不是 BatchNorm 是 Transformer 模型的一个重要设计选择。</p><h2 id="基于位置的前馈神经网络">基于位置的前馈神经网络</h2><p>这个其实就是一个普通的两层的线性神经网络，分别作用于输入序列的每一个位置，参数共享，并且在过完第一层之后使用ReLU激活函数，输入维度为512，隐藏层维度为2048，输出维度再变为512，具体如下：<br /><span class="math inline">\(\operatorname{FFN}(x)=\max(0,xW_1+b_1)W_2+b_2\)</span></p><h2 id="输出层">输出层</h2><p>在decoder输出时，使用了一个线性层+softmax，得到预测的每个位置上的词元的概率，并且这个线性层和encoder与decoder的两个嵌入层是共享参数矩阵的，同样的为了防止softmax可能导致的梯度消失，这里在计算时把嵌入层的权重乘以了<span class="math inline">\(\sqrt{d_{model} }\)</span>。</p><h2 id="位置编码">位置编码</h2><p>由于自注意力对于所有的词元都是一视同仁的，不会考虑到位置上的信息，因此，为了能够捕捉到位置上的信息，transformer考虑在输入的embedding上面加上位置编码，这个位置编码有两种方式，一种是训练得到的，也就是你赋予每一个位置一个embedding，让模型自己学，另一种是使用固定的，也就是论文里面采用的方式，他这里使用了一个余弦函数：<br /><span class="math inline">\(\begin{gathered} P E_{(p o s,2i)} =sin(pos/10000^{2i/d_\mathrm{model}}) \\ PE_{(pos,2i+1)} =cos(pos/10000^{2i/d_\text{model}}) \end{gathered}\)</span><br />其中pos是位置，i是维度。也就是说，位置编码的每个维度对应于一个正弦函数。<br />论文还试验了使用可学习的位置编码与固定的位置编码的效果，发现两个版本产生的结果几乎相同，而选择固定的正弦版本是因为它可以允许模型外推到比训练期间遇到的序列长度更长的序列长度。</p><h1 id="为什么要使用自注意力">为什么要使用自注意力？</h1><p>文章的最后来探讨一下在序列建模任务中为什么要使用自注意力，这里和卷积以及RNN做了对比，分别从计算复杂度、可并行度，以及长序列建模能力来进行讨论。<br /><img src="https://cdn.nlark.com/yuque/0/2023/svg/764062/1683041720960-e8f41c4e-d26e-4128-8944-51e627b87cc5.svg#clientId=ucb8551b1-5e38-4&amp;from=paste&amp;id=u4f813c97&amp;originHeight=419&amp;originWidth=628&amp;originalType=url&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uc7eea4d4-7ff0-4dc0-a47f-5ed489735e5&amp;title=" /><br />首先是计算复杂度，自注意力的计算复杂度可以说和卷积以及RNN的差不多，取决于输入的序列长度和embedding维度的大小，对于长序列计算attention会更为复杂。<br />然后是可并行度，这里的可并行度用的是以所需的最小顺序操作数来衡量，RNN建模需要满足先后关系，因此他是<span class="math inline">\(O(n)\)</span>,而attention和cnn则是<span class="math inline">\(O(1)\)</span><br />最后是长序列建模能力，长序列的建模能力是用使用序列头尾之间相连的网络路径长度来计算的，attention可以直接通过计算头尾之间的相似度并且进行加权，因此他是<span class="math inline">\(O(1)\)</span>, 而RNN的头尾则需要一步步传导，因此他是<span class="math inline">\(O(n)\)</span>, 而CNN则是<span class="math inline">\(O(log_k(n))\)</span>, 取决于卷积核的大小<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/764062/1683040501030-192c29d9-9c58-49c1-a95e-8ff01183053b.png#averageHue=%23f4f3f3&amp;clientId=ucb8551b1-5e38-4&amp;from=paste&amp;height=196&amp;id=u9d3a93fd&amp;originHeight=391&amp;originWidth=1632&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=93005&amp;status=done&amp;style=none&amp;taskId=u040c5d01-b9ae-4ded-a2ea-abf29cbae2b&amp;title=&amp;width=816" alt="image.png" /><br />因此attention的好处在于他不仅计算复杂度可以接受, 并且由于可以并行, 工业界的模型都是在集群上并行计算的, 因此由于其并行能力强也可以看作他计算速度快了, 而且由于可以连接一个序列上的任意两个位置,对于长序列建模能力也很不错<br />还有一个就是他效果好, 而且由于可以输出注意力的分布, 使得他还具备一定的可解释性, 因此慢慢地在各个领域里面就都有应用了</p><h1 id="参考">参考</h1><ol type="1"><li><a href="http://arxiv.org/abs/1706.03762">Attention Is All You Need</a></li><li><a href="https://zh-v2.d2l.ai/">《动手学深度学习》</a></li><li>chatgpt</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;transformer自诞生以来，基本上在每个领域都取得了非常大的成功，如nlp领域的Bert、GPT，cv领域的ViT，swin transformer，推荐系统领域的autoint，behavior sequence transformer，还有时序里面的tft、informer，以及强化学习也搞了个Decision Transformer，而这些都源自于谷歌团队在2017年提出的这篇文章《Attention is All you Need》，本着阅读经典，顺便复习面经的精神，这次我们就来阅读transformer这篇论文，深入到每一个细节之中，确保对这个模型知根知底，当然，具体在写的时候不会严格按照原文来，而是按照我自己的想法来进行组织的。&lt;/p&gt;</summary>
    
    
    
    <category term="深度学习" scheme="https://lukan217.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="面经" scheme="https://lukan217.github.io/tags/%E9%9D%A2%E7%BB%8F/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle Otto推荐系统比赛TOP方案总结</title>
    <link href="https://lukan217.github.io/2023/02/12/Kaggle%20Otto%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%AF%94%E8%B5%9BTOP%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/"/>
    <id>https://lukan217.github.io/2023/02/12/Kaggle%20Otto%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%AF%94%E8%B5%9BTOP%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/</id>
    <published>2023-02-12T13:52:01.863Z</published>
    <updated>2023-02-12T13:57:18.121Z</updated>
    
    <content type="html"><![CDATA[<p>最近Otto的比赛完结了，总结学习一下奖金区的方案，顺便在文末放自己一份单模在榜单上能排大概22名的代码</p><h1 id="赛题介绍">赛题介绍</h1><ul><li>赛题名称：<a href="https://www.kaggle.com/competitions/otto-recommender-system">OTTO – Multi-Objective Recommender System</a></li><li>赛题简介：本次比赛的目标是预测电子商务点击量、购物车添加量和订单。您将根据用户会话中的先前事件构建一个多目标推荐系统。</li><li>数据：训练数据包含4周的电子商务会话信息，每个session（可以理解为用户）中包含用户交互过的多个aid（商品），每个aid都有用户交互的行为（clicks,carts,orders）以及发生的时间戳，测试数据包含未来一周session按照均匀分布随机截断的数据，需要预测测试session中最后一个时间戳之后三种交互行为(clicks， carts，orders)可能对应的aid</li><li>评价指标：对每种交互类型的加权recall@20:<ul><li><span class="math inline">\(\textit{score}=0.10\cdot R_{clicks}+0.30\cdot R_{carts}+0.60\cdot R_{orders}\)</span></li><li><span class="math inline">\(R_{t ype}=\dfrac{\sum_{i}^{N}\left|\{\text{predicted aids}\}_{t,type}\cap\{\text{ground truth aids}\}_{i,type}\right|}{\sum_{i}^{N}\min\left(20,\left|\{\text{ground truth aids}\}_{i,tye}\right|\right)}\)</span></li></ul></li></ul><p>整体比赛还是比较难的，一方面数据量大，需要较大的内存，同时需要懂的=各种优化操作，另一方面特征很少，用户和商品特征几乎没有，需要自行构建较多的相似度特征才能取得比较好的成绩。</p><h1 id="st-place-solution">1st Place Solution</h1><ul><li>链接：<a href="https://www.kaggle.com/competitions/otto-recommender-system/discussion/384022">https://www.kaggle.com/competitions/otto-recommender-system/discussion/384022</a></li><li>方案亮点：生成了1200个候选，并且使用一个精心设计的NN模型来进行召回，这个应该是在top方案里面唯一使用NN模型的</li></ul><h2 id="召回阶段">召回阶段</h2><p>召回了1200个候选，召回策略包括：</p><ol type="1"><li>session内交互过的aid</li><li>共同访问矩阵<ol type="1"><li>构建了多个版本，分别对类别以及时间进行不同的加权</li><li>像beam search一样多次从共同访问矩阵中进行召回</li></ol></li><li>NN召回<ol type="1"><li>构建了多个版本的NN模型来召回候选以及生成特征，NN的架构是MLP或者Transformer，具体方式如下：</li><li>在训练阶段，将session进行切分，一部分作为x_aids, 一部分作为y_aids，x_aids与一些时间特征还有拼接后输入一个NN，然后pooling后得到一个session embedding，同时，为了能够输出不同类型的embedding，将想要得到的类型也作为一个特征输入到NN中，然后y_aids则作为负样本，过embedding层后与session embedding计算余弦相似度，然后将计算的相似度取平均和最小值加和除以2，同时，也采样一些负样本，得到负样本的embedding后与session embedding计算余弦相似度后取top k个，最后计算 cross entropy损失。</li><li>在测试阶段，对于每一个session，将session内的所有aid丢进去计算一个session embedding，然后把所有的aid与session embedding计算余弦相似度后取top k作为最终的召回结果。</li></ol></li></ol><p>不得不说这个NN的训练方式设计的真的很巧妙，流程图如下：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/764062/1676140497214-d77571c3-0428-4271-a1fc-c3706d4dc714.png#averageHue=%23fbfafa&amp;clientId=u80392229-df4f-4&amp;from=paste&amp;id=u99e9652b&amp;name=image.png&amp;originHeight=976&amp;originWidth=1816&amp;originalType=url&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=150055&amp;status=done&amp;style=none&amp;taskId=uc81087a6-3e89-4bc1-8dcc-050a272f709&amp;title=" alt="image.png" /><br /><img src="https://cdn.nlark.com/yuque/0/2023/png/764062/1676140504832-5d5bf01c-f5aa-43cf-887a-b95836a9f3b8.png#averageHue=%23fcfcfc&amp;clientId=u80392229-df4f-4&amp;from=paste&amp;id=ue687111c&amp;name=image.png&amp;originHeight=1002&amp;originWidth=1804&amp;originalType=url&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=104807&amp;status=done&amp;style=none&amp;taskId=u57e04ce1-e9fc-4157-932b-5f6c6d6811a&amp;title=" alt="image.png" /></p><h2 id="排序阶段">排序阶段</h2><h3 id="特征工程">特征工程</h3><ol type="1"><li>session特征: 长度、aid重复率、最后一个aid与倒数第二个aid的时间差</li><li>aid特征：aid的热门程度（使用多个时间窗进行加权），不同行为类型的比率等</li><li>session与aid交互特征<ol type="1"><li>共同访问矩阵的排名</li><li>NN模型生成的余弦相似度</li><li>session中的aid特征（何时出现、交互类型等）</li></ol></li></ol><h3 id="模型">模型</h3><p>LightGBM Ranker, 单模0.604，使用了9个不同超参训练的Lightgbm, 最终得分0.605</p><h2 id="其他">其他</h2><ol type="1"><li>负样本采样：click 5%, carts: 25%, orders: 40%</li><li>cv策略：采用开源的方案，为了快速迭代，采用5%的数据进行训练，10%的数据作为验证</li><li>消融实验，可以看到这个NN模型提升还是挺大的，提升了5个千分位</li></ol><figure><img src="https://cdn.nlark.com/yuque/0/2023/png/764062/1676143052203-c7656281-db7b-4429-aa0d-3b4cf35de8ee.png#averageHue=%23fefefd&amp;clientId=ucaaefed0-cb00-4&amp;from=paste&amp;height=600&amp;id=u971916f7&amp;name=image.png&amp;originHeight=1199&amp;originWidth=1627&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=142420&amp;status=done&amp;style=none&amp;taskId=uc188f676-e414-4259-8788-f5d740c7e5b&amp;title=&amp;width=813.5" alt="image.png" /><figcaption aria-hidden="true">image.png</figcaption></figure><h1 id="nd-place-solution-part-1">2nd Place Solution Part 1</h1><ul><li>链接：<a href="https://www.kaggle.com/competitions/otto-recommender-system/discussion/382839">https://www.kaggle.com/competitions/otto-recommender-system/discussion/382839</a></li><li>方案亮点：对于item cf的召回做了很多工作</li></ul><h2 id="召回阶段-1">召回阶段</h2><p>由于这个比赛没有什么用户/商品特征，然后热门召回也不起作用，因此主要的召回方式包括：</p><ol type="1"><li>session内交互过的aid</li><li>next action: 与共同访问矩阵类似，统计每个aid和下一个aid的出现次数，排序进行召回</li><li>itemcf，使用了多种矩阵和加权方式<ol type="1"><li>矩阵：cart-order，click-cart&amp;order，click-cart-order</li><li>加权方式：交互类别，共现时间距离，共现的顺序，session action 顺序，热门程度</li></ol></li></ol><h2 id="排序阶段-1">排序阶段</h2><h3 id="特征工程-1">特征工程</h3><ol type="1"><li>聚合特征：session，aid, session*aid，以及分类别的计数</li><li>next action特征：候选商品与最后一个商品共同出现的次数</li><li>时间：session和aid的开始时间和结束时间</li><li>itemcf分数，候选商品与session最后一个商品、最后一个小时商品、所有商品的最大、加和、加权和的itemcf分数</li><li>embedding相似度，word2vec生成的候选商品与最后一个商品的相似度，ProNE生成的session和aid相似度</li></ol><h3 id="模型-1">模型</h3><p>catboost ranker+lightgbm classifier融合</p><h2 id="其他-1">其他</h2><ol type="1"><li>使用polars代替pandas，在数据merge时可以加速40倍（不过我自己用的时候很坑的一点是如果有空值会把数据类型改成float 64，虽然速度很快，但极大加剧了我的内存占用）</li><li>使用TreeLite来加速lightgbm的推理速度(快2倍)，CatBoost-GPU比lightgbm-CPU的推理快30倍</li></ol><h1 id="nd-place-solution-part-2">2nd Place Solution Part 2</h1><ul><li>链接：<a href="https://www.kaggle.com/competitions/otto-recommender-system/discussion/382790">https://www.kaggle.com/competitions/otto-recommender-system/discussion/382790</a></li><li>方案亮点：这是他们队另外一个人写的方案，写的有点少，item2item的特征做的比较出色</li></ul><h2 id="召回阶段-2">召回阶段</h2><p>略，用的队友@psilogram的方案，没有写</p><h2 id="排序阶段-2">排序阶段</h2><h3 id="特征工程-2">特征工程</h3><p>一部分略，用的队友@psilogram的方案，主要做了一些的item2item特征，包括：</p><ol type="1"><li>计数</li><li>时间差</li><li>sequence difference(<span class="citation" data-cites="psilogram发明的">@psilogram发明的</span>)</li><li>2种以上提到的加权特征</li><li>上述特征的聚合</li></ol><p>最终得到400-500个特征</p><h3 id="模型-2">模型</h3><p>xgboost+catboost</p><h2 id="其他-2">其他</h2><ol type="1"><li>伪标签？：模型分两阶段，第一阶段训练好后输出oof prediciton, 然后作为特征再训练一次模型，虽然可能会过拟合，但是分数提升了</li><li>使用了cudf和cuml进行加速</li></ol><h1 id="rd-place-solution-part-1">3rd Place Solution Part 1</h1><ul><li>链接：<a href="https://www.kaggle.com/competitions/otto-recommender-system/discussion/383013">https://www.kaggle.com/competitions/otto-recommender-system/discussion/383013</a></li><li>方案亮点：这个部分是Chris大神做的，非常简洁，没有各种花里胡哨的召回和特征工程，仅仅靠各种规则生成的共同访问矩阵就能单模0.601</li></ul><h2 id="召回阶段-3">召回阶段</h2><ol type="1"><li>session内交互过的aid</li><li>共同访问矩阵，根据不同的规则一共做了20个共同访问矩阵，具体可以看他开源的notebook<a href="https://www.kaggle.com/code/cdeotte/rules-only-model-achieves-lb-590/notebook">https://www.kaggle.com/code/cdeotte/rules-only-model-achieves-lb-590/notebook</a></li></ol><h2 id="排序阶段-3">排序阶段</h2><h3 id="特征工程-3">特征工程</h3><ol type="1"><li>session特征</li><li>aid特征</li><li>session aid交互特征</li><li>共同访问矩阵生成的分数特征</li></ol><h3 id="模型-3">模型</h3><p>单模xgboost</p><h2 id="其他-3">其他</h2><ol type="1"><li>使用了cudf进行加速，在4块v100的GPU上生成共同访问矩阵，生成了上百个，一个一分钟左右就能跑完，最终计算local cv挑了20个</li></ol><h1 id="rd-place-solution-part-2">3rd Place Solution Part 2</h1><ul><li>链接：<a href="https://www.kaggle.com/competitions/otto-recommender-system/discussion/382975">https://www.kaggle.com/competitions/otto-recommender-system/discussion/382975</a></li><li>方案亮点：和上面的方案大差不差，主要是后面提到一两个trick比较有意思</li></ul><h2 id="召回阶段-4">召回阶段</h2><p>用的Chris的候选，经过一点点调整</p><h2 id="排序阶段-4">排序阶段</h2><h3 id="特征工程-4">特征工程</h3><ol type="1"><li>常规特征</li><li>item2item相似度特征：（w2v相似度，矩阵分解相似度，共同访问矩阵相似度），对session内的aid进行各种加权（时间、位置、类别）计算相似度，然后聚合（mean、max、sum等），如下图</li></ol><figure><img src="https://cdn.nlark.com/yuque/0/2023/png/764062/1676192192198-34d4e62c-179e-47bb-bcb2-c6d1e61ce8ad.png#averageHue=%23fefcfb&amp;clientId=ucaaefed0-cb00-4&amp;from=paste&amp;height=595&amp;id=ucf5e6861&amp;name=image.png&amp;originHeight=892&amp;originWidth=1736&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=241733&amp;status=done&amp;style=none&amp;taskId=u3b116f93-4c21-41c2-8012-f76501c922c&amp;title=&amp;width=1157.3333333333333" alt="image.png" /><figcaption aria-hidden="true">image.png</figcaption></figure><h3 id="模型-4">模型</h3><p>xgboost</p><h2 id="其他-4">其他</h2><ol type="1"><li>增加训练数据，由于主办方在训练和预测分割时，丢掉了一部分数据，于是他把这些数据也加进来训练，有0.0005 到 0.001的提升</li></ol><figure><img src="https://cdn.nlark.com/yuque/0/2023/png/764062/1676192180483-c727ca56-b609-47c3-bfdd-967b1fb96a27.png#averageHue=%23fcfaf9&amp;clientId=ucaaefed0-cb00-4&amp;from=paste&amp;height=353&amp;id=u5dd99973&amp;name=image.png&amp;originHeight=529&amp;originWidth=1917&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=108710&amp;status=done&amp;style=none&amp;taskId=u999e678b-77b4-4c2d-9f03-33fe7287ad1&amp;title=&amp;width=1278" alt="image.png" /><figcaption aria-hidden="true">image.png</figcaption></figure><ol start="2" type="1"><li>使用optuna来调整多折训练融合的权重</li><li>代码已开源：<a href="https://github.com/TheoViel/kaggle_otto_rs">https://github.com/TheoViel/kaggle_otto_rs</a></li></ol><p>另外，这里原本的第三名应该是另外一支队伍的，因为有个GM作弊，导致整只队伍被取消成绩，他们的方案也很值得学习，并且也有代码开源：<a href="https://www.kaggle.com/competitions/otto-recommender-system/discussion/382879">https://www.kaggle.com/competitions/otto-recommender-system/discussion/382879</a></p><h1 id="总结">总结</h1><p>这次比赛还是学到挺多的，更多的是认清了kaggle的水深，敬告大家组队时一定要擦亮双眼，防止队友作弊导致全队几个月的工作付之一炬，最后放一份自己的代码：<br /><a href="https://github.com/lukan217/kaggle_otto_rec_sys">https://github.com/lukan217/kaggle_otto_rec_sys</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近Otto的比赛完结了，总结学习一下奖金区的方案，顺便在文末放自己一份单模在榜单上能排大概22名的代码&lt;/p&gt;</summary>
    
    
    
    <category term="比赛" scheme="https://lukan217.github.io/categories/%E6%AF%94%E8%B5%9B/"/>
    
    
    <category term="kaggle" scheme="https://lukan217.github.io/tags/kaggle/"/>
    
    <category term="推荐系统" scheme="https://lukan217.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>树模型的特征选择-Boruta</title>
    <link href="https://lukan217.github.io/2023/02/07/%E6%A0%91%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9-Null%20Importance/"/>
    <id>https://lukan217.github.io/2023/02/07/%E6%A0%91%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9-Null%20Importance/</id>
    <published>2023-02-07T05:05:14.358Z</published>
    <updated>2023-02-07T05:06:19.436Z</updated>
    
    <content type="html"><![CDATA[<p>Null Importance，和很久之前介绍过的<a href="https://zhuanlan.zhihu.com/p/479950999">Boruta</a>一样，是一种专门针对树模型的特征选择方法，用来解决树模型中特征重要性并不能真实反映特征与标签的真实关系的问题。最近在一些特征选择的问题上用到了它，效果还不错，并且速度和内存占用上比Bortuta要优秀很多。 <a name="Ca4V7"></a> # 算法思想 Null Importance的核心思想是输出两种特征重要性，一种是实际的特征重要性，另一种是打乱标签训练得到的null importance，然后使用后者对前者做一个修正，以得到真实的特征重要性。<br />具体步骤：</p><ol type="1"><li>计算实际的importance，以正常的方式训练一个树模型，输出特征重要度，这个特征重要度便反映了模型训练过程中起作用的特征排序。</li><li>计算null importance，首先将标签打乱，然后以步骤一同样的方式训练一个模型，使用模型输出特征重要性，这里输出的特征重要性就被称为null importance，这个null importance就反映了在不考虑标签的情况下，模型在训练过程中是如何理解特征的。然而，由于特征被打乱过，特征与目标之间已经不存在实际意义上的关联，所以结果是不稳定的，就需要多次实验来得到一个null importance的分布才会比较准确</li><li>计算特征分数，对于好的特征，实际的importance应该会很高，而null importance会很低，而对于不好的特征，它的null importance会和实际的importance差不多甚至大于实际的importace，因此我们便可以借助步骤12输出的实际importance和null importance的相对关系来构建一个评价体系，也就是每个特征的分数，来评价一个特征好不好，具体做法就有很多了，比如实际importance与null importance的差值、比率等，作者这里使用了log(实际importance/null importance的75分位数)</li><li>输出特征选择结果，根据计算的特征分数，便可以卡一个阈值，来选择需要输出的特征数量，也可以自己观察下实际的importance和null importance的差距，来决定特征的去留。</li></ol><p>从上面的过程中我们可以发现，null importance这种方法实际上是对实际的特征重要性做了一个修正，之前提到特征重要性不能用来做特征选择的一个问题便是，高基数的类别特征或者连续性特征特征重要性天然会比别的特征大，因为特征重要度是根据决策树分裂前后节点的不纯度的减少量（基尼系数或者MSE）来算的，对于数值特征或者类别多的的类别特征，不纯度较少相对来说会比较多，而且像在lgb和xgb这种模型中，如果指定了category feature，这些特征的重要性也会相当高。这是特征的属性导致的，那么在打乱标签输出的null importance中，具有这种问题的特征重要性还是会相对较高，因此便可以用null importance来对实际的importance做一个修正，得到真实的特征重要性。 <a name="OU2ec"></a> # 代码实现 下面结合自己的理解看下代码实现：<br />首先我们需要一个函数用来计算importance, 并且实际的importance和null importance都能计算： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_feature_importances</span>(<span class="params">data, shuffle, seed=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="comment"># Gather real features</span></span><br><span class="line">    train_features = [f <span class="keyword">for</span> f <span class="keyword">in</span> data <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&#x27;TARGET&#x27;</span>]]</span><br><span class="line">    <span class="comment"># Go over fold and keep track of CV score (train and valid) and feature importances</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Shuffle target if required</span></span><br><span class="line">    y = data[<span class="string">&#x27;TARGET&#x27;</span>].copy()</span><br><span class="line">    <span class="keyword">if</span> shuffle:</span><br><span class="line">        <span class="comment"># Here you could as well use a binomial distribution</span></span><br><span class="line">        y = data[<span class="string">&#x27;TARGET&#x27;</span>].copy().sample(frac=<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Fit LightGBM in RF mode, yes it&#x27;s quicker than sklearn RandomForest</span></span><br><span class="line">    dtrain = lgb.Dataset(data[train_features], y, free_raw_data=<span class="literal">False</span>)</span><br><span class="line">    lgb_params = &#123;</span><br><span class="line">        <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;binary&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;boosting_type&#x27;</span>: <span class="string">&#x27;rf&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;subsample&#x27;</span>: <span class="number">0.623</span>,</span><br><span class="line">        <span class="string">&#x27;colsample_bytree&#x27;</span>: <span class="number">0.7</span>,</span><br><span class="line">        <span class="string">&#x27;num_leaves&#x27;</span>: <span class="number">127</span>,</span><br><span class="line">        <span class="string">&#x27;max_depth&#x27;</span>: <span class="number">8</span>,</span><br><span class="line">        <span class="string">&#x27;seed&#x27;</span>: seed,</span><br><span class="line">        <span class="string">&#x27;bagging_freq&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;verbose&#x27;</span>: -<span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;n_jobs&#x27;</span>: <span class="number">4</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Fit the model</span></span><br><span class="line">    clf = lgb.train(params=lgb_params, train_set=dtrain, num_boost_round=<span class="number">200</span>, categorical_feature=categorical_feats)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get feature importances</span></span><br><span class="line">    imp_df = pd.DataFrame()</span><br><span class="line">    imp_df[<span class="string">&quot;feature&quot;</span>] = <span class="built_in">list</span>(train_features)</span><br><span class="line">    imp_df[<span class="string">&quot;importance_gain&quot;</span>] = clf.feature_importance(importance_type=<span class="string">&#x27;gain&#x27;</span>)</span><br><span class="line">    imp_df[<span class="string">&quot;importance_split&quot;</span>] = clf.feature_importance(importance_type=<span class="string">&#x27;split&#x27;</span>)</span><br><span class="line">    imp_df[<span class="string">&#x27;trn_score&#x27;</span>] = roc_auc_score(y, clf.predict(data[train_features]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> imp_df</span><br><span class="line"></span><br></pre></td></tr></table></figure> 这里实际上用的是lightgbm实现的随机森林模型，因为随机森林输出的特征重要性更稳定（多颗决策树的叠加），GBDT还需要考虑迭代次数过多而导致的过拟合问题，而随机森林不需要，因此用了随机森林。最终输出的importance有两个，一一个是split，代表这个特征被决策树选择用来分裂的次数，另外一个是gain，代表这个特征分裂时带来的增益总和，这里两种类型都输出，两种结果有点差异，最终自己选一种就行了。<br />然后接下来计算实际的importance和null importance： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">actual_imp_df = get_feature_importances(data=data, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">null_imp_df = pd.DataFrame()</span><br><span class="line">nb_runs = <span class="number">80</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nb_runs):</span><br><span class="line">    <span class="comment"># Get current run importances</span></span><br><span class="line">    imp_df = get_feature_importances(data=data, shuffle=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># Concat the latest importances with the old ones</span></span><br><span class="line">    null_imp_df = pd.concat([null_imp_df, imp_df], axis=<span class="number">0</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure> 最后计算特征的分数： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">feature_scores = []</span><br><span class="line"><span class="keyword">for</span> _f <span class="keyword">in</span> actual_imp_df[<span class="string">&#x27;feature&#x27;</span>].unique():</span><br><span class="line">    f_null_imps_gain = null_imp_df.loc[null_imp_df[<span class="string">&#x27;feature&#x27;</span>] == _f, <span class="string">&#x27;importance_gain&#x27;</span>].values</span><br><span class="line">    f_act_imps_gain = actual_imp_df.loc[actual_imp_df[<span class="string">&#x27;feature&#x27;</span>] == _f, <span class="string">&#x27;importance_gain&#x27;</span>].mean()</span><br><span class="line">    gain_score = np.log(<span class="number">1e-10</span> + f_act_imps_gain / (<span class="number">1</span> + np.percentile(f_null_imps_gain, <span class="number">75</span>)))  <span class="comment"># Avoid didvide by zero</span></span><br><span class="line">    f_null_imps_split = null_imp_df.loc[null_imp_df[<span class="string">&#x27;feature&#x27;</span>] == _f, <span class="string">&#x27;importance_split&#x27;</span>].values</span><br><span class="line">    f_act_imps_split = actual_imp_df.loc[actual_imp_df[<span class="string">&#x27;feature&#x27;</span>] == _f, <span class="string">&#x27;importance_split&#x27;</span>].mean()</span><br><span class="line">    split_score = np.log(<span class="number">1e-10</span> + f_act_imps_split / (<span class="number">1</span> + np.percentile(f_null_imps_split, <span class="number">75</span>)))  <span class="comment"># Avoid didvide by zero</span></span><br><span class="line">    feature_scores.append((_f, split_score, gain_score))</span><br><span class="line"></span><br><span class="line">scores_df = pd.DataFrame(feature_scores, columns=[<span class="string">&#x27;feature&#x27;</span>, <span class="string">&#x27;split_score&#x27;</span>, <span class="string">&#x27;gain_score&#x27;</span>])</span><br><span class="line">scores_df = scores_df.sort_values(<span class="string">&#x27;split_score&#x27;</span>, ascending=<span class="literal">False</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure> 根据输出的score_df便可以得到每个特征的分数，也可以理解为它们真实的特征重要性。 <a name="iYWob"></a> # 总结 Null Importance以打乱标签的方式来输出null importance，来对实际的importance进行修正，从而得到真实的特征重要性，和Boruta一样，是针对树模型的特征选择方法，不过Boruta是打乱特征，而Null Importance是打乱标签，因此Null Importance对于内存的占用和速度都会比Boruta要好。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Null Importance，和很久之前介绍过的&lt;a href=&quot;https://zhuanlan.zhihu.com/p/479950999&quot;&gt;Boruta&lt;/a&gt;一样，是一种专门针对树模型的特征选择方法，用来解决树模型中特征重要性并不能真实反映特征与标签的真实关系的问题。最近在一些特征选择的问题上用到了它，效果还不错，并且速度和内存占用上比Bortuta要优秀很多。 &lt;a name=&quot;Ca4V7&quot;&gt;&lt;/a&gt; # 算法思想 Null Importance的核心思想是输出两种特征重要性，一种是实际的特征重要性，另一种是打乱标签训练得到的null importance，然后使用后者对前者做一个修正，以得到真实的特征重要性。&lt;br&gt;具体步骤：&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://lukan217.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="https://lukan217.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="特征选择" scheme="https://lukan217.github.io/tags/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"/>
    
  </entry>
  
  <entry>
    <title>2022w微信大数据挑战赛Top方案总结</title>
    <link href="https://lukan217.github.io/2022/09/24/2022%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9BTop%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/"/>
    <id>https://lukan217.github.io/2022/09/24/2022%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9BTop%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/</id>
    <published>2022-09-24T02:26:35.231Z</published>
    <updated>2022-09-24T02:28:31.919Z</updated>
    
    <content type="html"><![CDATA[<p>上周微信大数据挑战赛的决赛结束了，自己之前也投入了不少的时间来做，所以还是需要好好学习一下决赛的方案 <a name="wCpG0"></a> # 赛题介绍</p><ul><li>赛题名称：多模态短视频分类</li><li>赛题链接：<a href="https://algo.weixin.qq.com/">微信大数据挑战赛</a></li><li>数据<ul><li>10w有标注数据（包含视频类别）</li><li>100w无标注数据</li><li>每条数据包含短视频的：标题/OCR/ASR文本，32帧视频图像（初赛为抽取的特征，复赛为原始视频图像）</li></ul></li></ul><figure><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1663962743344-48189f70-eb1c-43a8-a117-7e005af137c8.png#clientId=u04545e1a-2ebf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=342&amp;id=ufedde171&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=684&amp;originWidth=1672&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=62398&amp;status=done&amp;style=none&amp;taskId=ucf3d64e5-261c-4b9f-94f8-5c573ed8fe6&amp;title=&amp;width=836" alt="image.png" /><figcaption aria-hidden="true">image.png</figcaption></figure><ul><li><p>预测任务：预测每个视频所属的子类别，一共200类</p></li><li><p>评价指标：一二级分类F1的micro和macro平均值</p></li><li><p>决赛回放：<a href="https://live.csdn.net/room/wl5875/Z7h0CxuN">2022中国高校计算机大赛——微信大数据挑战赛决赛-CSDN直播</a> <a name="sVF9i"></a> # 1st 苟进决赛 <a name="V4Xbk"></a> ## 模型架构 采用三种模型架构进行融合：</p></li><li><p>模型一：单流架构，文本过embedding层，视频过clip的vit，然后拼接起来送入bert，最后mean pooing后接分类层</p></li><li><p>模型二，双流架构，文本过bert，视频过clip，然后将视频向量和文本向量拼接起来，再过一个transformer，mean pooing后接分类层</p></li><li><p>模型三，双流架构，文本过bert，视频过clip，得到视频向量和文本向量，然后做cross attention,即对于视频向量，用文本向量作为Q进行注意力加权，而对于文本向量，用视频向量作为Q进行注意力加权，最后mean pooing后接分类层</p></li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1663636603759-8daf9518-86ba-42a1-b1e5-06c6472a1a65.png#clientId=ua1e5a05c-66ec-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=557&amp;id=u09c940ec&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1114&amp;originWidth=2698&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=462998&amp;status=done&amp;style=none&amp;taskId=ua4ba0bc2-5233-49e4-bea0-3f8f45fa82e&amp;title=&amp;width=1349" alt="image.png" /><br />其他选手的模型架构基本也都是这三种的一种，之后就不详细展开 <a name="j5Snx"></a> ## 预训练任务</p><ol type="1"><li><p>MLM（Mask languge model）：输入时随机mask掉一个文本，预测被mask掉的文本</p></li><li><p>VTM (Video text match)：输入时以50%概率随机采样替换掉一个视频，然后预测这个视频是不是原来的视频，即输入的文本是否与视频匹配</p></li><li><p>ICT (Inverse Cloze Task)：文本包含标题、OCR,ASR，随机取一段作为query，其余的作为condidate，做对比学习</p></li><li><p>SimCSE：对于一个文本输入，经过两次dropout后作为正样本，其他文本作为负样本，进行对比学习 <a name="xHRcQ"></a> ## 其他技巧</p></li><li><p>知识蒸馏</p></li></ol><p>这部分应该是整个方案的核心亮点了，也是拉开和后面几位差距的关键点。<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1663656074613-070c60d0-f475-48d5-9289-8b41c26aedac.png#clientId=ua1e5a05c-66ec-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=460&amp;id=u5dee590d&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=919&amp;originWidth=2724&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=328607&amp;status=done&amp;style=none&amp;taskId=u2d47d71c-ae92-4443-a982-8067e59dc89&amp;title=&amp;width=1362" alt="image.png" /><br />具体步骤应该是：</p><ol type="1"><li><p>在标注数据上，训练更长（32帧）的帧和更大（CLIP-Large）更多（ensemble）的模型</p></li><li><p>使用1得到的模型为无标注数据打伪标签，得到一份带伪标签的无标注数据</p></li><li><p>在2得到的这份数据上进行预训练，预训练任务包含伪标签预测以及之前提到的那4个，预训练时随机使用5/32帧的视频，以缓解预训练和微调过程的不一致性</p></li><li><p>重复2和3步骤，将最后得到的模型用来做下一步微调模型的初始化</p></li><li><p>在有标注数据上进行微调，得到最终预测结果 <a name="ZJl8y"></a> ## 亮点</p></li><li><p>伪标签知识蒸馏，直接提了两个百分点，还是很厉害的 <a name="aS6ll"></a> # 2nd 冲冲冲 <a name="LPCcV"></a> ## 模型架构 就是一个普通的单流架构，不过引入了Memory Bank来缓解batchsize过小导致预训练效果差的问题<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1663641177228-b70ef751-32e0-4710-b00f-cc5b13b63625.png#clientId=ua1e5a05c-66ec-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=414&amp;id=u987683bc&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=828&amp;originWidth=1475&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=507248&amp;status=done&amp;style=none&amp;taskId=u6f4c191e-6ea1-491c-bac2-edaca28c97d&amp;title=&amp;width=737.5" alt="image.png" /> <a name="IdPl2"></a> ## 预训练任务</p></li><li><p>MLM</p></li><li><p>MMA（Multi-modal Alignment）：最特色的地方，在对比学习时引入了三类共六个的任务，使得模态间信息更加对齐，并且在训练时随机丢弃一个模态，以缓解模态缺失的问题，并加快训练</p></li></ol><p><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1663699381018-1de11cd0-658e-4ec8-9efa-38427ea34eea.png#clientId=ua1e5a05c-66ec-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=613&amp;id=u876d1188&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1226&amp;originWidth=2671&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=575987&amp;status=done&amp;style=none&amp;taskId=ufccfd26b-dbb2-4449-9c8c-9a6b7c9c322&amp;title=&amp;width=1335.5" alt="image.png" /> <a name="T7mpQ"></a> ## 其他技巧</p><ol type="1"><li>EMA</li><li>Label smoothing</li><li>Rdrop</li><li>Class Balanced Loss</li></ol><figure><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1663699534745-92784cb8-5a4f-4836-8e5a-d29958670998.png#clientId=ua1e5a05c-66ec-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=78&amp;id=u77b1889e&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=156&amp;originWidth=794&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=38890&amp;status=done&amp;style=none&amp;taskId=ufe5e77b4-57c1-4880-ad16-52df2dc170c&amp;title=&amp;width=397" alt="image.png" /><figcaption aria-hidden="true">image.png</figcaption></figure><ol start="5" type="1"><li><p>模型加速</p><ol type="1"><li>图片解码加速，GPU预处理加速</li><li>TensorRT + 数据并行 + 共享内存</li><li>FP16推理 + 分桶预测 + 多进程模型并行</li></ol></li><li><p>伪标签：用10万有标记样本，训练DML模型并提取特征，然后用无标记数据检索有标记数据，用Top10样本进行类目投票，这里生成伪标签跟其他选手用的方案不一样，不是直接预测，而是用检索的方式来生成，也算一大特色 <a name="dnatb"></a> ## 亮点</p></li><li><p>预训练的MMA任务</p></li><li><p>伪标签用检索的方式生成 <a name="T5K4L"></a> # 3rd 抱朴子 <a name="Z8Jah"></a> ## 模型架构 这组一共用了5个模型，双流的三个模型共用编码器，编码器采用中文预训练的R2D2的Roberta-base和VIT-large，具体每个模型的架构也都和第一名提到的三个没太大差别<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1663700198529-3017edd9-c156-4887-ba1d-06926cc3550e.png#clientId=ua1e5a05c-66ec-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=638&amp;id=u548daa6a&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1276&amp;originWidth=1955&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=183162&amp;status=done&amp;style=none&amp;taskId=uecf60a59-f745-41ea-adfc-15b7a47e2c5&amp;title=&amp;width=977.5" alt="image.png" /><br />单流架构的Alpro应该是先把文本过6层的transformer后再和视频特征拼起来送入后6层<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1663700469412-44c0019e-94a7-41be-b026-4dfd820df250.png#clientId=ua1e5a05c-66ec-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=447&amp;id=ude6fd0f7&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=894&amp;originWidth=1820&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=111335&amp;status=done&amp;style=none&amp;taskId=u344be838-fa37-4d01-9269-9478cfcc1fe&amp;title=&amp;width=910" alt="image.png" /><br />双流架构一个使用cross-encoder的方式，另外两个用了cross-attention，这两个的差别在于处理视频向量时一个采用视频patch聚合另一个采用视频帧之间平均<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1663700522791-ddd1a1da-3b2d-4c54-9be6-65def1971554.png#clientId=ua1e5a05c-66ec-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=286&amp;id=u54d71ecd&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=571&amp;originWidth=2272&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=115170&amp;status=done&amp;style=none&amp;taskId=ue38ae86f-b960-44c3-ba8c-e1f7c77ab96&amp;title=&amp;width=1136" alt="image.png" /> <a name="w2tM4"></a> ## 预训练任务</p></li><li><p>MLM</p></li><li><p>VTM</p></li><li><p>MFM (mask frame model)：随机mask掉一个帧，然后在输出时还原对应的帧 <a name="W3Xfo"></a> ## 其他技巧</p></li><li><p>EMA, FGM等</p></li><li><p>TensorRT优化加速 <a name="xSJB8"></a> ## 亮点</p></li><li><p>文本和视频编码器用的中文预训练模型R2D2 <a name="pOEsX"></a> # 3rd 机器不学习啦 <a name="VHyZI"></a> ## 模型架构 使用双流的ALBEF架构，视频过clip，文本过六层的bert，最后在后六层的bert做交互。<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1663934670257-6c1329f4-1f4e-43e0-a750-3b8ac38771a6.png#clientId=u47c39a7c-ef19-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=476&amp;id=ub70c7338&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=951&amp;originWidth=924&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=99115&amp;status=done&amp;style=none&amp;taskId=u5ac6e148-dbe6-4c5a-a264-7b698804b8e&amp;title=&amp;width=462" alt="image.png" /> <a name="OejXd"></a> ## 预训练任务</p></li><li><p>MLM</p></li><li><p>MFM</p></li><li><p>VTA: 输出层前的视频向量和文本向量mean pool后用infoCSE做对比学习</p></li></ol><p><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1663934859662-ad03421c-eb7b-48e2-bbe3-b0a48a1ffd16.png#clientId=u47c39a7c-ef19-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=385&amp;id=uae51d491&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=770&amp;originWidth=970&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=80080&amp;status=done&amp;style=none&amp;taskId=uc06d7f22-ea83-4bf8-b475-e48d6ef653a&amp;title=&amp;width=485" alt="image.png" /> <a name="UvR1C"></a> ## 其他技巧</p><ol type="1"><li>多任务finetune</li></ol><p>这个队伍finetune时还用了多任务，除了正常的分类头，还给视觉编码器后面添加了一个分类头，还有加了一个对比学习的任务：<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1663959623942-972f9aff-7364-43ed-a5e9-fdd81c6140ed.png#clientId=u47c39a7c-ef19-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=379&amp;id=u33f7d946&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=757&amp;originWidth=750&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=73800&amp;status=done&amp;style=none&amp;taskId=ud967cd6e-b229-4f3a-9cf6-4672d4523a7&amp;title=&amp;width=375" alt="image.png" /><br />具体loss形式为：<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1663959707174-17d4adb1-ee8d-4045-84f7-9db8fc27833a.png#clientId=u47c39a7c-ef19-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=65&amp;id=u3a663643&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=129&amp;originWidth=1854&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=73126&amp;status=done&amp;style=none&amp;taskId=u02446e53-18b3-4582-b8b2-3cec33e937a&amp;title=&amp;width=927" alt="image.png" /></p><ol start="2" type="1"><li><p>训练技巧：EMA, R-drop</p></li><li><p>针对长尾问题，单独训练更强的尾部类别分类器，并进行集成</p></li><li><p>模型加速：TensorRT-FP16加速ViT-B/16 + Torch-FP16加速其他模块，多模型共用视觉特征，并行 <a name="Ms9Ve"></a> ## 亮点</p></li><li><p>多任务finetune，这个居然能取得不错的结果</p></li><li><p>针对长尾问题单独训练分类器 <a name="y8og2"></a> # 5th warriors <a name="HMLEE"></a> ## 模型架构 单流架构，不过针对视频特征和文本特征单独进行mean pooling后再进行一次mean pooling<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1663960085419-374cbdf9-f964-4395-a14f-6aec0e526b08.png#clientId=u47c39a7c-ef19-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=546&amp;id=u2df1793f&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1092&amp;originWidth=1510&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=131280&amp;status=done&amp;style=none&amp;taskId=ucd3b0fb8-d643-4cd2-8466-75348555dcf&amp;title=&amp;width=755" alt="image.png" /> <a name="pkgQv"></a> ## 预训练任务</p></li><li><p>MLM</p></li><li><p>MFM</p></li><li><p>VTA</p></li><li><p>VTM <a name="TBLri"></a> ## 其他技巧</p></li><li><p>使用词粒度的分词方案使得序列变短，处理速度更快，并且和字粒度的方案融合</p></li><li><p>针对类别不均衡对小于200个类别重采样， 对无标签数据打伪标签，根据类别数量进行不均衡采样，加入训练集</p></li><li><p>训练技巧：FGM, label smoothing</p></li><li><p>加速：混合精度训练，Fp16推理 <a name="QHgR1"></a> ## 亮点</p></li><li><p>分别对视频和文本进行mean pooing</p></li><li><p>使用了词粒度的分词方案 <a name="nJmhz"></a> # 6th 蜜度信息 <a name="M9A9S"></a> ## 模型架构 一个单流模型，不过最后时生成了四个pooling送入线性分类层<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1663960515768-1ed8f970-f469-45ca-907e-23878ccf8afa.png#clientId=u47c39a7c-ef19-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=625&amp;id=u0a9d3046&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1250&amp;originWidth=2791&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=473620&amp;status=done&amp;style=none&amp;taskId=u62807e18-888d-4342-8170-4c9048eed3d&amp;title=&amp;width=1395.5" alt="image.png" /><br />一个双流模型:<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1663960585819-8b1f57a6-f9d0-4144-b2d1-8e76a9ba9dbb.png#clientId=u47c39a7c-ef19-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=479&amp;id=u92764a6e&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=957&amp;originWidth=1321&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=99035&amp;status=done&amp;style=none&amp;taskId=u691cb9f3-a5da-43c4-ae30-7d16556c47c&amp;title=&amp;width=660.5" alt="image.png" /><br />这里双流模型和别的选手不同的地方是他们做了很多手工的特征拼接进来，具体包括：</p></li></ol><ul><li>视频第一帧的embedding</li><li>Nextvlad特征</li><li>Netvlad特征</li><li>Netrvlad特征</li><li>Softdbow特征</li><li>Netfv特征</li><li>Bottleneck fusion融合特征</li><li>帧相似度（shift 1 frame）</li><li>帧相似度（shift 2 frame）</li><li>帧相似度（shift 3 frame） <a name="S8lEF"></a> ## 预训练任务</li></ul><ol type="1"><li><p>MLM（单流、双流）</p></li><li><p>VTM（单流）</p></li><li><p>VTA（单流）</p></li><li><p>MFM（双流）</p></li><li><p>First Image Prediction（双流）: 这个是其他选手没有的，他们认为第一张图片很重要，于是加了一个这样的任务，让模型能够还原出第一帧的图片</p></li><li><p>单模态-交叉模态 CLIP（双流）：在交叉模态融合前与融合后，分别做CLIP loss</p></li><li><p>Caption（双流）： 使用融合过的多模态hidden当做encoder output， 来对拼接后的text inputs做解码预测 <a name="OCRul"></a> ## 其他技巧</p></li><li><p>训练技巧：对抗训练（预训练和finetune阶段都用了）</p></li><li><p>概率后处理：具体做法是 1/value_count,每个类别得到一个放大的概率值，大类是1，小类&gt;1</p></li><li><p>模型加速：BF16加速训练，FP16加速推理</p></li><li><p>伪标签 <a name="ZSuRL"></a> ## 亮点</p></li><li><p>加入了很多手工特征，拼接到模型中</p></li><li><p>设计了多种独特的预训练任务</p></li><li><p>后处理 <a name="lBDgU"></a> # 总结 总结一下六个队伍方案的基本都有用到的的东西，抽象出一套有效的方案：</p></li><li><p>模型架构上：单流、双流的各种架构都可以，融合起来更好</p></li><li><p>模型backbone：文本编码器用macbert或roberta，视觉编码器用clip的vit（这个尤为重要，因为是多模态的预训练模型，据说比swin高两个百分点，而且最好用large，冻结训练）</p></li><li><p>预训练任务：MLM、MFM、VTM、VTA等</p></li><li><p>训练技巧：FGM、EMA、Rdrop、label smoothing</p></li><li><p>类别不平衡处理：这个处理方式就多种多样，可以改CE loss的权重，也可以对类别少的样本过采样，从伪标签中生成，也可以后处理类别少的概率、训练单独分类器等</p></li><li><p>伪标签，可以将微调好的模型直接预测作为伪标签加入训练（蜜度信息），也可以用检索的方式投票（冲冲冲），也可以把伪标签当成一种预训练的方式（苟进决赛）</p></li><li><p>加速：tensor RT, FP16推理，并行等</p></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;上周微信大数据挑战赛的决赛结束了，自己之前也投入了不少的时间来做，所以还是需要好好学习一下决赛的方案 &lt;a name=&quot;wCpG0&quot;&gt;&lt;/a&gt; # 赛题介绍&lt;/p&gt;</summary>
    
    
    
    <category term="比赛" scheme="https://lukan217.github.io/categories/%E6%AF%94%E8%B5%9B/"/>
    
    
    <category term="比赛" scheme="https://lukan217.github.io/tags/%E6%AF%94%E8%B5%9B/"/>
    
    <category term="多模态" scheme="https://lukan217.github.io/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/"/>
    
  </entry>
  
  <entry>
    <title>为什么回归任务不能用Dropout</title>
    <link href="https://lukan217.github.io/2022/09/04/%E4%B8%BA%E4%BB%80%E4%B9%88%E5%9B%9E%E5%BD%92%E4%BB%BB%E5%8A%A1%E4%B8%8D%E8%83%BD%E7%94%A8Dropout/"/>
    <id>https://lukan217.github.io/2022/09/04/%E4%B8%BA%E4%BB%80%E4%B9%88%E5%9B%9E%E5%BD%92%E4%BB%BB%E5%8A%A1%E4%B8%8D%E8%83%BD%E7%94%A8Dropout/</id>
    <published>2022-09-04T07:08:23.626Z</published>
    <updated>2022-09-04T19:15:22.286Z</updated>
    
    <content type="html"><![CDATA[<p>最近在做一个nlp的<strong>回归</strong>任务，所以直接套用之前做分类问题的的代码，仅仅修改了下损失函数而已，结果发现验证损失一直在震荡，不收敛，但是别人的代码loss却能够稳定下降，最终下降到0.1左右，而我的只能却一直飘，最终只下降到0.14，如下图：</p><p><br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1662272974970-8d42ea39-ad46-4a2b-80c6-a590879d5b95.png#clientId=u0ab5314d-fcf2-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=251&amp;id=uf2fab61b&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=501&amp;originWidth=759&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=54439&amp;status=done&amp;style=none&amp;taskId=u4ad06981-ab02-40e2-b953-5de213cd5d5&amp;title=&amp;width=379.5" alt="image.png" /><br />最后通过对比别人的代码，我发现其实就两行代码的差异：<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1662273323938-f8c72690-18ee-45cb-afc8-91e0b5155683.png#clientId=u0ab5314d-fcf2-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=138&amp;id=ud7efc1fa&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=276&amp;originWidth=1315&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=54806&amp;status=done&amp;style=none&amp;taskId=u34879997-b2f6-4a3f-b37e-4206d995568&amp;title=&amp;width=657.5" alt="image.png" /><br />这边把bert内部的dropout全部关掉了，于是我也尝试了这种做法，最终得到这样的一个loss，对比一下，这个loss下降就很平稳了，而且最小值明显低很多<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1662272997572-f29d9213-3e21-403b-97b6-c42f1a69f32d.png#clientId=u0ab5314d-fcf2-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=258&amp;id=u8109820d&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=515&amp;originWidth=742&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=54691&amp;status=done&amp;style=none&amp;taskId=u3fba8b4d-826f-4daf-9810-4adbaf2e4f4&amp;title=&amp;width=371" alt="image.png" /></p><p>很神奇是不是，按照之前学的，dropout相当于ensemble，按理应该是能够防止过拟合，增加模型稳健性的，怎么到了我这里，用了dropout反而性能损失这么大？<br />于是我在讨论区发了个帖子问了一下，有个大佬给了我回复：<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1662266884608-46ab4f0b-7db7-4a46-8f52-4a45e7e4954f.png#clientId=u0ab5314d-fcf2-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=367&amp;id=ud1ea06fe&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=734&amp;originWidth=2175&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=236061&amp;status=done&amp;style=none&amp;taskId=u0a888409-7725-4787-80f1-c190fe0d66a&amp;title=&amp;width=1087.5" alt="image.png" /><br />通过阅读他给出的两个链接（见文末链接），我终于明白了问题的根源，总结一下，我做的这个是回归任务，回归任务是不能用dropout的，接下来结合我自己的理解阐述一下为什么。<br />首先回顾一下dropout的用法：<br />dropout在训练时会把以<span class="math inline">\(p\)</span>的概率将隐藏层的神经元置为零，同时会将其他神经元乘以<span class="math inline">\(\frac{1}{1-p}\)</span>，保证输出值期望的一致性，即<br /><span class="math inline">\(h^{\prime}= \begin{cases}0 &amp; \text { 概率为 } p \\ \frac{h}{1-p} &amp; \text { 其他情况 }\end{cases}\)</span><br />接下来我们来推导一下dropout输出值的均值和方差（这里是为了推出经过dropout层后方差发生了变化）<br />这里为了方便计算，我们把dropout代表的随机变量单独拿出来，假设<span class="math inline">\(d\)</span>为一个服从二项分布的随机变量（<span class="math inline">\(p\)</span>的概率取0，<span class="math inline">\(1-p\)</span>的概率取1），则根据二项分布的公式，<span class="math inline">\(d\)</span>的均值为<span class="math inline">\(1-p\)</span>, 方差为<span class="math inline">\(p(1-p)\)</span>, 假设原来的隐藏层为随机变量<span class="math inline">\(h\)</span>,则经过dropout后可以用如下公式表示：<br /><span class="math inline">\(h&#39; = \frac{1}{1-p} dh\)</span><br />接下来来计算下这个东西的均值和方差：<br />首先是均值：<br /><span class="math inline">\(E(h&#39;) = \frac{1}{1-p}\times (1-p)\times \mu_h = \mu_h\)</span><br />可以发现均值是没有发生变化的<br />然后是方差，这里直接套用计算两个随机变量相乘后方差的公式：<br /> <span class="math inline">\(D(h&#39;) =\frac{1}{(1-p)^2}\times E(d^2)E(h^2) - \frac{1}{(1-p)^2} (E(d)E(h))^2 = \frac{1}{1-p}(\mu_h^2+\sigma_h^2)-\mu_h^2\)</span><br />可以发现，经过dropout之后，输出的均值没有发生变化，但是方差发生了变化。<br />由于经过dropout的输出还要经过非线性层（比如Linear层+ReLU），非线性层可以理解为把它输入的一个分布转换成另外一个分布（ReLU就是把小于0部分全砍掉了），那它输出的均值就可以表示为一个关于dropout层输出均值和方差的一个函数，虽然在测试时，dropout层输出的均值没有发生改变，但是方差发生了变化，这个变化就会导致非线性层输出的均值发生偏移，最终导致整个网络的输出值发生偏移。<br />也就是说，<strong>如果使用了dropout，在训练时隐藏层神经元的输出的方差会与验证时输出的方差不一致，这个方差的变化在经过非线性层的映射之后会导致输出值发生偏移，最终导致了在验证集上的效果很差。</strong><br />由于回归问题输出是一个绝对值，对这种变化就很敏感，但是分类问题输出只是一个相对的logit，对这种变化就没那么敏感，因此，在回归问题上最好不要用dropout，而在分类问题上才用dropout，后面查了下发现也有一篇论文的实验佐证了这一观点：<a href="https://www.researchgate.net/publication/344274687_Effect_of_Dropout_Layer_on_Classical_Regression_Problems">(PDF) Effect of Dropout Layer on Classical Regression Problems</a><br />不过，根据上面的分析，其实dropout最好是不要加在网络的中间，在最后输出层前面加应该还是没问题的，根据我自己的实验来看，dropout加在最后一层是没有观察到明显的性能损失的，但是也没有提高就是了，因此，回归任务干脆就别用dropout了。</p><h1 id="参考">参考</h1><ol type="1"><li><a href="https://towardsdatascience.com/pitfalls-with-dropout-and-batchnorm-in-regression-problems-39e02ce08e4d">Pitfalls with Dropout and BatchNorm in regression problems | by Søren Rasmussen | Towards Data Science</a></li><li><a href="https://www.kaggle.com/competitions/commonlitreadabilityprize/discussion/260729">The Magic of No Dropout | Kaggle</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近在做一个nlp的&lt;strong&gt;回归&lt;/strong&gt;任务，所以直接套用之前做分类问题的的代码，仅仅修改了下损失函数而已，结果发现验证损失一直在震荡，不收敛，但是别人的代码loss却能够稳定下降，最终下降到0.1左右，而我的只能却一直飘，最终只下降到0.14，如下图：&lt;/p&gt;</summary>
    
    
    
    <category term="深度学习" scheme="https://lukan217.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="https://lukan217.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Transformers的性能优化方法</title>
    <link href="https://lukan217.github.io/2022/08/19/Transformers%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/"/>
    <id>https://lukan217.github.io/2022/08/19/Transformers%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/</id>
    <published>2022-08-19T01:45:50.876Z</published>
    <updated>2022-08-19T01:48:16.882Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言">前言</h1><p>自BERT出现以来，nlp领域已经进入了大模型的时代，大模型虽然效果好，但是毕竟不是人人都有着丰富的GPU资源，在训练时往往就捉襟见肘，出现显存out of memory的问题，或者训练时间非常非常的久，因此，这篇文章主要解决的问题就是如何在GPU资源受限的情况下训练transformers库上面的大模型。<br />这篇文章源自<span class="citation" data-cites="Vadim">[@Vadim Irtlach]</span>(https://www.kaggle.com/vad13irt)大佬在kaggle的<a href="https://www.kaggle.com/code/vad13irt/optimization-approaches-for-transformers/notebook">开源notebook</a>，感谢原作者的分享，本nlp小白觉得受益良多，因此搬运到知乎分享给大家，已取得作者授权，大部分内容是照搬翻译过来的，小部分内容结合自己的理解进行了补充和修改，不对的地方请大家批评指正，正文开始！</p><hr /><p>尽管Huggingface开源的Transformers在自然语言处理（NLP）任务中取得了惊人的成功，但由于里面的模型参数数量庞大，即使是使用GPU进行训练或者部署，也仍具有非常大的挑战性，因为用如此大的模型进行训练或推理，会很容易发生显存不足（OOM）以及训练时间过长的问题。（这里想吐槽一句的是，kaggle上面的nlp比赛现在动不动就用五折debert-large-v3，没几块V100根本玩不起这种比赛，所以这篇文章对我这种只能用colab的p100来跑实验的穷学生来说真的是福音啊！）<br />然而，有很多方法可以避免显存不足以及训练时间过长的方法，这篇文章的主要贡献就是介绍了这些方法的原理以及如何实现，具体包括以下几种方法：</p><ol type="1"><li>梯度累积（Gradient Accumulation）</li><li>冻结（Freezing）</li><li>自动混合精度（Automatic Mixed Precision）</li><li>8位优化器（8-bit Optimizers）</li><li>梯度检查点（Gradient Checkpointing）</li><li>快速分词器（Fast Tokenizers）</li><li>动态填充（Dynamic Padding）</li><li>均匀动态填充（Uniform Dynamic Padding）</li></ol><p>其中1-5是神经网络通用的方法，可以用在任何网络的性能优化上，6-8是针对nlp领域的性能优化方法。</p><h1 id="梯度累积">梯度累积</h1><p>梯度累积背后的想法非常简单，就是为了模拟更大的批量（batch）。有时，为了更好地收敛或提高性能，需要使用大批量进行训练，但是，这通常需要更大的显存。这个问题的一种可能的解决方案是使用较小的批量，但是，一方面，小批量训练会增加训练和推理时间，另一方面，梯度下降算法对批量大小的选择非常敏感，小批量可能会导致不稳定的收敛和性能降低。所以，我们可以先执行几次前向传播和反向传播，使得梯度进行累积，当我们有足够的计算梯度时，再对参数进行优化，从而利用小显存，模拟大批量的效果，并且训练时间也不会大幅增加。<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1660620493927-e9036332-e9f7-4f8c-b197-cef9a4957a11.png#clientId=u95242c66-2c25-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u13064602&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=998&amp;originWidth=1400&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=135231&amp;status=done&amp;style=none&amp;taskId=u76579be5-a79c-47e5-906d-00a8b32b705&amp;title=" alt="image.png" /></p><h2 id="代码实现">代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">steps = <span class="built_in">len</span>(loader)</span><br><span class="line"></span><br><span class="line"><span class="comment"># perform validation loop each `validation_steps` training steps!</span></span><br><span class="line">validation_steps = <span class="built_in">int</span>(validation_steps * gradient_accumulation_steps)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> step, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader, <span class="number">1</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># prepare inputs and targets for the model and loss function respectively.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># forward pass</span></span><br><span class="line">    outputs = model(inputs)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># computing loss</span></span><br><span class="line">    loss = loss_fn(outputs, targets)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># accumulating gradients over steps</span></span><br><span class="line">    <span class="keyword">if</span> gradient_accumulation_steps &gt; <span class="number">1</span>:</span><br><span class="line">        loss = loss / gradient_accumulation_steps</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># perform optimization step after certain number of accumulating steps and at the end of epoch</span></span><br><span class="line">    <span class="keyword">if</span> step % gradient_accumulation_steps == <span class="number">0</span> <span class="keyword">or</span> step == steps:</span><br><span class="line">        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)</span><br><span class="line">        optimizer.step()</span><br><span class="line">        model.zero_grad()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># perform validation loop</span></span><br><span class="line">    <span class="keyword">if</span> step % validation_steps == <span class="number">0</span>:</span><br><span class="line">        validation_loop()</span><br></pre></td></tr></table></figure><h1 id="冻结">冻结</h1><p>冻结是一种非常有效的方法，通过取消计算模型某些层中的梯度计算（如embedding层，bert的前几层），可以大大加快训练速度并且降低了显存占用，而且几乎不会损失模型的性能。<br />深度学习中的一个众所周知的事实是，网络的底层学习输入数据的通用特征，而网络顶层学习目标任务特定的高级特征，所以在对预训练模型进行微调时，一般网络底层的参数都不怎么需要变，这些都是通用的知识，需要学习的是顶层的那些参数，当使用某种优化算法（如SGD、AdamW或RMSprop）执行优化步骤时，网络的底层的梯度就都很小，因此参数几乎保持不变，这也被称为梯度消失，因此，与其花费大量的时间和算力来计算底层这些“无用”梯度，并对此类梯度很小的参数进行优化，不如直接冻结它们，直接不计算梯度也不进行优化。<br />PyTorch为关闭梯度计算提供了一个舒适的API，可以通过<code>torch.Tensor</code>的属性<code>requires_ grad</code>设置。</p><h2 id="代码实现-1">代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">freeze</span>(<span class="params">module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Freezes module&#x27;s parameters.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> parameter <span class="keyword">in</span> module.parameters():</span><br><span class="line">        parameter.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_freezed_parameters</span>(<span class="params">module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Returns names of freezed parameters of the given module.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    freezed_parameters = []</span><br><span class="line">    <span class="keyword">for</span> name, parameter <span class="keyword">in</span> module.named_parameters():</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> parameter.requires_grad:</span><br><span class="line">            freezed_parameters.append(name)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> freezed_parameters</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoConfig, AutoModel</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># initializing model</span></span><br><span class="line">model_path = <span class="string">&quot;microsoft/deberta-v3-base&quot;</span></span><br><span class="line">config = AutoConfig.from_pretrained(model_path)</span><br><span class="line">model = AutoModel.from_pretrained(model_path, config=config)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># freezing embeddings and first 2 layers of encoder</span></span><br><span class="line">freeze(model.embeddings)</span><br><span class="line">freeze(model.encoder.layer[:<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">freezed_parameters = get_freezed_parameters(model)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Freezed parameters: <span class="subst">&#123;freezed_parameters&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># selecting parameters, which requires gradients and initializing optimizer</span></span><br><span class="line">model_parameters = <span class="built_in">filter</span>(<span class="keyword">lambda</span> parameter: parameter.requires_grad, model.parameters())</span><br><span class="line">optimizer = torch.optim.AdamW(params=model_parameters, lr=<span class="number">2e-5</span>, weight_decay=<span class="number">0.0</span>)</span><br></pre></td></tr></table></figure><h1 id="自动混合精度">自动混合精度</h1><p>自动混合精度（AMP）是另一种在不损失最终质量的情况下减少显存消耗和训练时间的方法，该方法由NVIDIA和百度研究人员在2017年的<a href="https://arxiv.org/abs/1710.03740">"Mixed Precision Training"</a>论文中提出。该方法背后的关键思想是使用较低的精度将模型的梯度和参数保留在内存中，即不使用全精度（float32），而是使用半精度（例如float16）将张量保存在内存中。然而，当以较低精度计算梯度时，某些值可能太小，以至于被视为零，这种现象被称为“溢出”。为了防止“溢出”，原始论文的作者提出了一种梯度缩放方法。<br />PyTorch从1.6的版本开始提供了一个包：<code>torch.cuda.amp</code>，具有使用自动混合精度所需的功能（从降低精度到梯度缩放），自动混合精度作为上下文管理器实现，因此可以随时随地的插入到训练和推理脚本中。<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1660620741318-d97b8b39-dbb2-4147-b649-3a0276578385.png#clientId=u95242c66-2c25-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u98636977&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=711&amp;originWidth=1512&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=244947&amp;status=done&amp;style=none&amp;taskId=ub87efba5-33dd-4317-8b04-f6461940227&amp;title=" alt="image.png" /></p><h2 id="代码实现-2">代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.cuda.amp <span class="keyword">import</span> autocast, GradScaler</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">scaler = GradScaler()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> step, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader, <span class="number">1</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># prepare inputs and targets for the model and loss function respectively.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># forward pass with `autocast` context manager</span></span><br><span class="line">    <span class="keyword">with</span> autocast(enabled=<span class="literal">True</span>):</span><br><span class="line">        outputs = model(inputs)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># computing loss</span></span><br><span class="line">    loss = loss_fn(outputs, targets)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># scale gradint and perform backward pass</span></span><br><span class="line">    scaler.scale(loss).backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># before gradient clipping the optimizer parameters must be unscaled.</span></span><br><span class="line">    scaler.unscale_(optimizer)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># perform optimization step</span></span><br><span class="line">    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)</span><br><span class="line"></span><br><span class="line">    scaler.step(optimizer)</span><br><span class="line">    scaler.update()</span><br></pre></td></tr></table></figure><h1 id="bit-optimizers">8-bit Optimizers</h1><p>8-bit Optimizers的思想类似于自动混合精度（模型的参数和梯度使用较低的精度保存），但8-bit Optimizers还让优化器的状态使用低精度保存。作者（Meta Research）在最初的论文<a href="https://arxiv.org/abs/2110.02861">"8-bit Optimizers via Block-wise Quantization"</a>中详细介绍了8-bit Optimizers，表明8-bit Optimizers显著降低了显存占用，略微加快了训练速度。此外，作者研究了不同超参数设置的影响，表明8-bit Optimizers对不同的学习率、beta和权重衰减参数的效果是稳定的，不会降低性能或影响收敛性。因此，作者为8位优化器提供了一个高级库，叫做<a href="https://github.com/facebookresearch/bitsandbytes">bitsandbytes</a>。<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1660804734860-c3a9d710-3d76-497f-8a44-3637278eb344.png#clientId=ua760d25a-e986-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=490&amp;id=u5caea8f7&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=979&amp;originWidth=1365&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=347195&amp;status=done&amp;style=none&amp;taskId=uc97d0d51-2866-4af1-a7b1-7683d0384c8&amp;title=&amp;width=682.5" alt="image.png" /></p><h2 id="代码实现-3">代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install -q bitsandbytes-cuda110</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_embedding_parameters_bits</span>(<span class="params">embeddings_path, optim_bits=<span class="number">32</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    embedding_types = (<span class="string">&quot;word&quot;</span>, <span class="string">&quot;position&quot;</span>, <span class="string">&quot;token_type&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> embedding_type <span class="keyword">in</span> embedding_types:</span><br><span class="line">        attr_name = <span class="string">f&quot;<span class="subst">&#123;embedding_type&#125;</span>_embeddings&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(embeddings_path, attr_name): </span><br><span class="line">            bnb.optim.GlobalOptimManager.get_instance().register_module_override(</span><br><span class="line">                <span class="built_in">getattr</span>(embeddings_path, attr_name), <span class="string">&#x27;weight&#x27;</span>, &#123;<span class="string">&#x27;optim_bits&#x27;</span>: optim_bits&#125;</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> bitsandbytes <span class="keyword">as</span> bnb</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># selecting parameters, which requires gradients</span></span><br><span class="line">model_parameters = <span class="built_in">filter</span>(<span class="keyword">lambda</span> parameter: parameter.requires_grad, model.parameters())</span><br><span class="line"></span><br><span class="line"><span class="comment"># initializing optimizer </span></span><br><span class="line">bnb_optimizer = bnb.optim.AdamW(params=model_parameters, lr=<span class="number">2e-5</span>, weight_decay=<span class="number">0.0</span>, optim_bits=<span class="number">8</span>)</span><br><span class="line"><span class="comment"># bnb_optimizer = bnb.optim.AdamW8bit(params=model_parameters, lr=2e-5, weight_decay=0.0) # equivalent to the above line</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># setting embeddings parameters</span></span><br><span class="line">set_embedding_parameters_bits(embeddings_path=model.embeddings)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;8-bit Optimizer:\n\n<span class="subst">&#123;bnb_optimizer&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h1 id="梯度检查点">梯度检查点</h1><p>有时候，即使用了上面的几种方法，显存可能还是不够，尤其是在模型足够大的情况下。那么梯度检查点（Gradient Checkpointing）就是压箱底的招数了，这个方法第一次在 <a href="https://arxiv.org/abs/1604.06174">"Training Deep Nets With Sublinear Memory Cost"</a> ，作者表明梯度检查点可以显著降低显存利用率，从<span class="math inline">\(O(n)\)</span>降低到<span class="math inline">\(O(\sqrt n)\)</span>，其中n是模型的层数。这种方法允许在单个GPU上训练大型模型，或者提供更多内存以增加批量大小，从而更好更快地收敛。梯度检查点背后的思想是在小数据块中计算梯度，同时在正向和反向传播过程中从内存中移除不必要的梯度，从而降低内存利用率，但是这种方法需要更多的计算步骤来再现整个反向传播图，其实就是一种用时间来换空间的方法。<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1660805746716-029ea553-21a5-4eeb-8488-988eba2d47df.png#clientId=ua760d25a-e986-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=drop&amp;id=u21665c21&amp;margin=%5Bobject%20Object%5D&amp;name=0_nMSeZxl6ppnrivgv_.png&amp;originHeight=730&amp;originWidth=1400&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=107465&amp;status=done&amp;style=none&amp;taskId=ua39d3d57-9858-41c6-8671-e8d98f729b4&amp;title=" alt="0_nMSeZxl6ppnrivgv_.png" /></p><p><img src="https://cdn.nlark.com/yuque/0/2022/gif/764062/1660805738813-5c578b58-806f-406b-a280-78d35db405fc.gif#clientId=ua760d25a-e986-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=drop&amp;id=u532bec1a&amp;margin=%5Bobject%20Object%5D&amp;name=0_s7U1QDfSXuVd1LrF_.gif&amp;originHeight=121&amp;originWidth=541&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=true&amp;size=309943&amp;status=done&amp;style=none&amp;taskId=u967c6883-a688-4a8a-8dd9-1a15a4dc3a7&amp;title=%E6%BC%94%E7%A4%BA%E6%A2%AF%E5%BA%A6%E6%A3%80%E6%9F%A5%E7%82%B9%E5%A6%82%E4%BD%95%E5%9C%A8%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%B7%A5%E4%BD%9C" title="演示梯度检查点如何在正向和反向传播过程中工作" alt="0_s7U1QDfSXuVd1LrF_.gif" /><br />PyTorch框架里也有梯度检查点的实现，通过这两个函数：<code>torch.utils.checkpoint.checkpoint</code>和<code>torch.utils.checkpoint.checkpoint_sequential</code><br />这边引用一段torch官网对梯度检查点的介绍：</p><blockquote><p>梯度检查点通过用计算换取内存来工作。检查点部分不是存储整个计算图的所有中间激活以进行反向计算，而是不保存中间激活，而是在反向过程中重新计算它们。它可以应用于模型的任何部分。 具体而言，在前向传播中，该函数将以torch.no_grad()的方式运行，即不存储中间激活。然而，前向传播保存了输入元组和函数参数。在反向传播时，检索保存的输入和函数，然后再次对函数进行前向传播，现在跟踪中间激活，然后使用这些激活值计算梯度。</p></blockquote><p>此外，HuggingFace Transformers也支持梯度检查点。梯度检查点可以通过PreTrainedModel实例的gradient_checkpointing_enable方法执行，一行代码直接搞定！</p><h2 id="代码实现-4">代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoConfig, AutoModel</span><br><span class="line"><span class="comment"># https://github.com/huggingface/transformers/issues/9919</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.checkpoint <span class="keyword">import</span> checkpoint</span><br><span class="line"></span><br><span class="line"><span class="comment"># initializing model</span></span><br><span class="line">model_path = <span class="string">&quot;microsoft/deberta-v3-base&quot;</span></span><br><span class="line">config = AutoConfig.from_pretrained(model_path)</span><br><span class="line">model = AutoModel.from_pretrained(model_path, config=config)</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient checkpointing</span></span><br><span class="line">model.gradient_checkpointing_enable()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Gradient Checkpointing: <span class="subst">&#123;model.is_gradient_checkpointing&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h1 id="快速分词器">快速分词器</h1><p>HuggingFace Transformers提供两种类型的分词器：基本分词器和快速分词器。它们之间的主要区别在于，快速分词器是在Rust上编写的，因为Python在循环中非常慢，但在分词的时候又要用到循环。快速分词器是一种非常简单的方法，允许我们在分词的时候获得额外的加速。要使用快速分词器也很简单，只要把<a href="https://huggingface.co/docs/transformers/v4.19.3/en/model_doc/auto#transformers.AutoTokenizer">transformers.AutoTokenizer</a> 里面的<a href="https://huggingface.co/docs/transformers/v4.19.3/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained">from_pretrained</a>方法的<code>use_fast</code>的值修改为True就可以了。<br /><img src="https://cdn.nlark.com/yuque/0/2022/svg/764062/1660807996929-7d3dd145-9e93-407e-a30c-25b13431b15b.svg#clientId=ua760d25a-e986-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u7912c397&amp;margin=%5Bobject%20Object%5D&amp;originHeight=1276&amp;originWidth=1776&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=true&amp;status=done&amp;style=none&amp;taskId=uc1ee8d1c-28f5-4757-9c5a-8f6976a03ed&amp;title=%E5%88%86%E8%AF%8D%E5%99%A8%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84" title="分词器是如何工作的" alt="分词器是如何工作的" /></p><h2 id="代码实现-5">代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># initializing Base version of Tokenizer</span></span><br><span class="line">model_path = <span class="string">&quot;microsoft/deberta-v3-base&quot;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Base version Tokenizer:\n\n<span class="subst">&#123;tokenizer&#125;</span>&quot;</span>, end=<span class="string">&quot;\n&quot;</span>*<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># initializing Fast version of Tokenizer</span></span><br><span class="line">fast_tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Fast version Tokenizer:\n\n<span class="subst">&#123;fast_tokenizer&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h1 id="动态填充">动态填充</h1><p>通常来说，模型是用批量数据输入训练的，批中的每个输入必须具有固定大小，即一批量的数据必须是矩阵的表示，所有批量数据的尺寸都一样。固定尺寸通常是根据数据集中的长度分布、特征数量和其他因素来选择的。在NLP任务中，输入大小称为文本长度，或者最大长度（max length）。然而，不同的文本具有不同的长度，为了处理这种情况，研究人员提出了填充标记和截断。当最大长度小于输入文本的长度时，会使用截断，因此会删除一些标记。当输入文本的长度小于最大长度时，会将填充标记，比如[PAD]，添加到输入文本的末尾，值得注意的是，填充标记不应包含在某些任务的损失计算中（例如掩蔽语言建模或命名实体识别）<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1660809140323-9d6e9dc1-296f-4a0b-b311-e8b9d817a936.png#clientId=ua760d25a-e986-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=drop&amp;id=udb05c024&amp;margin=%5Bobject%20Object%5D&amp;name=fixed_padding_length.png&amp;originHeight=580&amp;originWidth=1581&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=true&amp;size=114729&amp;status=done&amp;style=none&amp;taskId=uf50757a8-36d6-4b19-a2d9-87f7b181e13&amp;title=%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%A1%AB%E5%85%85" title="固定长度填充" alt="fixed_padding_length.png" /><br />然而，填充标记有明显的缺点。比如在输入文本相对于选定的最大长度非常短的情况下，效率就很低，需要更多的额外内存，比如我有一条文本长度512，然后其他文本长度都在10左右，那么如果将max seq设置为512，就会导致很多无效计算。为了防止额外的计算操作，研究人员提出了一种非常有效的方法，就是将批量的输入填充到这一批量的最大输入长度，如下图所示，这种方法可以将训练速度提高35%甚至50%，当然这种方法加速的效果取决于批量的大小以及文本长度的分布，批量越小，加速效果越明显，文本长度分布越不均，加速效果也越好。<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1660809160291-199358bc-6c29-4aca-b82e-1f5ca4b1d5d8.png#clientId=ua760d25a-e986-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=drop&amp;id=u8b70e8fd&amp;margin=%5Bobject%20Object%5D&amp;name=dynamic_padding.png&amp;originHeight=577&amp;originWidth=1582&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=true&amp;size=107538&amp;status=done&amp;style=none&amp;taskId=u597d4c1c-1d38-40d6-844d-45ec13aa727&amp;title=%E5%8A%A8%E6%80%81%E5%A1%AB%E5%85%85" title="动态填充" alt="dynamic_padding.png" /></p><h1 id="均匀动态填充">均匀动态填充</h1><p>还有一种基于动态填充的方法，叫做均匀动态填充。其思想是在分batch时，先按文本的长度对文本进行排序，这样同一个batch里面的文本长度就都差不多。这种方法非常有效，在训练或推理期间的计算量都比动态填充要来的少。但是，不建议在训练期间使用均匀动态填充，因为训练时数据最好是要shuffer的，但是推理时如果一次性要推理很多文本的话可以考虑这么做</p><figure><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1660814142931-1222a4b1-82ad-4816-a313-8ef565a5f1bb.png#clientId=ua760d25a-e986-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=drop&amp;id=u04146ac5&amp;margin=%5Bobject%20Object%5D&amp;name=uniform_length_batching.png&amp;originHeight=585&amp;originWidth=1592&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=true&amp;size=101412&amp;status=done&amp;style=none&amp;taskId=u939a8674-40c3-4a4d-9643-629ab22e05f&amp;title=%E5%9D%87%E5%8C%80%E5%8A%A8%E6%80%81%E5%A1%AB%E5%85%85" title="均匀动态填充" alt="uniform_length_batching.png" /><figcaption aria-hidden="true">uniform_length_batching.png</figcaption></figure><h1 id="总结">总结</h1><p>即使在现代GPU上，优化内存和时间也是开发模型的必要步骤，因此，本文介绍了加速训练和减少transformers等大型模型内存消耗的最强大、最流行的方法。</p><h1 id="参考">参考</h1><ol type="1"><li><a href="https://huggingface.co/docs/transformers/performance">Performance and Scalability: How To Fit a Bigger Model and Train It Faster</a></li><li><a href="https://www.kaggle.com/code/rhtsingh/speeding-up-transformer-w-optimization-strategies">Speeding up Transformer w/ Optimization Strategies</a></li><li><a href="https://www.kaggle.com/competitions/AI4Code/discussion/327777">Things you can try to speed up training speed and preventing memory shortage if you are using transformers.</a></li><li><a href="https://www.kaggle.com/competitions/feedback-prize-2021/discussion/303131">8-bit Adam and other memory optimizations</a></li><li><a href="https://medium.com/tensorflow/fitting-larger-networks-into-memory-583e3c758ff9">Fitting larger networks into memory.</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;前言&lt;/h1&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://lukan217.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="nlp" scheme="https://lukan217.github.io/tags/nlp/"/>
    
  </entry>
  
  <entry>
    <title>时间序列的区间预测/概率预测</title>
    <link href="https://lukan217.github.io/2022/08/17/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E7%9A%84%E5%8C%BA%E9%97%B4%E9%A2%84%E6%B5%8B_%E6%A6%82%E7%8E%87%E9%A2%84%E6%B5%8B/"/>
    <id>https://lukan217.github.io/2022/08/17/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E7%9A%84%E5%8C%BA%E9%97%B4%E9%A2%84%E6%B5%8B_%E6%A6%82%E7%8E%87%E9%A2%84%E6%B5%8B/</id>
    <published>2022-08-16T17:57:01.824Z</published>
    <updated>2022-08-16T18:05:47.287Z</updated>
    
    <content type="html"><![CDATA[<p>一般我们做时间序列预测都是做点预测（point forecasting），很少会去考虑区间预测（interval forecasting），或者概率预测（probabilistic forecasting），但实际上区间预测也是很重要的，具体来说有这三方面的作用：</p><ol type="1"><li>刻画不确定性以应对风险，预测都是服务于决策，那么在决策时就必然要考虑到可能的风险，也就是最好的情况和最坏的情况，因此就需要使用区间预测来描述预测值可能的上下限</li><li>特定场景下的用处，比如供应链中的库存管理模型，使用区间预测/概率预测可以用来最优化补货量，如果需要满足95%的服务水平，那么就可以输出95%分位数下对应的销量预测值来作为补货量</li><li>好看，业务方和老板在看你预测结果时，如果只有一条干巴巴的曲线是不好说服他们的，毕竟预测就是个玄学，那就整一些花里胡哨的的，比如加个区间，这样他们看着就很开心了（）</li></ol><p><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1660099121338-60770410-fc82-4fa4-806a-5131f66769b8.png#clientId=u6d0bf445-93be-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u3b9790df&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=433&amp;originWidth=603&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=93491&amp;status=done&amp;style=none&amp;taskId=u69c564d1-67c8-4b3c-b8f4-17b9e5e996e&amp;title=" alt="image.png" /><br />目前关于时间序列区间预测的方法似乎还没有一个系统性的总结，这里我就把自己调研看到的几种方法整理出来，根据我的分类，区间预测具体可以分为两类方法：</p><ol type="1"><li><p>统计学方法，使用统计学上的一些方法来估计区间</p></li><li><p>损失函数法，通过定义特定的损失函数来输出区间</p></li></ol><h1 id="统计学方法">统计学方法</h1><h2 id="区间估计法">区间估计法</h2><p>学过统计学的都会知道区间估计，要估计一个值的区间，首先会假设它服从正态分布，进一步再计算出这个值的估计标准差，然后给定某个置信度，比如95%，查表就可以得到Z值为1.96，那么就可以把Z值乘上标准差，再用均值加减一下，就可以得到区间的左端和右端。<br />区间预测也用到的同样的思路，但是在区间预测里，我们并不会假设预测值服从正态分布，而是假设误差服从正态分布，然后估计出误差的上下限，再把他加到预测值里面，就可以得到预测值的上下限了，具体来说，步骤如下：</p><ol type="1"><li><p>假设预测误差服从均值为0的正态分布，估计预测误差的标准差</p></li><li><p>给定置信度，查表得到Z值</p></li><li><p>计算预测误差的上限和下限</p></li><li><p>将上下限加到预测值里面，得到一个预测区间</p></li></ol><p><span class="math inline">\(\hat{y}_{T+h \mid T} \pm k \hat{\sigma}_{h}\)</span><br />但是，怎么得到预测误差的标准差呢？很多传统统计学的预测方法都是直接用训练误差的标准差，也有了很多成熟的估计方法，但是由于训练数据上是过拟合的，会导致这个标准差比较小，就导致最后出来的预测区间也比较小，所以，比较合理的做法是在训练数据集上先划分出一个验证集，然后使用验证集上的预测误差来估计标准差。 <a name="lPNfh"></a></p><h2 id="bootstrap">Bootstrap</h2><p>bootstrap，也就是自助采样法，这个方法的思路也是先估计出一个误差的上下限，然后把这个上下限加到原来的预测值中，进而得到预测区间，不过，bootstrap不需要假定误差服从正态分布，而是通过采用N次的预测误差，然后取这N次的误差的分位数作为上下限，比如抽样了三次误差，分别为[-50,0,50], 则5%分位数为-45，95%分位数为45，把这个分位数误差加到预测值上就得到了预测区间。<br />参考链接：<a href="https://otexts.com/fppcn/prediction-intervals.html">https://otexts.com/fppcn/prediction-intervals.html</a> <a name="fO0kk"></a></p><h1 id="损失函数">损失函数</h1><p>最近几年，基于深度的时序预测方法也很多，所以也衍生出了一些区间预测的方法，但具体来说都是从损失函数层面来实现的。 <a name="jQRFV"></a></p><h2 id="分位数损失">分位数损失</h2><p>分位数的损失函数形式如下所示：<br /><span class="math inline">\(L_{q}(y, \hat{y})=q(y-\hat{y})_{+}+(1-q)(\hat{y}-y)_{+}\)</span><br />其中，<span class="math inline">\((\cdot)_{+}=\max (0, \cdot)\)</span>.，加号左边那项代表的就是预测值小于真实值的loss，右边那项代表队是预测值大于真实值时的loss，我们通过取不同的q来理解下这个函数：</p><ul><li>当 <span class="math inline">\(q=0.5\)</span>时，两边的权重相等，这个损失函数就和MAE一样</li><li>当<span class="math inline">\(q=0.95\)</span>时，左边那项的loss权重比较大，因此，模型就会尽可能的使得预测值大于真实值，这样才能使得整体的loss小，这就起到了一个拉高预测值的作用，也可以理解为预测区间的上限</li><li>当<span class="math inline">\(q=0.05\)</span>时，这时候就是右边的那项loss权重比较大，因此，模型就会尽可能使得预测值小于真实值，才能保证整体的loss小，这就起到了一个拉低预测值的作用，也可以理解为预测区间的下限</li></ul><p>在实操时，我们一般会指定三个分位数，如（0.1, 0.5, 0.9），把这三个分位数损失加起来作为最终的损失函数，在预测时就可以输出三个值，分别对应：10%的区间预测，点预测以及90%的区间预测，目前很多基于深度学习的时序预测算法都用到了这个损失函数，比如MQRNN/CNN, TFT等，GBDT也可以使用这个损失，像lightgbm和xgboost的objective里面也都有quantile这个选项，也都可以输出区间预测。 <a name="vQtET"></a></p><h2 id="负对数似然损失">负对数似然损失</h2><p>这个思路我最早是在DeepAR那看到的，大概思路是首先指定一个预测值服从的概率分布，如正态分布，然后，使用神经网络模型分别预测这个概率分布的参数，比如正态分布就是预测他的均值和方差，接着构造负对数似然函数作为损失函数，优化这个损失函数就可以到得到概率分布的参数，最后就可以得到预测时每一步的概率分布，知道了概率分布，那么就可以通过蒙特卡洛采样的方式来生成预测值和区间预测了，比如对这个概率分布采样100次，那这100次的均值就是点预测的结果，95%分位数和5%分位数就可以对应区间预测的结果。 # 开源工具包的实现</p><h2 id="gluonts">GluonTS</h2><ol type="1"><li><p>对于自回归模型，通过预测概率分布来实现概率预测</p></li><li><p>对于其他模型，使用分位数回归</p></li></ol><h2 id="darts">Darts</h2><ol start="3" type="1"><li><p>对于传统统计学模型，使用区间估计法进行概率预测</p></li><li><p>对于部分深度学习模型，使用负对数似然损失</p></li></ol><h2 id="mapie">MAPIE</h2><p>这是一个专门用来做区间预测的包，基于sklearn接口进行开发的，支持回归、分类、时序回归的区间预测，其中，时序部分的区间预测用了一篇论文（<a href="https://arxiv.org/abs/2010.09107">https://arxiv.org/abs/2010.09107</a>）的算法，叫做EnbPI，号称是一个通用的distribution-free的时序区间预测框架，不需要划分验证集重新训练，原理太复杂没去看，试着跑了下demo有点慢，并且目前这个包只支持sklearn那边的模型。</p><h1 id="总结">总结</h1><p>时间序列的区间预测方法按照我的分类方式大致可以分为两大类，其中，统计学方法通过估计误差的上下限再加到原来的预测值上面进行区间预测，一般在传统统计学模型（ARIMA、指数平滑法等）上应用很多，因为估计误差的方法已经有了非常成熟的公式，很多包也集成了这些区间预测，但应用在其他模型上面可能先需要划分训练集和验证集，估计出误差后再对测试集进行区间预测。</p><p>而损失函数的方法只能用在深度学习和GBDT这些靠优化损失函数来预测的模型，具体可以分为分位数损失和负对数似然损失，分位数损失通过损失函数拉高/拉低预测值来实现区间预测的效果，GBDT和深度学习都能用，而负对数似然损失通过直接预测概率分布，然后采样的方式来实现预测，只能用在深度学习模型上</p><h1 id="参考">参考</h1><ol type="1"><li><p><a href="https://unit8.com/resources/probabilistic-forecasting-in-darts/">Probabilistic Forecasting in Darts - Unit8</a></p></li><li><p><a href="https://towardsdatascience.com/time-series-forecasting-prediction-intervals-360b1bf4b085">Time Series Forecasting: Prediction Intervals | by Brendan Artley | Towards Data Science</a></p></li><li><p><a href="https://otexts.com/fppcn/prediction-intervals.html">3.5 预测区间 | 预测： 方法与实践</a></p></li><li><p><a href="https://arxiv.org/abs/1906.05264">[1906.05264] GluonTS: Probabilistic Time Series Models in Python</a></p></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;一般我们做时间序列预测都是做点预测（point forecasting），很少会去考虑区间预测（interval forecasting），或者概率预测（probabilistic forecasting），但实际上区间预测也是很重要的，具体来说有这三方面的作用：&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://lukan217.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="时间序列" scheme="https://lukan217.github.io/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>code-server搭建指南</title>
    <link href="https://lukan217.github.io/2022/07/10/code-server%E6%90%AD%E5%BB%BA%E6%8C%87%E5%8D%97/"/>
    <id>https://lukan217.github.io/2022/07/10/code-server%E6%90%AD%E5%BB%BA%E6%8C%87%E5%8D%97/</id>
    <published>2022-07-10T10:17:42.730Z</published>
    <updated>2022-07-10T10:24:59.765Z</updated>
    
    <content type="html"><![CDATA[<p>虽然自己之前搞了一台服务器，也在服务器上<a href="https://zhuanlan.zhihu.com/p/384888122">部署了jupyter notebook</a>，但是仍有两个痛点没有解决：</p><ol type="1"><li>服务器部署了一些代码，有时候需要修改，通过vim直接修改是不现实的，因为没有补全高亮，改起来很麻烦，只能本地改好再上传上去</li><li>虽然部署了jupyter，能够实现一些简单的代码编辑需求，但是仅限于ipynb，其他文件无法编辑查看，并且补全功能十分鸡肋</li></ol><p>因此，为了能够在浏览器里面得到和本地编程一样丝滑的体验，最终决定部署一个code-server，也就是web版的vscode，实测体验和本地的vscode没有任何区别，效果如下：<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1657447452075-701b98ea-8435-4da3-b86a-5181aac0797d.png#clientId=u7f73bf32-1eb1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=841&amp;id=u78da3e34&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1262&amp;originWidth=2560&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=83496&amp;status=done&amp;style=none&amp;taskId=ucf3b3635-f4a1-4f4e-ab2c-a5e8c1e0bd3&amp;title=&amp;width=1706.6666666666667" alt="image.png" /></p><p><a name="FavUM"></a></p><h1 id="搭建过程">搭建过程</h1><p><a name="wJ0di"></a></p><h2 id="准备">准备</h2><ol type="1"><li>一台云服务器</li><li>一个经过公安部备案的域名</li></ol><p>为什么要域名呢？因为我经常需要用jupyter notebook，但是这玩意在code-server里面由于安全性的原因需要通过https才能打开，但是通过ip地址是没办法走https的，因此就需要一个域名，而且是要经过备案的，不然没法访问。当然，如果你不需要用到jupyter notebook可以直接跳过这个步骤。<br />具体申请流程如下，以腾讯云为例：</p><ol type="1"><li>购买一个域名：<a href="https://console.cloud.tencent.com/domain">https://console.cloud.tencent.com/domain</a></li><li>为域名备案，走完整套流程大概要2周：<a href="https://console.cloud.tencent.com/beian">https://console.cloud.tencent.com/beian</a></li><li>最后一步，添加DNS解析：<a href="https://console.dnspod.cn/">https://console.dnspod.cn/</a></li></ol><p>主机记录可以填一个前缀，比如code，最后就是通过code.xxx.com来访问，记录值填写服务器公网ip，这样就在浏览器里面输入域名就会自动解析到服务器的地址了<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1657434255367-9c6b978a-c2c9-4976-86d6-8588c85b01d1.png#clientId=u7f73bf32-1eb1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=355&amp;id=u5a4e0ffc&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=533&amp;originWidth=2034&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=93394&amp;status=done&amp;style=none&amp;taskId=uc9c8c788-7296-44dd-bfb1-93ba8620160&amp;title=&amp;width=1356" alt="image.png" /> <a name="BqcT9"></a></p><h2 id="code-server配置">code-server配置</h2><p>完成准备步骤后，就可以配置code-server了，安装步骤也很简单，依次输入以下命令就行了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -fsSL https://code-server.dev/install.sh | sh </span><br></pre></td></tr></table></figure><p>如果上面的命令因为墙的原因下载不了，就只能通过本地下载安装包，传到服务器，再手动安装，这里以ubuntu为例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dpkg -i code-server_4.5.0_amd64.deb</span><br></pre></td></tr></table></figure><p>然后输入命令行输入<code>code-server</code>, 会生成一个本地配置文件，ctrl+C关闭，再去改配置文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.config/code-server/config.yaml</span><br><span class="line">===============</span><br><span class="line">bind-addr: 0.0.0.0:8080 # 如果没域名需要改成这个</span><br><span class="line">auth: password</span><br><span class="line">password: 123456</span><br><span class="line">cert: false</span><br><span class="line">===============</span><br><span class="line">code-server</span><br></pre></td></tr></table></figure><p>这时候浏览器输入：公网ip:8080应该就能访问了 <a name="HBU8I"></a></p><h2 id="配置https访问">配置https访问</h2><p>完成以上的操作，code-server的基本配置就完成了，但是之前说过，这样是不完整的，因为没有域名，并且没有https，很多操作进行不了，所以建立弄一个备案好的域名，然后根据官网给的操作说明，配置nginx和用Let's Encrypt生成证书，依次进行以下操作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装nginx并配置</span></span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install -y nginx certbot python3-certbot-nginx</span><br><span class="line">vim /etc/nginx/sites-available/code-server</span><br><span class="line"><span class="meta">#</span><span class="bash"> 填入以下内容，域名记得改一下</span></span><br><span class="line">===========================================</span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    listen [::]:80;</span><br><span class="line">    server_name mydomain.com;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">      proxy_pass http://localhost:8080/;</span><br><span class="line">      proxy_set_header Host $host;</span><br><span class="line">      proxy_set_header Upgrade $http_upgrade;</span><br><span class="line">      proxy_set_header Connection upgrade;</span><br><span class="line">      proxy_set_header Accept-Encoding gzip;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">============================================</span><br><span class="line">sudo ln -s ../sites-available/code-server /etc/nginx/sites-enabled/code-server</span><br><span class="line"><span class="meta">#</span><span class="bash"> 为域名生成证书，最后那个是你的邮箱</span></span><br><span class="line">sudo certbot --non-interactive --redirect --agree-tos --nginx -d mydomain.com -m me@example.com</span><br></pre></td></tr></table></figure><p><a name="eaemE"></a></p><h2 id="配置守护进程">配置守护进程</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">vim /usr/lib/systemd/system/code-server.service</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输入以下配置</span></span><br><span class="line">=========================</span><br><span class="line">[Unit]</span><br><span class="line">Description=code-server</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=exec</span><br><span class="line">Environment=HOME=/root</span><br><span class="line">ExecStart=/usr/bin/code-server</span><br><span class="line">Restart=always</span><br><span class="line">=========================</span><br><span class="line"><span class="meta">#</span><span class="bash"> 然后就可以通过以下命令来启动和关闭code-server服务了</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> start code-server</span></span><br><span class="line">systemctl start code-server</span><br><span class="line"><span class="meta">#</span><span class="bash"> stop code-server</span></span><br><span class="line">systemctl stop code-server</span><br><span class="line"><span class="meta">#</span><span class="bash"> code-server status</span></span><br><span class="line">systemctl status code-server</span><br></pre></td></tr></table></figure><p>这样就基本配置成功了，之后再根据自己的需要装上插件，换下主题，就完全和本地的vscode没啥区别，可以随时随地在浏览器连接服务器进行编程了！</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;虽然自己之前搞了一台服务器，也在服务器上&lt;a href=&quot;https://zhuanlan.zhihu.com/p/384888122&quot;&gt;部署了jupyter notebook&lt;/a&gt;，但是仍有两个痛点没有解决：&lt;/p&gt;</summary>
    
    
    
    <category term="计算机" scheme="https://lukan217.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"/>
    
    
    <category term="服务器" scheme="https://lukan217.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle HM推荐赛获奖方案总结</title>
    <link href="https://lukan217.github.io/2022/05/14/kaggle%20HM%E6%8E%A8%E8%8D%90%E8%B5%9B%E8%8E%B7%E5%A5%96%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/"/>
    <id>https://lukan217.github.io/2022/05/14/kaggle%20HM%E6%8E%A8%E8%8D%90%E8%B5%9B%E8%8E%B7%E5%A5%96%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/</id>
    <published>2022-05-14T09:39:02.476Z</published>
    <updated>2022-05-14T16:22:13.698Z</updated>
    
    <content type="html"><![CDATA[<p><a name="uOrxS"></a></p><h1 id="st-place-solution">1st place solution</h1><p>文档链接：<a href="https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/discussion/324070">1st place solution</a><br />整体框架：<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1652519977145-990e767f-fd60-4ced-bd79-d24e225fd1a3.png" alt="overview (1).png" /> <a name="agjGv"></a></p><h2 id="召回策略">召回策略</h2><ol type="1"><li>用户上次购买的商品</li><li>Item CF</li><li>属于同个product code的商品</li><li>热门商品</li><li>graph embedding：ProNE</li><li>逻辑回归：训练Logistic回归模型，从前1000个热门商品中检索到50~200个商品</li></ol><p>召回策略一共为每个用户召回了100-500个商品，使用HitNum@100来评估召回策略的质量，尽可能覆盖更多的正样本。 <a name="jbxxm"></a></p><h2 id="特征工程">特征工程</h2><table><colgroup><col style="width: 50%" /><col style="width: 50%" /></colgroup><thead><tr class="header"><th>类型</th><th>描述</th></tr></thead><tbody><tr class="odd"><td>Count</td><td>user-item, user-category of last week/month/season/same week of last year/all, time weighted count…</td></tr><tr class="even"><td>Time</td><td>first,last days of tranactions…</td></tr><tr class="odd"><td>Mean/Max/Min</td><td>aggregation of age,price,sales_channel_id…</td></tr><tr class="even"><td>Difference/Ratio</td><td>difference between age and mean age of who purchased item, ratio of one user's purchased item count and the item's count</td></tr><tr class="odd"><td>Similarity</td><td>item2item的协同过滤分数, item2item(word2vec)的余弦相似度, user2item(ProNE)的余弦相似度</td></tr></tbody></table><p><a name="WKsy0"></a></p><h2 id="排序模型">排序模型</h2><p>5个lightgbm classifier + 7个catboost classifier<br />不同的分类器分别用不同的时间跨度以及召回数量的数据进行训练，如下图所示：<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1652512638734-0abf8e61-2a80-4042-9547-38db5e32de91.png" alt="cv.png" /> <a name="rrbKI"></a></p><h2 id="cv策略">CV策略</h2><p>使用最后一周作为验证集 <a name="rZbAm"></a></p><h2 id="优化技巧">优化技巧</h2><ol type="1"><li>模型推理优化：使用TreeLite 来优化lightgbm推理的速度（快了2倍），caboost-gpu版本比lightgbm-cpu版本快了30倍</li><li>内存优化：类别特征用了labelencoder，并且使用了reduce_mem_usage函数</li><li>特征存储：将创建的特征保存为feather格式，方便使用</li><li>并行：将用户分为28组，在多个服务器上同时进行推理</li><li>机器：128g内存，64核CPU, TITAN RTX GPU（真特么有钱啊！） <a name="WQeOZ"></a></li></ol><h2 id="亮点">亮点</h2><ol type="1"><li><p>使用逻辑回归作为pre-ranker进行召回</p></li><li><p>模型融合，用了12个模型进行融合</p></li><li><p>各种优化技巧 <a name="Q561R"></a></p></li></ol><h1 id="nd-place-solution">2nd place solution</h1><p>文档链接：<a href="https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/discussion/324197">2nd place solution</a> <a name="tfTnq"></a></p><h2 id="召回策略-1">召回策略</h2><ol type="1"><li><p>热门商品，基于不同的维度进行召回：</p><ol type="1"><li>用户属性：如不同年龄、地域购买的热门商品（其中，基于地域postal_code的召回最为显著的提升了分数）</li><li>商品属性：如果用户购买了具有特定属性的商品，会寻找具有相同属性的热门商品</li><li>使用不同的时间窗口：1、3、7、30、90天。</li></ol></li><li><p>用户历史购买过的全部商品</p></li><li><p>使用MobileNet embedding计算的图像相似度及进行召回</p></li><li><p>graph embedding：random walk <a name="xCAkG"></a></p></li></ol><h2 id="特征工程-1">特征工程</h2><ol type="1"><li><p>用户基本特征：包括购买数量、价格、sales_channel_id</p></li><li><p>商品基本特征：根据商品的每个属性进行统计，包括：times, price, age, sales_channel_id, FN, Active, club_member_status, fashion_news_frequency, last purchase time, average purchase interval</p></li><li><p>用户商品组合特征：基于商品每个属性的统计信息，包括：num, time, sales_channel_id, last purchase time, and average purchase interval</p></li><li><p>年龄商品组合特征：每个年龄组的商品受欢迎程度。</p></li><li><p>用户商品回购特征：用户是否会回购商品以及商品是否会被回购</p></li><li><p>高阶组合特征：例如，预测用户下次购买商品的时间</p></li><li><p>相似度特征：通过各种手段计算商品与客户购买的商品的平均相似度 <a name="M5TgH"></a></p></li></ol><h2 id="排序模型-1">排序模型</h2><p>魔改的lightgbm ranker，使用lambdarankmap作为目标函数（从xgboost里面copy的代码），比lightgbm原生的lambdarank目标要好。 <a name="J9f3W"></a></p><h2 id="cv策略-1">cv策略</h2><p>2-3个月作为训练集，最后一周作为测试集。 <a name="GX3mX"></a></p><h2 id="亮点-1">亮点</h2><ol type="1"><li><p>使用MobileNet生成了图像的embedding特征</p></li><li><p>各种高阶特征：用户是否会回购商品以及商品是否会被回购、用户下次购买商品的时间等</p></li><li><p>使用lambdarankmap作为目标函数的lgb ranker <a name="G7QZT"></a></p></li></ol><h1 id="rd-place-solution">3rd place solution</h1><p>文档链接：<a href="https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/discussion/324129">3rd place solution</a><br />作者说他整体建模的套路都和其他人差不多，因此分享了两点他觉得跟别人不同但是有用的东西：</p><ol type="1"><li><p>召回策略特征：这个商品被哪种策略召回，以及被召回时的排名，加上这两个特征，以及将召回的数量从几十增加到上百，将LB分数从0.02855提高到0.03262，直接从银牌区进去了金牌区，此外，如果只增加召回的数量，而不添加增加召回的特征的话，CV分数非常低。</p></li><li><p>BPR 矩阵分解得到的用户-商品相似度特征：用户和商品的相似性特征对排序模型很重要。关于item2item相似性的特征，例如Buyd together计数和word2vec，在大多数竞争对手的模型中都很常用，这些特征也大大提高了我的分数，但最能改善我的模型的是通过BPR矩阵分解获得的user2item相似性。这个BPR模型是在目标周之前（每周训练一个BPR）使用<a href="https://implicit.readthedocs.io/en/latest/bpr.html">implicit</a>训练所有交易数据的。BPR相似性的auc约为0.720，而整个排序模型的auc约为0.806，其他单一特征的最佳auc约为0.680。最后，这个相似性特征将我的LB分数从0.03363提高到了0.03510，这将我从金牌区带到了奖品区。 <a name="fU9mA"></a></p></li></ol><h1 id="th-place-solution">4th place solution</h1><p>文档链接：<a href="https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/discussion/324094">4th place solution</a><br />整体思路：<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1652517925129-614ba42d-e10b-44aa-87ff-980f75d216a0.png" alt="arch.png" /> <a name="qL1xq"></a></p><h2 id="召回策略-2">召回策略</h2><ol type="1"><li>item CF</li><li>最近购买：用户最近购买的12个商品</li><li>热门商品：上周的热门商品</li><li>Two Tower MMoE：作者主要关注这个模型的训练，因为它不仅能够为用户生成任意多的候选商品，还能够创建用户-商品相似度特征，这是模型的架构：</li></ol><p><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1652518291522-78e85301-578d-4bbf-9d28-f7b84a34311a.png" alt="loss.png" /><br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1652518252440-b3e414e8-19fc-4429-ad96-38c68c168fb7.png" alt="item-tower.png" /><br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1652518271421-f86f7bb6-b8d5-409a-9a52-ebd109add659.png" alt="user-tower.png" /><br />对于用户侧的tower，作者还用了一个门控网络，以确保用户塔可以通过使用不同的expert为最近的活跃客户和非活跃客户进行学习。 <a name="ZYVEp"></a></p><h2 id="冷启动">冷启动</h2><ul><li><p>用户冷启动：双塔MMoE可以使用用户基础特征为没有购买日志的用户生成候选商品。</p></li><li><p>商品冷启动：除了商品的基本特征，作者还用了图像和文本的特征</p><ul><li><p>文本：从商品描述中提取TF-IDF特征，使用SVD+K-Means对商品进行聚类。然后使用聚类的label作为特征。</p></li><li><p>图像：使用预训练的tf_efficientnet_b3_ns提取图像向量，使用PCA+K-均值聚类。然后使用聚类的label作为特征。 <a name="eXWZi"></a></p></li></ul></li></ul><h2 id="亮点-2">亮点</h2><ol type="1"><li><p>召回策略用了Two Tower MMoE</p></li><li><p>文本和图像特征用的是embedding过后再进行一次聚类的标签 <a name="BctOx"></a></p></li></ol><h1 id="th-place-solution-1">5th place solution</h1><p>文档链接：<a href="https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/discussion/324098">5th place solution</a> <a name="yjDMN"></a></p><h2 id="召回策略-3">召回策略</h2><ol type="1"><li>用户上一篮子的购买（以及和用户上次购买商品相同product code的商品），最近购买的商品</li><li>User CF</li><li>Item CF</li><li>word2vec</li><li>经常会被一起购买的商品</li><li>根据用户的属性（年龄、性别等）召回的热门商品</li></ol><p>关于召回的数量，作者使用一个正样本的比例作为阈值来控制的，比如把阈值设为0.05的话，然后某个策略召回100个商品，正样本比例为0.01，那么可以召回少一点的商品，比如50个，这样刚好可以使得正样本比例刚好卡在0.05. <a name="EANNj"></a></p><h2 id="embedding方法">Embedding方法</h2><ol type="1"><li><p>商品的图像信息：使用swin transformer来提取embedding</p></li><li><p>商品的文本信息：使用SentenceTransformer提取</p></li><li><p>tf-idf获取商品的embedding</p></li><li><p>word2vec获取商品的embedding <a name="V67L5"></a></p></li></ol><h2 id="特征工程-2">特征工程</h2><ol type="1"><li>用户特征</li><li>商品特征</li><li>用户-商品特征：如相似度特征，聚合的统计特征等</li></ol><p>对于第1部分和第2部分，可以进行计算并保存一次，然后与第3部分的特征合并。这种方法可以节省很多时间，尤其是在推理的时候。 <a name="iBcjc"></a></p><h2 id="模型">模型</h2><p>作者用了大量时间在召回策略的设计上，因此只用了lightgbm单模 <a name="pKWxi"></a></p><h2 id="亮点-3">亮点</h2><ol type="1"><li>召回策略非常丰富，一共用了21种</li><li>图像和文本的embedding，图像用了swin transformer，文本用了SentenceTransformer</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;a name=&quot;uOrxS&quot;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="比赛" scheme="https://lukan217.github.io/categories/%E6%AF%94%E8%B5%9B/"/>
    
    
    <category term="kaggle" scheme="https://lukan217.github.io/tags/kaggle/"/>
    
    <category term="推荐系统" scheme="https://lukan217.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>BERT原理总结</title>
    <link href="https://lukan217.github.io/2022/04/08/Bert%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/"/>
    <id>https://lukan217.github.io/2022/04/08/Bert%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/</id>
    <published>2022-04-08T08:10:03.489Z</published>
    <updated>2022-05-14T16:20:47.163Z</updated>
    
    <content type="html"><![CDATA[<p>最近在做nlp相关的任务，发现无脑上bert就能达到很好的效果了，于是就去看了原论文，写篇文章好好总结一下吧！ <a name="YRyi1"></a></p><h1 id="背景">背景</h1><p>在计算机视觉领域，预训练已经被证明是行之有效的了，比如ImageNet，训练了一个很大的模型，用来分类1000种东西，然后底层的模型架构就能很好的捕捉到图像的信息了，就可以直接迁移到其他任务上，比如一个猫狗的二分类问题，就只需要把模型拿来微调，接一个softmax输出层，然后重新训练几个epoch就能达到很好的效果了。类似的预训练一个大模型然后拿来做迁移学习的思想也被用在了nlp上，语言模型的预训练用在下游任务的策略主要有两种：</p><ol type="1"><li>基于特征（feature-base）：也就是词向量，预训练模型训练好后输出的词向量直接应用在下游模型中。如ELMo，用了一个双向的LSTM，一个负责用前几个词预测下一个词，另一个相反，用后面几个词来预测前一个词，一个从左看到右，一个从右看到左，能够很好地捕捉到上下文的信息，不过只能输出一个词向量，需要针对不同的下游任务构建新的模型。</li><li>基于微调（fine-tuning）：先以自监督的形式预训练好一个很大的模型，然后根据下游任务的不同接一个输出层就行了，不需要再重新去设计模型架构，如OpenAI-GPT，但是GPT用的是一个单向的transformer，训练时用前面几个词来预测后面一个词，只能从左往右看，不能够很好的捕捉到上下文的信息。</li></ol><p>ELMo虽然用了两个单向的LSTM来构成一个双向的架构，能够捕捉到上下文信息，但是只能输出词向量，下游任务的模型还是要自己重新构建，而GPT虽然是基于微调，直接接个输出层就能用了，但是是单向的模型，只能基于上文预测下文，没有办法很好的捕捉到整个句子的信息。<br />因此，BERT（Bidirectional Encoder Representations from Transformers）就把这两个模型的思想融合了起来，首先，他用的是基于微调的策略，在下游有监督任务里面只需要换个输出层就行，其次，他在训练的时候用了一个transformer的encoder来基于双向的上下文来表示词元，下图展示了ELMo、GPT和BERT的区别：<br /><img src="https://cdn.nlark.com/yuque/0/2022/svg/764062/1649144748837-d0dd42fe-0a8b-4e29-820f-c9b923850db3.svg#clientId=u0872f9ad-41c6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u00a83598&amp;margin=%5Bobject%20Object%5D&amp;originHeight=392&amp;originWidth=611&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uf43e63ab-467c-46cb-ad61-51e39d67573&amp;title=" /><br />BERT很好的融合了ELMo和GPT的优点，论文中提到在11种自然语言处理任务中（文本分类、自然语言推断、问答、文本标记）都取得了SOTA的成绩。 <a name="HEjdw"></a></p><h1 id="核心思想">核心思想</h1><p>BERT的模型结构采用的是transformer的编码器，模型结构如下，其实就是输入一个<span class="math inline">\(n\times h\)</span>（n为最大句子长度，h为隐藏层的个数）的向量，经过内部的一些操作，也输出一个<span class="math inline">\(n\times h\)</span>的向量。<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1649397385919-e4ce313b-f3d7-4dee-8c05-a1ee3e48c5f3.png" alt="image.png" /><br />根据模型的一些参数设置的不同，BERT又分为：</p><ul><li><span class="math inline">\(BERT_{BASE}\)</span>：transformer层12，隐藏层大小768，多头注意力个数12，总共1.1亿参数</li><li><span class="math inline">\(BERT_{LARGE}\)</span>：transformer层24，隐藏层大小1024，多头注意力个数16，总共3.4亿参数</li></ul><p>BERT主要的工作在于对于<strong>输入表示的改造</strong>以及<strong>训练目标的设计</strong>。 <a name="CaisL"></a></p><h2 id="输入表示">输入表示</h2><p>在自然语言处理中，有的任务的输入可能只需要一个句子，比如情感分析，但是有的任务的输入是需要一对句子的，比如自然语言推断，因此，为了使Bert能够用在更多的下游任务上，BERT的输入被设计为不仅可以输入一个句子，也可以输入一个句子对。<br />不管输入的是一个句子还是句子对，BERT的输入的第一个词元都是一个特殊的词元<CLS>，作为句子的开始，并且这个<CLS>在最后输出的表征中也有很重要的作用，对于两个句子，BERT用一个分隔符<SEP>，因此：</p><ul><li>对于一个句子，BERT的输入结构为：<CLS>句子<SEP></li><li>对于一个句子对，BERT的输入为：<CLS>句子1<SEQ>句子2<SEP></li></ul><p>由于注意力机制是无法捕捉到位置信息的，因此BERT还加了一个position embedding，这里的position embedding的参数是自己学出来的，用来加在每个词元上的token embedding。<br />并且，为了区分句子对，BERT又训练了一个两个Segment Embeddings，分别加在原来的两个句子对应的token embedding上。<br />因此，最后BERT的输入就是三个embedding相加的结果，如下图所示：</p><p><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1649399414503-4c3e9e2a-5555-4d35-937b-d6f4eee065f2.png" alt="image.png" /> <a name="w8GyY"></a></p><h2 id="masked-language-model-mlm"><strong>Masked Language Model (MLM)</strong></h2><p>前面说到，之前的预训练模型都是单向的，也就是用前几个词来预测下一个词，这样有个缺陷就是无法捕捉整个句子的上下文信息。因此BERT采用了在输入时随机mask词元的方式，然后基于上下文，在输出层里面预测这些被mask的词元，其实这就是完型填空了，就像我们以前高中英语做的一样，要能够填空，那么就得对上下文的语义有一个比较深入的了解，因此bert最后训练出来的参数就能够很有效的表征整个句子的语义。<br />具体来说，输入的时候会会把一个句子中的词随机mask掉一部分，比如：“你笑起来真好看”变成“你<mask>起来真<mask>看”，然后还会记住这些被mask住的词的位置，然后再输出的地方找到这些词元的对应的表征，再接一个和词典大小一样的输出层，就可以预测这些位置上被<mask>掉的词是什么了，训练时使用的损失函数也使用交叉熵。<br />但是该遮掉多少词也是个问题，论文里给了一个15%的比例，在训练时将15%的词替换为用一个特殊的“<mask>”替换，不过在训练时可以这么做，在我们微调的时候可就没有<mask>词元了，因此BERT选择这样的设计：</p><ul><li>80%时间为特殊的“<mask>“词元（例如，“this movie is great”变为“this movie is<mask>”；</li><li>10%时间为随机词元（例如，“this movie is great”变为“this movie is drink”），这里的目的是为了引入一些噪声，有点像纠错了；</li><li>10%时间内为不变的标签词元（例如，“this movie is great”变为“this movie is great”） <a name="DFglo"></a></li></ul><h2 id="next-sentence-prediction-nsp"><strong>Next Sentence Prediction (NSP)</strong></h2><p>因为研究者想让bert还能够适应像自然语言推理这类的任务，因此还加入了另一个任务，也就是当输入的是一个句子对的时候，BERT会预测这两个句子在上下文中是否是相邻的，具体在训练时，就会有50%概率输入的句子对是相邻的，50概率输入的句子对是不相邻的，其实就是一个二分类任务，这里刚好用之前提到的句子开头那个<CLS>标记最终输出的隐藏层再接一个softmax二分类输出层就行了，然后用交叉熵来作为损失函数。<br />最终把MLM的损失函数和NSP的损失函数加起来就是BERT最终的损失了，可以用Adam来做优化。 <a name="y0agw"></a></p><h1 id="bert的使用">BERT的使用</h1><p>接下来主要讲讲BERT在各个任务上是怎么使用的，其实也就是接一个输出层啦。</p><ol type="1"><li>文本分类任务：和NSP类似，在<CLS>这个词元的输入顶部接一个softmax分类层</li><li>问答任务：输入一个文本序列，需要从这个序列中找到答案的位置，就是接两个输出层，一个用来代表答案开始的地方，一个用来代表答案结束的地方。</li><li>命名实体识别（NER）任务：输入一个文本，标记文本中每个词元属于什么类型，直接把每个词元的输出向量输入到一个分类层就行。</li></ol><p>具体在使用的时候，直接使用huggingface的<a href="https://huggingface.co/docs/transformers/index">🤗 Transformers</a>就行，里面内置了很多预训练模型，并且对于每个任务也都有很好的封装，使用成本很低。 <a name="EwtoE"></a></p><h1 id="参考">参考</h1><ol type="1"><li><a href="https://arxiv.org/abs/1810.04805">[1810.04805] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></li><li><a href="https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270">BERT Explained: State of the art language model for NLP | by Rani Horev | Towards Data Science</a></li><li><a href="https://zh.d2l.ai/chapter_natural-language-processing-pretraining/bert.html">14.8. 来自Transformers的双向编码器表示（BERT） — 动手学深度学习 2.0.0-beta0 documentation</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近在做nlp相关的任务，发现无脑上bert就能达到很好的效果了，于是就去看了原论文，写篇文章好好总结一下吧！ &lt;a name=&quot;YRyi1&quot;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="深度学习" scheme="https://lukan217.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="自然语言处理" scheme="https://lukan217.github.io/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    <category term="深度学习" scheme="https://lukan217.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>树模型的特征选择-Boruta</title>
    <link href="https://lukan217.github.io/2022/03/12/%E6%A0%91%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9-Boruta/"/>
    <id>https://lukan217.github.io/2022/03/12/%E6%A0%91%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9-Boruta/</id>
    <published>2022-03-12T12:44:33.274Z</published>
    <updated>2022-05-14T16:24:34.122Z</updated>
    
    <content type="html"><![CDATA[<p>对于结构化数据建模，现在主流使用的模型是都是树模型，lightgbm、xgboost等，这些模型有一个很重要的特性就是可以输出特征重要性，可以用来指导特征工程，但是却不能直接用来做特征选择，这篇文章就先主要谈谈使用特征重要性来筛选特征的缺陷，然后介绍一种基于特征重要性改进的特征选择方法——Boruta。 <a name="oDFBy"></a></p><h1 id="使用特征重要性来筛选特征的缺陷">使用特征重要性来筛选特征的缺陷</h1><ol type="1"><li>特征重要性只能说明哪些特征在训练时起到作用了，并不能说明特征和目标变量之间一定存在依赖关系。举例来说，随机生成一大堆没用的特征，然后用这些特征来训练模型，一样可以得到特征重要性，但是这个特征重要性并不会全是0，这是完全没有意义的。</li><li>特征重要性容易高估数值特征和基数高的类别特征的重要性。这个道理很简单，特征重要度是根据决策树分裂前后节点的不纯度的减少量（基尼系数或者MSE）来算的，那么对于数值特征或者基础高的类别特征，不纯度较少相对来说会比较多。</li><li>特征重要度在选择特征时需要决定阈值，要保留多少特征、删去多少特征，这些需要人为决定，并且删掉这些特征后模型的效果也不一定会提升。</li></ol><p>正由于特征重要性存在的这些缺陷，所以一般来说，特征重要性只能用来指导特征工程，比如看排名前几的特征都有啥，之后可以怎么根据这几个特征进行交叉，但是是不能够用来作为特征选择的依据的。但是特征重要性也不是完全没有用，使用得当还是能够作为特征选择的手段的，比如Boruta和Null Importance的特征选择就是基于特征重要性来做的。 <a name="k1sKx"></a></p><h1 id="boruta">Boruta</h1><p>Boruta的名字来自斯拉夫神话中一个住在树上里的恶魔，专门吃贵族，大致含义就是，专门用来剔除树模型那些特征重要性看起来很大，但是实际上并没有用的特征。<br />Boruta的主要思想包含两个，阴影特征（shadow feature）和二项分布，下面一一阐述： <a name="Drf6l"></a></p><h2 id="阴影特征">阴影特征</h2><p>特征重要性的一个缺陷就是无论这些特征的效果如何，重要性都是在这些特征之间对比，就有可能出现矮个里面选高个的现象，那能不能让他们和随机生成的特征比呢，按理来说随机生成特征的重要性应该都很低，那么这样就有了一个基准，就可以识别出哪些特征是有用的了。<br />阴影特征的思想就是把原来所有特征的取值都打乱，打乱后的特征就叫做阴影特征（这里用打乱原来特征的取值而不是新生成特征一个好处就是就保留了原来特征的分布，而不用生成一个新的分布），然后把这些阴影特征加入到原来的数据集中进行训练，如果原始特征的特征重要性还不如阴影特征的话，那说明这个原始特征的效果还不如随机的，可以直接剔除，具体来说步骤如下：</p><ol type="1"><li>对于一个包含有m个特征的数据集，对于每个特征都会创建一份副本</li><li>将特征副本的取值打乱顺序，得到m个阴影特征</li><li>将m个阴影特征加入到原数据集中进行训练，输出特征重要性</li><li>观察m个阴影特征的特征重要性的最大值，将之与原始特征的重要性进行比较，如果原始特征的重要性还不如阴影特征的话，那么就说明这个原始特征是没有用的</li></ol><p>不过这样做还是有个问题，因为这样只做了一次实验，会不会有随机性在里面呢？碰巧某个阴影特征就是特别的强，因此需要做多次实验，才能保证结果更可靠，这就是Boruta的第二个思想，用迭代的方式来进行特征选择。 <a name="eXnle"></a></p><h2 id="二项分布">二项分布</h2><p>前面说到，需要做多次试验才能保证结果更可靠，那么做完多次试验后怎么判断某个特征的去留？假设做了20次实验，然后有三个变量，age、height和weight，在20次实验中，age都被保留了，height被保留了4次，而weight一次都没被保留，那么应该选择哪些变量保留？哪些变量剔除呢？<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1647071703892-4bc4ec90-ff61-44dd-9c8a-87aa81ddfbff.png" alt="image.png" /><br />这里就用到了二项分布，假设每个特征被保留和被剔除的概率都是0.5的话，就跟抛硬币一样，所以n次实验的概率遵从二项分布，就可以通过设置一个阈值（如<span class="math inline">\(p=0.01\)</span>)，把分布的两端截断，分为三个区域：</p><figure><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1647070157764-ea4e794d-f9f3-442c-92ef-61c84b48ef64.png" alt="image.png" /><figcaption aria-hidden="true">image.png</figcaption></figure><ol type="1"><li>拒绝区域（红色）：落在这块区域的特征在大部分实验中都被剔除了，因此是无用特征，可以直接剔除</li><li>不确定区域（紫色）：落在这块区域的特征，有时候被剔除了，有时候又被保留，这时候就需要自行决定是否保留，算法默认保留</li><li>接受区域（绿色）：落在这块区域的特征，大部分实验中都被保留了，可以视为有用特征。</li></ol><p><a name="ghaYE"></a></p><h1 id="使用">使用</h1><p>Boruta原本是R的包，现在也有了Python实现，可以直接调包使用： <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install boruta</span><br></pre></td></tr></table></figure> Bortuta使用了类sklearn的接口，用起来也很方便，理论上lightgbm、xgboost、catboost都可以放进Boruta里面，但是实操中有时候会报错，原因未明，但实际上用官方例子的随机森林就可以了： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> boruta <span class="keyword">import</span> BorutaPy</span><br><span class="line"></span><br><span class="line"><span class="comment"># load X and y</span></span><br><span class="line"><span class="comment"># NOTE BorutaPy accepts numpy arrays only, hence the .values attribute</span></span><br><span class="line">X = pd.read_csv(<span class="string">&#x27;examples/test_X.csv&#x27;</span>, index_col=<span class="number">0</span>).values</span><br><span class="line">y = pd.read_csv(<span class="string">&#x27;examples/test_y.csv&#x27;</span>, header=<span class="literal">None</span>, index_col=<span class="number">0</span>).values</span><br><span class="line">y = y.ravel()</span><br><span class="line"></span><br><span class="line"><span class="comment"># define random forest classifier, with utilising all cores and</span></span><br><span class="line"><span class="comment"># sampling in proportion to y labels</span></span><br><span class="line">rf = RandomForestClassifier(n_jobs=-<span class="number">1</span>, class_weight=<span class="string">&#x27;balanced&#x27;</span>, max_depth=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define Boruta feature selection method</span></span><br><span class="line">feat_selector = BorutaPy(rf, n_estimators=<span class="string">&#x27;auto&#x27;</span>, verbose=<span class="number">2</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># find all relevant features - 5 features should be selected</span></span><br><span class="line">feat_selector.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># check selected features - first 5 features are selected</span></span><br><span class="line">feat_selector.support_</span><br><span class="line"></span><br><span class="line"><span class="comment"># check ranking of features</span></span><br><span class="line">feat_selector.ranking_</span><br><span class="line"></span><br><span class="line"><span class="comment"># call transform() on X to filter it down to selected features</span></span><br><span class="line">X_filtered = feat_selector.transform(X)</span><br></pre></td></tr></table></figure> <a name="GST3P"></a></p><h1 id="总结">总结</h1><p>总结来说，Boruta就是生成了随机的阴影特征加入到原数据中，并比较阴影特征和原始特征的重要性大小，然后多次迭代，最终根据二项分布来比较特征优于阴影特征的次数来决定是否保留或者剔除特征，这样筛选最后得到的特征都是对于模型的预测能够起到积极作用的特征，注意到这是能够起到积极作用，但是并不代表特征筛选后一定会使得预测的效果最好，不过根据自己的实验，使用Boruta之后的效果基本上都不亚于原来未筛选时的效果，并且训练速度也大大加快了。 <a name="KP7iR"></a></p><h1 id="参考">参考</h1><ol type="1"><li><a href="https://towardsdatascience.com/boruta-explained-the-way-i-wish-someone-explained-it-to-me-4489d70e154a">Boruta Explained Exactly How You Wished Someone Explained to You | by Samuele Mazzanti | Towards Data Science</a></li><li><a href="https://danielhomola.com/feature%20selection/phd/borutapy-an-all-relevant-feature-selection-method/">BorutaPy - Daniel Homola</a></li><li><a href="https://github.com/scikit-learn-contrib/boruta_py">scikit-learn-contrib/boruta_py: Python implementations of the Boruta all-relevant feature selection method.</a></li></ol><p><a href="https://towardsdatascience.com/boruta-explained-the-way-i-wish-someone-explained-it-to-me-4489d70e154a"></a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;对于结构化数据建模，现在主流使用的模型是都是树模型，lightgbm、xgboost等，这些模型有一个很重要的特性就是可以输出特征重要性，可以用来指导特征工程，但是却不能直接用来做特征选择，这篇文章就先主要谈谈使用特征重要性来筛选特征的缺陷，然后介绍一种基于特征重要性改进的特征选择方法——Boruta。 &lt;a name=&quot;oDFBy&quot;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://lukan217.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="https://lukan217.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="特征选择" scheme="https://lukan217.github.io/tags/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"/>
    
  </entry>
  
  <entry>
    <title>特征选择的基本方法总结</title>
    <link href="https://lukan217.github.io/2022/03/12/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    <id>https://lukan217.github.io/2022/03/12/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/</id>
    <published>2022-03-12T12:44:33.272Z</published>
    <updated>2022-05-14T16:24:45.617Z</updated>
    
    <content type="html"><![CDATA[<p>做机器学习时往往会通过特征交叉来衍生出一系列的特征，那么如何来确保这些特征是有用的呢？太多的特征一方面会加重模型的负担，跑得很慢，另一方面无效的特征也会使得模型效果下降，因此就需要一些特征选择的方法来剔除无效的特征，这篇文章就主要总结下特征选择的几种基本思路。 <a name="LZb8F"></a></p><h1 id="img过滤法"><img src="https://pic4.zhimg.com/80/v2-05756baf02bd7a023f7b27842594bc2b_1440w.jpg" alt="img" />过滤法</h1><p>过滤法的思想就是不依赖模型，仅从特征的角度来做特征的筛选，具体又可以分为两种方法，一种是根据特征里面包含的信息量，如方差选择法，如果一列特征的方差很小，每个样本的取值都一样的话，说明这个特征的作用不大，可以直接剔除。另一种是对每一个特征，都计算关于目标特征的相关度，然后根据这个相关度来筛选特征，只保留高于某个阈值的特征，这里根据相关度的计算方式不同就可以衍生出一下很多种方法：</p><ol type="1"><li>Pearson相关系数</li><li>卡方验证</li><li>互信息和最大信息系数</li></ol><p>过滤法的优势在于效率非常快，不用跑模型就能很快筛选出一批的特征，不过缺陷是筛选出来的特征对于模型不一定是有用的，并且可能会有冗余特征，而且也不能考虑到特征之间的相互作用。 <a name="Fnzju"></a></p><h1 id="包装法">包装法</h1><p>与过滤法不同，包装法是根据训练模型的效果来筛选特征的，所以第一步就是先划分训练集和测试集，然后搜索一个最优的特征子集，使得模型在测试集上的指标表现最好。根据搜索方式的不同又可以分为以下三种类型：</p><ol type="1"><li>暴力搜索：穷举所有的特征子集，获取最好的一个，不过计算复杂度是指数级的，一般不会用</li><li>贪心搜索：分为前向搜索和后向搜索，就是每次增加一个或者减少一个特征，看模型的效果会不会变好，依此来选择特征是否保留，计量里面学的逐步回归就属于这种方法</li><li>启发式搜索：根据遗传算法、模拟退火、蚁群算法等启发式算法来搜索最优的特征子集</li></ol><p>包装法的优势在于选出的特征都是对于模型的效果有提升的，但是缺陷是需要训练很多次模型来评估特征的作用，效率低下，只能在特征和样本量相对较少的时候用一下。 <a name="hEZGe"></a></p><h1 id="嵌入法">嵌入法</h1><p>嵌入法的嵌入就是把特征的选择嵌入到模型的训练过程中，在模型训练完成之后便可得出哪些特征是有用的，哪些特征是没用的。这种方法就需要特定的模型才能做了，具体来说有两种：</p><ol type="1"><li>Lasso：通过控制惩罚项<span class="math inline">\(\lambda\)</span>的大小，可以将一些变量的系数压缩为0，就起到了特征选择的作用</li><li>树模型：随机森林和GBDT这些树模型，可以输出特征重要性，通过特征重要性可以大概知道哪些特征有用，哪些没用</li></ol><p>嵌入法的同时兼顾了包装法和嵌入法的优点，不过实际使用过程中，还是会有些问题，尤其是用特征重要性，之后更新下两篇文章，主要谈谈使用特征重要性作为特征选择的缺陷，以及两种基于特征重要性改进的特征选择方法：Boruta和Null Importance。 <a name="A8Flw"></a></p><h1 id="参考">参考</h1><ol type="1"><li><a href="https://zhuanlan.zhihu.com/p/74198735">【机器学习】特征选择(Feature Selection)方法汇总 - 知乎</a></li><li>《美团机器学习实践》</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;做机器学习时往往会通过特征交叉来衍生出一系列的特征，那么如何来确保这些特征是有用的呢？太多的特征一方面会加重模型的负担，跑得很慢，另一方面无效的特征也会使得模型效果下降，因此就需要一些特征选择的方法来剔除无效的特征，这篇文章就主要总结下特征选择的几种基本思路。 &lt;a name=&quot;LZb8F&quot;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://lukan217.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="https://lukan217.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="特征选择" scheme="https://lukan217.github.io/tags/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"/>
    
  </entry>
  
  <entry>
    <title>贝叶斯优化基本原理总结</title>
    <link href="https://lukan217.github.io/2022/01/23/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/"/>
    <id>https://lukan217.github.io/2022/01/23/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/</id>
    <published>2022-01-22T17:50:03.926Z</published>
    <updated>2022-06-11T09:08:15.144Z</updated>
    
    <content type="html"><![CDATA[<p>贝叶斯优化（Bayesian Optimization），主要用来解决计算成本昂贵的黑盒优化问题，这种问题有着以下两个特点：</p><ol type="1"><li>目标函数<span class="math inline">\(f(x)\)</span>及其导数未知，否则就可以用梯度下降等方法求解</li><li>计算目标函数时间成本大，意味着像蚁群算法、遗传算法这种方法也失效了，因为计算一次要花费很多时间</li></ol><p><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1642518880682-ca49f801-c6dd-406d-965d-9ba3690c74a6.png#clientId=u3fe6f5be-444f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=52&amp;id=SNVtL" alt="image.png" /><br />这种问题最典型的就是机器学习里面的超参数优化，使用的模型为 <span class="math inline">\(f\)</span>，超参数为输入的 <span class="math inline">\(x\)</span>，评估指标（MSE, AUC等）为输出的目标函数值，在这个场景下，很多机器学习的入门课程都会提到网格搜索和随机搜索，但是这两个其实本质上也是一种类似于穷举的方式，随便选取一组可能的<span class="math inline">\(x\)</span>，然后分别计算目标值，最后对比所有的结果得到最好的解，可以看出来这种求解是很低效的，因此，解决这种问题需要设计一种高效的算法，来在有限的时间里面找到一个相对不错的解，这就是贝叶斯优化。<br />贝叶斯优化，是一种使用贝叶斯定理来指导搜索以找到目标函数的最小值或最大值的方法，就是在每次迭代的时候，利用之前观测到的历史信息（先验知识)来进行下一次优化，通俗点讲，就是在进行一次迭代的时候，先回顾下之前的迭代结果，结果太差的<span class="math inline">\(x\)</span>附近就不去找了，尽量往结果好一点的<span class="math inline">\(x\)</span>附近去找最优解，这样一来搜索的效率就大大提高了，这其实和人的思维方式也有点像，每次在学习中试错，并且在下次的时候根据这些经验来找到最优的策略。 <a name="raVsx"></a></p><h1 id="贝叶斯优化过程">贝叶斯优化过程</h1><p>首先，假设有一个这样的函数<span class="math inline">\(c(x)\)</span>，我们需要找到他的最小值，如下图所示，这也是我们所需要优化的目标函数，但是我们并不能够知道他的具体形状以及表达形式是怎么样的。<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1642862207488-61095c80-c151-4cb2-848d-74c44f23901f.png#clientId=u86233cce-d6bd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u10477eea" alt="image.png" /><br />贝叶斯优化是通过一种叫做代理优化的方式来进行的，就是不知道真实的目标函数长什么样，我们就用一个代理函数（surrogate function）来代替目标函数，而这个代理函数就可以通过先采样几个点，再通过这几个点来给他拟合出来，如下图虚线所示：<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1642862350662-cfeab91b-ee4f-4395-8cae-1c9c1df4d8c1.png#clientId=u86233cce-d6bd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u93bcdc6a" alt="image.png" /><br />基于构造的代理函数，我们就可以在可能是最小值的点附近采集更多的点，或者在还没有采样过的区域来采集更多的点，有了更多点，就可以更新代理函数，使之更逼近真实的目标函数的形状，这样的话也更容易找到目标函数的最小值，这个采样的过程同样可以通过构建一个采集函数来表示，也就是知道了当前代理函数的形状，如何选择下一个<span class="math inline">\(x\)</span>使得收益最大。<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1642862456555-21005371-dd1b-419e-9c9c-2c4e28d83ddf.png#clientId=u86233cce-d6bd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uc7daab55" alt="image.png" /><br />然后重复以上过程，最终就可以找到函数的最小值点了，这大致就是贝叶斯优化的一个过程：</p><ol type="1"><li>初始化一个代理函数的先验分布</li><li>选择数据点<span class="math inline">\(x\)</span>，使得采集函数<span class="math inline">\(a(x)\)</span>取最大值</li><li>在目标函数 <span class="math inline">\(c(x)\)</span>中评估数据点<span class="math inline">\(x\)</span>并获取其结果 <span class="math inline">\(y\)</span></li><li>使用新数据<span class="math inline">\((x,y)\)</span>更新代理函数，得到一个后验分布（作为下一步的先验分布）</li><li>重复2-4步，直到达到最大迭代次数</li></ol><p>举个例子，如图所示，一开始只有两个点（t=2），代理函数的分布是紫色的区域那块，然后根据代理函数算出一个采集函数（绿色线），取采集函数的最大值所在的<span class="math inline">\(x\)</span>（红色三角处），算出<span class="math inline">\(y\)</span>，然后根据新的点<span class="math inline">\((x,y)\)</span>更新代理函数和采集函数（t=3），继续重复上面步骤，选择新的采集函数最大值所在的<span class="math inline">\(x\)</span>，算出<span class="math inline">\(y\)</span>，再更新代理函数和采集函数，然后继续迭代<br /><img src="https://cdn.nlark.com/yuque/0/2022/png/764062/1642870783116-4e643df2-ec8f-4b2c-84e2-f5d11c2cfac2.png#clientId=u86233cce-d6bd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u912a5632" alt="image.png" /><br />问题的核心就在于代理函数和采集函数如何构建，常用的代理函数有：</p><ol type="1"><li>高斯过程（Gaussian processes）</li><li>Tree Parzer Estimator</li><li>概率随机森林：针对类别型变量</li></ol><p>采集函数则需要兼顾两方面的性质：</p><ol type="1"><li>利用当前已开发的区域（Exploitation）：即在当前最小值附近继续搜索</li><li>探索尚未开发的区域（Exploration）：即在还没有搜索过的区域里面搜索，可能那里才是全局最优解</li></ol><p>常用的采集函数有：</p><ol type="1"><li><p>Probability of improvement（PI）</p></li><li><p>Expected improvement（EI）</p></li><li><p>Confidence bound criteria，包括LCB和UCB <a name="lYgNb"></a></p></li></ol><h1 id="可用的贝叶斯优化框架">可用的贝叶斯优化框架</h1><ol type="1"><li>BayesianOptimization：<a href="https://github.com/fmfn/BayesianOptimization">https://github.com/fmfn/BayesianOptimization</a></li><li>清华开源的openbox：<a href="https://open-box.readthedocs.io/zh_CN/latest/index.html">https://open-box.readthedocs.io/zh_CN/latest/index.html</a></li><li>华为开源的HEBO：<a href="https://github.com/huawei-noah/HEBO">https://github.com/huawei-noah/HEBO</a></li><li>Hyperopt：<a href="http://hyperopt.github.io/hyperopt/">http://hyperopt.github.io/hyperopt/</a></li></ol><p>个人觉得1和2就挺好用的 <a name="ZDkC6"></a></p><h1 id="参考">参考</h1><ol type="1"><li><a href="https://towardsdatascience.com/the-beauty-of-bayesian-optimization-explained-in-simple-terms-81f3ee13b10f">https://towardsdatascience.com/the-beauty-of-bayesian-optimization-explained-in-simple-terms-81f3ee13b10f</a></li><li><a href="https://chengfeng96.com/blog/2019/09/08/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96%E7%AC%94%E8%AE%B0/">https://chengfeng96.com/blog/2019/09/08/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96%E7%AC%94%E8%AE%B0/</a></li><li><a href="https://zhuanlan.zhihu.com/p/459110020">https://zhuanlan.zhihu.com/p/459110020</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;贝叶斯优化（Bayesian Optimization），主要用来解决计算成本昂贵的黑盒优化问题，这种问题有着以下两个特点：&lt;/p&gt;</summary>
    
    
    
    <category term="最优化" scheme="https://lukan217.github.io/categories/%E6%9C%80%E4%BC%98%E5%8C%96/"/>
    
    
    <category term="贝叶斯优化" scheme="https://lukan217.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/"/>
    
    <category term="最优化" scheme="https://lukan217.github.io/tags/%E6%9C%80%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>一个简约的beamer模板</title>
    <link href="https://lukan217.github.io/2021/12/05/%E4%B8%80%E4%B8%AA%E7%AE%80%E7%BA%A6%E7%9A%84beamer%E6%A8%A1%E6%9D%BF/"/>
    <id>https://lukan217.github.io/2021/12/05/%E4%B8%80%E4%B8%AA%E7%AE%80%E7%BA%A6%E7%9A%84beamer%E6%A8%A1%E6%9D%BF/</id>
    <published>2021-12-05T10:24:04.588Z</published>
    <updated>2022-05-14T16:25:34.024Z</updated>
    
    <content type="html"><![CDATA[<p>开组会啥的，要做ppt，但感觉还是用beamer比较方便，用默认的模板改了改，看着也还行 ​</p><p>项目链接：<a href="https://github.com/Smallviller/beamer_template">https://github.com/lukan217/beamer_template</a> <img src="https://cdn.nlark.com/yuque/0/2021/jpeg/764062/1638691638592-6975409f-6254-4735-8062-0b436f49051b.jpeg#clientId=uca4f431b-7c8d-4&amp;from=drop&amp;id=u2147a6de&amp;margin=%5Bobject%20Object%5D&amp;name=0001.jpg&amp;originHeight=1063&amp;originWidth=1890&amp;originalType=binary&amp;ratio=1&amp;size=82132&amp;status=done&amp;style=none&amp;taskId=u14532634-3b60-409f-9605-bb6f6f05ca2" alt="0001.jpg" /><img src="https://cdn.nlark.com/yuque/0/2021/jpeg/764062/1638691638348-e5ff3e5b-f79d-4782-8e55-0c30b903ba5f.jpeg#clientId=uca4f431b-7c8d-4&amp;from=drop&amp;id=u3af9e72d&amp;margin=%5Bobject%20Object%5D&amp;name=0002.jpg&amp;originHeight=1063&amp;originWidth=1890&amp;originalType=binary&amp;ratio=1&amp;size=54464&amp;status=done&amp;style=none&amp;taskId=u06378bdd-14f5-4d70-8234-2de0e293ae7" alt="0002.jpg" /><img src="https://cdn.nlark.com/yuque/0/2021/jpeg/764062/1638691638612-1fe8e3f9-6a92-4e37-ae33-b5b6ab56f8e2.jpeg#clientId=uca4f431b-7c8d-4&amp;from=drop&amp;id=u8c014218&amp;margin=%5Bobject%20Object%5D&amp;name=0003.jpg&amp;originHeight=1063&amp;originWidth=1890&amp;originalType=binary&amp;ratio=1&amp;size=93115&amp;status=done&amp;style=none&amp;taskId=u2ea290d5-3e0e-4325-8026-ef36ee6ca4f" alt="0003.jpg" /><img src="https://cdn.nlark.com/yuque/0/2021/jpeg/764062/1638691638621-2ea8a6c3-280f-42aa-b3c0-ad26cfaa4c76.jpeg#clientId=uca4f431b-7c8d-4&amp;from=drop&amp;id=u36cfdf6d&amp;margin=%5Bobject%20Object%5D&amp;name=0004.jpg&amp;originHeight=1063&amp;originWidth=1890&amp;originalType=binary&amp;ratio=1&amp;size=78021&amp;status=done&amp;style=none&amp;taskId=u1217dd56-073b-4fa2-b583-b8fb2918500" alt="0004.jpg" /><img src="https://cdn.nlark.com/yuque/0/2021/jpeg/764062/1638691638656-448960af-454b-40ab-8d10-cd79c533bf18.jpeg#clientId=uca4f431b-7c8d-4&amp;from=drop&amp;id=u3b90e5c0&amp;margin=%5Bobject%20Object%5D&amp;name=0005.jpg&amp;originHeight=1063&amp;originWidth=1890&amp;originalType=binary&amp;ratio=1&amp;size=91360&amp;status=done&amp;style=none&amp;taskId=u9030a713-073c-4dd9-8d48-af400e2ad07" alt="0005.jpg" /><img src="https://cdn.nlark.com/yuque/0/2021/jpeg/764062/1638691638958-0c02aa64-99e9-4ea3-ba8c-531ac03c087b.jpeg#clientId=uca4f431b-7c8d-4&amp;from=drop&amp;id=u80084e0b&amp;margin=%5Bobject%20Object%5D&amp;name=0006.jpg&amp;originHeight=1063&amp;originWidth=1890&amp;originalType=binary&amp;ratio=1&amp;size=57523&amp;status=done&amp;style=none&amp;taskId=ua805a004-b4b3-4624-a5b3-87eea69d808" alt="0006.jpg" /><img src="https://cdn.nlark.com/yuque/0/2021/jpeg/764062/1638691639346-c7384931-218f-4b0b-b9f3-d022f11872fe.jpeg#clientId=uca4f431b-7c8d-4&amp;from=drop&amp;id=ufb0038af&amp;margin=%5Bobject%20Object%5D&amp;name=0007.jpg&amp;originHeight=1063&amp;originWidth=1890&amp;originalType=binary&amp;ratio=1&amp;size=82696&amp;status=done&amp;style=none&amp;taskId=ud7d2d344-949b-44c7-a352-376c052870f" alt="0007.jpg" /><img src="https://cdn.nlark.com/yuque/0/2021/jpeg/764062/1638691639446-6f42c330-ccdb-401e-93dc-4be4c74550e2.jpeg#clientId=uca4f431b-7c8d-4&amp;from=drop&amp;id=u79b63874&amp;margin=%5Bobject%20Object%5D&amp;name=0008.jpg&amp;originHeight=1063&amp;originWidth=1890&amp;originalType=binary&amp;ratio=1&amp;size=70224&amp;status=done&amp;style=none&amp;taskId=u33f6e90c-dad6-4134-ab5e-d189eff53c1" alt="0008.jpg" /><img src="https://cdn.nlark.com/yuque/0/2021/jpeg/764062/1638691639692-a5053fac-411d-40d1-8501-6c7fe318e305.jpeg#clientId=uca4f431b-7c8d-4&amp;from=drop&amp;id=ud5f6369d&amp;margin=%5Bobject%20Object%5D&amp;name=0009.jpg&amp;originHeight=1063&amp;originWidth=1890&amp;originalType=binary&amp;ratio=1&amp;size=51952&amp;status=done&amp;style=none&amp;taskId=u6b9d7536-8999-465a-9817-ce762930acf" alt="0009.jpg" /></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;开组会啥的，要做ppt，但感觉还是用beamer比较方便，用默认的模板改了改，看着也还行 ​&lt;/p&gt;</summary>
    
    
    
    <category term="计算机" scheme="https://lukan217.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"/>
    
    
    <category term="beamer" scheme="https://lukan217.github.io/tags/beamer/"/>
    
    <category term="latex" scheme="https://lukan217.github.io/tags/latex/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle M5时间序列预测比赛的发现总结</title>
    <link href="https://lukan217.github.io/2021/11/27/Kaggle%20M5%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%E7%9A%84%E5%8F%91%E7%8E%B0%E6%80%BB%E7%BB%93/"/>
    <id>https://lukan217.github.io/2021/11/27/Kaggle%20M5%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B%E7%9A%84%E5%8F%91%E7%8E%B0%E6%80%BB%E7%BB%93/</id>
    <published>2021-11-27T08:52:00.501Z</published>
    <updated>2023-05-02T16:38:46.248Z</updated>
    
    <content type="html"><![CDATA[<p>谈到时序预测，2020年kaggle上举办的那场M5沃尔玛销量预测比赛肯定是最值得学习的，有人甚至直接根据这场比赛写了两篇论文（见文末）发在 International Journal of Forecasting上，来总结这场比赛用到的一些方法，这里就把论文中的一些关键发现列出来供学习参考。 <a name="Y2CJP"></a></p><h1 id="机器学习方法的优越性"><strong>机器学习方法的优越性</strong></h1><p>多年来，经验发现，简单的方法与复杂的或统计上复杂的方法一样准确。由于有限的数据可用性、算法的低效性、预处理的需要以及受限的计算能力，此前机器学习方法和统计学方法相比准确性都有所不足。M4是第一个发现两个ML方法明显比简单的统计方法更准确的预测竞赛，突出了ML方法对更准确预测的潜在价值。赢得M4竞赛的第一名是混合了RNN和指数平滑的混合方法，而排名第二的方法是使用XGBoost对标准时间序列预测方法产生的预测进行优化加权。尽管M4的两个获奖作品在本质上都是ML，但它们都建立在统计学、系列的特定功能上，同时也与四种统计学方法的简单组合有着差不多的准确性。然而，M5是第一个所有表现最好的方法都是 "纯 "ML方法，并且明显优于所有统计基准及其组合的比赛。LightGBM证明了它可以有效地用于处理大量相关的时间序列序列和外生变量，并减少预测误差。此外，像DeepAR和N-BEATS这样的深度学习方法，也显示出预测的潜力。 <a name="scDUJ"></a></p><h1 id="模型融合的价值"><strong>模型融合的价值</strong></h1><p>M5 Accuracy竞赛表明融合不同方法的预测，即使是相对简单的方法，也能从总体上提高精确度。M5 Accuracy竞赛的冠军采用了一个非常简单的简单平均融合，涉及6个模型，每个模型利用不同的学习方法和训练集。同样，亚军采用了5个模型的简单平均融合，每个模型对趋势有不同的估计，而第三名的方法，是43个NN的简单平均融合。排名14th, 17th, 21st, 24th, 25th和44th方法也使用了模型的简单平均融合。 在这些融合方法中，只有排名25的方法考虑了对单个方法的不平等加权融合。模型融合的价值也被竞争的baleline之间的比较所支持：指数平滑模型和ARIMA模型的融合比单个方法的表现更好，自上而下和自下而上的调和预测的融合则比自上而下和自下而上的表现都好。 <a name="KXkQA"></a></p><h1 id="时间序列交叉学习-的价值"><strong>"时间序列交叉学习 "的价值</strong></h1><p>在以前的M系列竞赛中，大多数时间序列都是不相关的，属于不同的频率和领域，而且时间上也不对齐。因此，尽管M4比赛中表现最好的两个参赛者都同时考虑了从多个序列中"交叉学习"，而不是一次一个系列，但他们的方法在实践中难以有效实施，也没有充分展示出该方法的潜力。相比之下，由于M5是由排列整齐、高度相关的时间序列组成的，而且是分层结构的，所以 "交叉学习 "更容易应用，与逐个时间序列训练的方法相比，取得了很好的效果。同时，除了可以提高准确率，"交叉学习 "意味着可以在多个时间序列上只使用一个模型，因为这些序列是一起训练的，而不用针对每个时间序列都训练一个模型，因此减少了整体的计算成本，缓解了与有限的历史观察相关的困难。基本上，M5中所有表现最好的50个方法都使用了 "交叉学习"，利用了数据集提供的所有信息。 <a name="R2rMu"></a></p><h1 id="获胜的方法和用于销售预测的baseline之间存在重大差异"><strong>获胜的方法和用于销售预测的baseline之间存在重大差异</strong></h1><p>M5 Accuracy竞赛考虑了24个通常用于销售预测应用的各种类型的baseline，包括传统的和最先进的统计方法、ML方法和他们的融合。但与这些baseline相比，获胜的作品明显提供了更准确的预测，并且在WRMSSE方面也平均高出20%以上。尽管较低的聚集水平上表现差不多，但结果仍清楚地表明了它们的优越性，并促使在ML预测方法领域进行更多的研究，这些方法可用于预测时间序列之间复杂的非线性关系，同时也能够方便的引入外生/解释变量。 <a name="HxvtW"></a></p><h1 id="从模型外部校正预测的价值"><strong>从模型外部校正预测的价值</strong></h1><p>当预测者利用外部信息、内部知识以及他们的专业知识来提高预测精度时，通常会使用预测调整。在M5 Accuracy竞赛中，一些表现最好的方法，如排名第2和第5的方法，以乘数的形式利用这种调整来提高ML模型的预测（即在原先的预测结果上乘以一个系数，如0.95-1.05来校正预测结果，这个实际上是因为lightgbm外推能力差，在有趋势的序列上容易高估预测或者低估预测）。尽管这些调整并不完全基于判断，而是基于最低聚合水平产生的预测与较高聚合水平的预测之间的分析进行调整，但这些调整被证明是有用的，能够帮助预测模型减少偏差，更好地说明在较高聚合水平上更容易观察到的长期趋势。 然后，这种调整的实际价值需要进一步调查，但在预测领域，调和在不同聚集水平产生的预测的概念并不新鲜，许多研究实证证明了它的好处，特别是当预测和来自完整层次的信息被利用时。 <a name="LOU5s"></a></p><h1 id="有效的cv交叉验证策略的价值"><strong>有效的CV（交叉验证）策略的价值</strong></h1><p>在处理复杂的预测任务时，采用有效的CV策略对于提高样本外预测的准确性、避免过拟合和减轻不确定性至关重要。采用这种策略的重要性在M5 Accuracy竞赛的结果中得到了证明，选择进行CV的时间段，验证时间窗口的大小，这些窗口的更新方式，以及用于衡量预测表现的标准，都是预测者必须考虑的一些因素。在M5精确度竞赛中，表现最好的四种方法和前50名提交的绝大多数都考虑了这样的一种CV策略，即至少使用最后四个28天长的可用的数据窗口来做交叉验证以评估预测精确度，从而对样本外的表现提供一个合理的近似。除了这个CV方案之外，第一名的方案还同时测量了他所开发的模型CV结果的平均值和标准偏差。根据他的验证，他的方法中的递归模型被发现平均比非递归模型更准确，但更不稳定。因此，他决定将这两个模型结合起来，以确保产生的预测既是准确和稳定。在评估预测方法时，必须考虑到预测误差的全部分布，特别是其尾部，这表明稳健性是实现高准确度的前提条件。我们希望M5的结果将鼓励在这一领域的更多研究，并有助于开发更强大的CV策略。 <a name="VfP42"></a></p><h1 id="外生解释变量的重要性"><strong>外生/解释变量的重要性</strong></h1><p>时间序列方法通常足以识别和捕捉其历史数据模式（水平、趋势和季节性），通过推断这种模式并产生准确的预测。然而，仅仅依靠历史数据的时间序列方法不能有效地说明节假日、特殊事件、促销活动、价格以及可能的天气的影响。在这种情况下，来自外生/解释变量的信息对于提高预测精度显得至关重要。在M5 Accuracy预测竞赛中，所有获奖作品都利用外部信息来提高其模型的预测性能。例如，monsaraida和其他团队发现，几个与价格相关的特征对于提高他们模型结果的准确性具有重要意义。此外，外生/解释变量的重要性也在几个简单统计学模型中得到的支持，例如，使用促销信息和特殊事件作为外生变量的指数平滑模型比普通的指数平滑模型精确度要高6%。ARIMA模型的情况也是如此，ARIMAX的精度比普通的ARIMA要高13%。 <a name="mDxVC"></a></p><h1 id="参考">参考</h1><ol type="1"><li><a href="https://www.researchgate.net/publication/344487258_The_M5_Accuracy_competition_Results_findings_and_conclusions">The M5 Accuracy competition: Results, findings and conclusions</a></li><li><a href="https://www.researchgate.net/publication/346493740_The_M5_Uncertainty_competition_Results_findings_and_conclusions">The M5 Uncertainty competition: Results, findings and conclusions</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;谈到时序预测，2020年kaggle上举办的那场M5沃尔玛销量预测比赛肯定是最值得学习的，有人甚至直接根据这场比赛写了两篇论文（见文末）发在 International Journal of Forecasting上，来总结这场比赛用到的一些方法，这里就把论文中的一些关键发现列出来供学习参考。 &lt;a name=&quot;Y2CJP&quot;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="比赛" scheme="https://lukan217.github.io/categories/%E6%AF%94%E8%B5%9B/"/>
    
    
    <category term="机器学习" scheme="https://lukan217.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="时间序列" scheme="https://lukan217.github.io/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>Git常用操作总结</title>
    <link href="https://lukan217.github.io/2021/08/29/Git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E6%80%BB%E7%BB%93/"/>
    <id>https://lukan217.github.io/2021/08/29/Git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E6%80%BB%E7%BB%93/</id>
    <published>2021-08-28T18:31:42.115Z</published>
    <updated>2022-05-14T16:21:32.743Z</updated>
    
    <content type="html"><![CDATA[<p>最近工作上会用到Git，这里记录一下一些常用操作供参考！</p><h1 id="git配置">Git配置</h1><ol type="1"><li><p>安装Git：<a href="https://git-scm.com/">https://git-scm.com/</a></p></li><li><p>本地命令行生成密钥绑定GitHub账号 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 输入命令生成密钥对，替换成自己邮箱，然后一路回车</span></span><br><span class="line">ssh-keygen -t rsa -C &quot;youremail@example.com&quot;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 将生成的公钥打印出来复制，将这串文本复制粘贴到GitHub的Setting-&gt;SSH and GPG keys中</span></span><br><span class="line">cat ~/.ssh/id_rsa.pub</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 输入命令检查是否绑定成功,输入yes后，如果出现Hi,xxx!则绑定成功</span></span><br><span class="line">ssh -T git@github.com</span><br><span class="line"></span><br></pre></td></tr></table></figure></p></li><li><p>配置用户名和邮箱信息： <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看配置信息，一开始为空</span></span><br><span class="line">git config --list</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 全局配置，对所有代码库生效</span></span><br><span class="line">git config --global user.name &quot;你的名字&quot;</span><br><span class="line">git config --global user.email &quot;你的邮箱&quot;</span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 局部配置，只对当前的代码库有效</span></span><br><span class="line">git config --local user.name &quot;你的名字&quot;</span><br><span class="line">git config --local user.email &quot;你的邮箱&quot;</span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置后，远程仓库提交的commit里对应的用户即为 user.name</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p></li></ol><h1 id="git基本概念">Git基本概念</h1><ol type="1"><li>本地仓库：本地仓库上存放所有相关的文件，具体可分为工作区、暂存区和仓库区，工作区即项目文件夹下不包含<code>.git</code>文件夹的所有文件，暂存区和仓库区则在<code>.git</code>文件夹下<ol type="1"><li>工作区：即我们工作的文件夹，在里面进行文件的增删改操作</li><li>暂存区：临时保存工作区上的改动，通过<code>git add</code>操作将工作区的修改同步到暂存区</li><li>仓库区：当执行<code>git commit</code>操作时，将暂存区上的所有变动同步到本地仓库</li></ol></li><li>远程仓库：GitHub/GitLab上保存的仓库，通过<code>git push</code>将本地仓库同步到远程仓库，也可以通过<code>git fetch/pull</code>将远程仓库同步到本地仓库</li></ol><figure><img src="https://cdn.nlark.com/yuque/0/2021/png/764062/1630159880578-b47a2dae-9236-4c17-8de3-f4d7155ac69f.png" alt="image.png" /><figcaption aria-hidden="true">image.png</figcaption></figure><h1 id="git基本操作">Git基本操作</h1><h2 id="创建版本库">创建版本库</h2><p>创建版本库有两种方式，一种是将本地的文件夹直接变成一个git仓库，另一种是直接将远程的仓库克隆到本地 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git init # 将本地文件夹变为一个git仓库</span><br><span class="line">git clone &lt;url&gt; #将远程仓库克隆到本地</span><br></pre></td></tr></table></figure></p><h2 id="修改与提交操作">修改与提交操作</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git add &lt;file&gt; # 将单个文件从工作区添加到暂存区</span><br><span class="line">git add . # 将所有文件添加到暂存区</span><br><span class="line">git commit -m &quot;messenge&quot; # 将暂存区文件提交到本地仓库</span><br><span class="line">git status # 查看工作区状态，显示有变更的文件。</span><br><span class="line">git diff # 比较文件的不同，即暂存区和工作区的差异。</span><br></pre></td></tr></table></figure><h2 id="远程操作">远程操作</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">git push origin master # 将本地的master分支推送到远程对应的分支</span><br><span class="line">git pull  # 下载远程代码并合并，相当于git fetch + git pull</span><br><span class="line">git fetch# 从远程获取代码库，但不进行合并操作</span><br><span class="line"></span><br><span class="line">git remote add origin &lt;url&gt; # 将远程仓库与本地仓库关联起来</span><br><span class="line">git remote -v # 查看远程库信息</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="撤销与回退操作">撤销与回退操作</h2><p>撤销操作：当修改了工作区/暂存区的文件，但是还没有commit时，想要撤销之前的操作： <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 场景1：当你改乱了工作区某个文件的内容，但还没有add到暂存区</span></span><br><span class="line">git checkout &lt;file&gt; # 撤销工作区的某个文件到和暂存区一样的状态</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 场景2：当乱改了工作区某个文件的内容，并且git add到了暂存区</span></span><br><span class="line">git reset HEAD &lt;file&gt; # 第1步，将暂存区的文件修改撤销掉</span><br><span class="line">git checkout &lt;file&gt; # 第2步，将工作区的文件修改撤销掉</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 场景3：乱改了很多文件，想回到最新一次提交时的状态</span></span><br><span class="line">git reset --hard HEAD # 撤销工作区中所有未提交文件的修改内容</span><br><span class="line"></span><br></pre></td></tr></table></figure> 回退操作：当已经进行了commit操作，需要回退到之前的版本： <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git reset --hard HEAD^ # 回退到上次提交的状态</span><br><span class="line">git reset --hard HEAD~n # 回退到n个版本前的状态</span><br><span class="line">git reset --hard HEAD commitid # 回退到某一个commitid的状态</span><br></pre></td></tr></table></figure></p><h1 id="git分支管理">Git分支管理</h1><p>git的最强大之处就在于分支管理了，具体有两种应用场景：</p><ol type="1"><li>多人协作：每个人都基于主分支创建一个自己的分支，在分支上进行开发，然后再不断将写好的代码合并到主分支</li><li>自己修复bug/增加feature：创建一个bug分支或者feature分支，写好代码后合并到自己的分支然后删除bug/feature分支 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">git branch &lt;name&gt; # 创建分支</span><br><span class="line">git checkout &lt;name&gt; # 切换到某个分支</span><br><span class="line">git checkout -b newtest # 创建并切换到新分支，相当于同时执行了以上两个命令</span><br><span class="line">git merge &lt;name&gt; # 合并某个分支到当前分支中，默认fast forward</span><br><span class="line">git branch -a # 查看所有分支</span><br><span class="line">git branch -d &lt;name&gt; # 删除分支</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ol><h1 id="git多人协作">Git多人协作</h1><p>多人协作在同一个分支上进行开发的工作模式：</p><ol type="1"><li>首先，可以试图用<code>git push origin &lt;branch-name&gt;</code>推送自己的修改；</li><li>如果推送失败，则因为远程分支比你的本地更新，需要先用<code>git pull</code>试图合并；</li><li>如果合并有冲突，则解决冲突，并在本地提交；</li><li>没有冲突或者解决掉冲突后，再用<code>git push origin &lt;branch-name&gt;</code>推送就能成功！</li><li>如果<code>git pull</code>提示<code>no tracking information</code>，则说明本地分支和远程分支的链接关系没有创建，用命令<code>git branch --set-upstream-to &lt;branch-name&gt; origin/&lt;branch-name&gt;</code>。<br /></li></ol><h1 id="参考">参考</h1><ol type="1"><li><a href="https://www.runoob.com/git/git-tutorial.html">Git教程 | 菜鸟教程</a></li><li><a href="https://www.liaoxuefeng.com/wiki/896043488029600">Git教程 - 廖雪峰的官方网站</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近工作上会用到Git，这里记录一下一些常用操作供参考！&lt;/p&gt;</summary>
    
    
    
    <category term="计算机" scheme="https://lukan217.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"/>
    
    
    <category term="git" scheme="https://lukan217.github.io/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>科大讯飞|线下商店销量预测挑战赛top7方案</title>
    <link href="https://lukan217.github.io/2021/08/21/%E7%A7%91%E5%A4%A7%E8%AE%AF%E9%A3%9E_%E7%BA%BF%E4%B8%8B%E5%95%86%E5%BA%97%E9%94%80%E9%87%8F%E9%A2%84%E6%B5%8B%E6%8C%91%E6%88%98%E8%B5%9Btop7%E6%96%B9%E6%A1%88/"/>
    <id>https://lukan217.github.io/2021/08/21/%E7%A7%91%E5%A4%A7%E8%AE%AF%E9%A3%9E_%E7%BA%BF%E4%B8%8B%E5%95%86%E5%BA%97%E9%94%80%E9%87%8F%E9%A2%84%E6%B5%8B%E6%8C%91%E6%88%98%E8%B5%9Btop7%E6%96%B9%E6%A1%88/</id>
    <published>2021-08-21T11:10:08.518Z</published>
    <updated>2022-05-14T16:23:20.895Z</updated>
    
    <content type="html"><![CDATA[<p>最近参加了科大讯飞的线下商店销量预测挑战赛，线上成绩0.66，最终排名第七，这里把自己的方案分享出来，欢迎大家交流讨论！代码和数据均已上传到GitHub：<br /><a href="https://github.com/Smallviller/KDXF_sales_forecast_competition">https://github.com/Smallviller/KDXF_sales_forecast_competition</a> <a name="hjSac"></a></p><h1 id="赛题说明">赛题说明</h1><p>比赛传送门：<a href="https://challenge.xfyun.cn/topic/info?type=offline-store-sales-forecast">https://challenge.xfyun.cn/topic/info?type=offline-store-sales-forecast</a> <a name="WNhyD"></a></p><h2 id="赛题任务">赛题任务</h2><p>给定商店销量历史相关数据和时间等信息，预测商店对应商品的周销量。 <a name="j2N5j"></a></p><h2 id="数据说明">数据说明</h2><p>训练集：33周的历史销量数据<br />测试集：34周的销量<br />数据字段：字段shop_id（店铺id）、 item_id（商品id）、week（周标识）、item_price（商品价格）、item_category_id（商品品类id）、weekly_sales（周销量）组成。<br /><img src="https://cdn.nlark.com/yuque/0/2021/png/764062/1629537615118-1f4a390d-5a87-4d37-8629-ffc0700e24ed.png" alt="image.png" /><br />可以发现这里的shop_id、item_id、week和item_category_id进行了脱敏处理，经过简单探索，发现：</p><ol type="1"><li><p>shop_id共有32个，item_id共有523个、item_category_id共有34个，shop和item是多对多的关系，通过shop*item可标识唯一商品。</p></li><li><p>item_price存在大量空值，比率达73%</p></li><li><p>weekly_sales大多偏低，集中在0和1，存在间歇性需求的问题 <a name="mQdqi"></a></p></li></ol><h1 id="特征工程">特征工程</h1><p>一般销量预测，特征工程主要从这几个方面入手：时间相关特征、历史销量相关特征、价格相关特征...不过这里的时间特征被脱敏了，用不到，所以特征工程主要从销量和价格入手。 <a name="mib5L"></a></p><h2 id="销量相关特征">销量相关特征</h2><ol type="1"><li><p>滞后特征：滞后 1-14周的销量</p></li><li><p>滑动特征：滑动2-14周销量的min/max/median/mean/std</p></li><li><p>类别encoding特征：每个item、shop、item_category、shop*item_category、shop*item销量的mean和std</p></li><li><p>类别滞后特征：每个item、shop、item_category滞后1-14周的销量 <a name="m6Ypo"></a></p></li></ol><h2 id="价格相关特征">价格相关特征</h2><ol type="1"><li><p>价格原始值：包含原始特征和填充特征，填充策略采用先向前填补再向后填补，最后没填补到的在用众数填补</p></li><li><p>类别encoding特征：每个item、shop、item_category、shop*item_category、shop*item价格的mean和std</p></li><li><p>价格差异特征：当前价格与shop、item、item_cat、shop_cat、shop_item的价格均值的差值</p></li><li><p>价格变动特征：当前价格与上周价格/上个月平均价格的差值 <a name="Ty2SW"></a></p></li></ol><h1 id="模型">模型</h1><p><a name="Fxz2m"></a></p><h2 id="模型-1">模型</h2><p>只使用了lightgbm <a name="JQtAZ"></a></p><h2 id="损失函数">损失函数</h2><p>训练的损失函数采用tweedie，由于存在间歇性需求的问题，很多商品的销量的销量为0，满足tweedie分布，因此采用tweedie作为损失函数效果要比mse要更好 <a name="Ls2BR"></a></p><h2 id="交叉验证策略">交叉验证策略</h2><p>由于时间序列的数据存在先后，只能用历史来预测未来，因此在交叉验证的时候就得格外小心，不能使用随机划分，因为这样会泄露未来的数据，但是时序也有自己的一套交叉验证方法，我这里使用了三折交叉。<br />使用三折交叉验证，建立三个lgb模型：</p><ol type="1"><li>模型1：训练集使用1-30周数据，验证集使用31周数据，早停100轮</li><li>模型2：训练集使用1-31周数据，验证集使用32周数据，早停100轮</li><li>模型3：训练集使用1-32周数据，验证集使用33周数据，早停100轮</li></ol><p>特征工程、模型的调参等都是基于这个交叉策略来做的，最后将这三个模型取简单平均。<br />为什么不用五折交叉？五折交叉融合的效果不太好，经试验3折融合的成绩是最好的 <a name="wELKW"></a></p><h2 id="后处理">后处理</h2><p>由于树模型无法捕捉到趋势，只能学习到历史的东西，不能外推，预测的时候就容易偏高或者偏低，所以提交的时候其实还试着给结果乘上了一个系数1.025，这也是kaggle上很多时序比赛用的一个trick，结果大概能提升0.005个点吧 <a name="okZbV"></a></p><h1 id="一些本地有效果但线上不能提分的尝试">一些本地有效果但线上不能提分的尝试</h1><ol type="1"><li><p>分shop、item、item_category建模，以及这几种方式得到结果的简单平均融合，按理来说在数据量足够的情况下，对每个类别分别建一个模型应该是比全部数据一起建模效果要好的，不过线上无提升</p></li><li><p>去掉部分重要度特征不高的特征后建模，用到的特征有159个之多，试着使用特征过滤的手段去掉部分无用特征，仍然是本地有提升，线上无提升</p></li><li><p>训练集删掉前15周的数据进行建模，由于构造了很多lag特征，导致了前15周一些特征都是空值的情况，试着把这部分数据删掉，并且越早的数据对于之后的预测越没用，所以按理删掉这些数据应该是能有所提升的，但是还是本地有提升，线上无提升</p></li><li><p>... <a name="Q9Xyh"></a></p></li></ol><h1 id="总结">总结</h1><p>第一次比较投入的去参加这种比赛，感觉还是蛮靠运气和一些trick的，最后怎么弄都上不了分，不知道瓶颈卡在哪了，或许对数据做更多的探索，以及换一些深度的模型能上分吧，再接再励！ <a name="f2Vxd"></a></p><h1 id="代码">代码</h1><p><a name="qjE5G"></a></p><h2 id="数据预处理">数据预处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并训练测试</span></span><br><span class="line">train = pd.read_csv(<span class="string">&#x27;./线下商店销量预测_数据集/train.csv&#x27;</span>)</span><br><span class="line">test = pd.read_csv(<span class="string">&#x27;./线下商店销量预测_数据集/test.csv&#x27;</span>)</span><br><span class="line">df=pd.concat([train,test]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">df=df.sort_values([<span class="string">&#x27;shop_id&#x27;</span>,<span class="string">&#x27;item_id&#x27;</span>,<span class="string">&#x27;week&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用来做滑动和滞后特征的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">makelag</span>(<span class="params">data,values,shift</span>):</span></span><br><span class="line">    lags=[i+shift <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">15</span>)]</span><br><span class="line">    rollings=[i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>,<span class="number">15</span>)]</span><br><span class="line">    <span class="keyword">for</span> lag <span class="keyword">in</span> lags:</span><br><span class="line">        data[<span class="string">f&#x27;lag_<span class="subst">&#123;lag&#125;</span>&#x27;</span>]=values.shift(lag)</span><br><span class="line">    <span class="keyword">for</span> rolling <span class="keyword">in</span> rollings:</span><br><span class="line">        data[<span class="string">f&#x27;s_<span class="subst">&#123;shift&#125;</span>_roll_<span class="subst">&#123;rolling&#125;</span>_min&#x27;</span>]=values.shift(shift).rolling(window=rolling).<span class="built_in">min</span>()</span><br><span class="line">        data[<span class="string">f&#x27;s_<span class="subst">&#123;shift&#125;</span>_roll_<span class="subst">&#123;rolling&#125;</span>_max&#x27;</span>]=values.shift(shift).rolling(window=rolling).<span class="built_in">max</span>()</span><br><span class="line">        data[<span class="string">f&#x27;s_<span class="subst">&#123;shift&#125;</span>_roll_<span class="subst">&#123;rolling&#125;</span>_median&#x27;</span>]=values.shift(shift).rolling(window=rolling).median()</span><br><span class="line">        data[<span class="string">f&#x27;s_<span class="subst">&#123;shift&#125;</span>_roll_<span class="subst">&#123;rolling&#125;</span>_std&#x27;</span>]=values.shift(shift).rolling(window=rolling).std()</span><br><span class="line">        data[<span class="string">f&#x27;s_<span class="subst">&#123;shift&#125;</span>_roll_<span class="subst">&#123;rolling&#125;</span>_mean&#x27;</span>]=values.shift(shift).rolling(window=rolling).mean()</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对每个item都做滞后和滑动特征</span></span><br><span class="line">df=df.groupby([<span class="string">&#x27;shop_id&#x27;</span>,<span class="string">&#x27;item_id&#x27;</span>]).apply(<span class="keyword">lambda</span> x:makelag(x,x[<span class="string">&#x27;weekly_sales&#x27;</span>],<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 价格填充特征，先用前一个值填补，再向后填补，最后没填补到的用那个item的价格众数填补</span></span><br><span class="line">df[<span class="string">&#x27;item_price_fill&#x27;</span>]=df.groupby([<span class="string">&#x27;shop_id&#x27;</span>,<span class="string">&#x27;item_id&#x27;</span>])[<span class="string">&#x27;item_price&#x27;</span>].apply(<span class="keyword">lambda</span> x: x.ffill().bfill())</span><br><span class="line">df[<span class="string">&#x27;item_price_fill&#x27;</span>]=df.groupby([<span class="string">&#x27;item_id&#x27;</span>])[<span class="string">&#x27;item_price_fill&#x27;</span>].apply(<span class="keyword">lambda</span> x: x.fillna(x.mode()[<span class="number">0</span>]))</span><br><span class="line"><span class="comment"># 对于每个shop,item,item_cat,shop*item_cat,shop*item分别做价格和销量的mean/std encoding，</span></span><br><span class="line"><span class="keyword">for</span> func <span class="keyword">in</span> [<span class="string">&#x27;mean&#x27;</span>,<span class="string">&#x27;std&#x27;</span>]:</span><br><span class="line">    df[<span class="string">f&#x27;shop_sale_<span class="subst">&#123;func&#125;</span>&#x27;</span>]=df.groupby([<span class="string">&#x27;shop_id&#x27;</span>])[<span class="string">&#x27;weekly_sales&#x27;</span>].transform(func)</span><br><span class="line">    df[<span class="string">f&#x27;category_sale_<span class="subst">&#123;func&#125;</span>&#x27;</span>]=df.groupby([<span class="string">&#x27;item_category_id&#x27;</span>])[<span class="string">&#x27;weekly_sales&#x27;</span>].transform(func)</span><br><span class="line">    df[<span class="string">f&#x27;item_sale_<span class="subst">&#123;func&#125;</span>&#x27;</span>]=df.groupby([<span class="string">&#x27;item_id&#x27;</span>])[<span class="string">&#x27;weekly_sales&#x27;</span>].transform(func)</span><br><span class="line">    df[<span class="string">f&#x27;shop_cat_sale_<span class="subst">&#123;func&#125;</span>&#x27;</span>]=df.groupby([<span class="string">&#x27;shop_id&#x27;</span>,<span class="string">&#x27;item_category_id&#x27;</span>])[<span class="string">&#x27;weekly_sales&#x27;</span>].transform(func)</span><br><span class="line">    df[<span class="string">f&#x27;shop_item_sale_<span class="subst">&#123;func&#125;</span>&#x27;</span>]=df.groupby([<span class="string">&#x27;shop_id&#x27;</span>,<span class="string">&#x27;item_id&#x27;</span>])[<span class="string">&#x27;weekly_sales&#x27;</span>].transform(func)</span><br><span class="line">    df[<span class="string">f&#x27;shop_price_<span class="subst">&#123;func&#125;</span>&#x27;</span>]=df.groupby([<span class="string">&#x27;shop_id&#x27;</span>])[<span class="string">&#x27;item_price&#x27;</span>].transform(func)</span><br><span class="line">    df[<span class="string">f&#x27;category_price_<span class="subst">&#123;func&#125;</span>&#x27;</span>]=df.groupby([<span class="string">&#x27;item_category_id&#x27;</span>])[<span class="string">&#x27;item_price&#x27;</span>].transform(func)</span><br><span class="line">    df[<span class="string">f&#x27;shop_cat_price_<span class="subst">&#123;func&#125;</span>&#x27;</span>]=df.groupby([<span class="string">&#x27;shop_id&#x27;</span>,<span class="string">&#x27;item_category_id&#x27;</span>])[<span class="string">&#x27;item_price_fill&#x27;</span>].transform(func)</span><br><span class="line">    df[<span class="string">f&#x27;item_price_<span class="subst">&#123;func&#125;</span>&#x27;</span>]=df.groupby([<span class="string">&#x27;item_id&#x27;</span>])[<span class="string">&#x27;item_price&#x27;</span>].transform(func)</span><br><span class="line">    df[<span class="string">f&#x27;shop_item_price_<span class="subst">&#123;func&#125;</span>&#x27;</span>]=df.groupby([<span class="string">&#x27;shop_id&#x27;</span>,<span class="string">&#x27;item_id&#x27;</span>])[<span class="string">&#x27;item_price_fill&#x27;</span>].transform(func)</span><br><span class="line"><span class="comment"># 价格差异特征，当前价格与shop、item、item_cat、shop_cat、shop_item的价格均值的差值</span></span><br><span class="line">df[<span class="string">&#x27;shop_price_diff&#x27;</span>]=df[<span class="string">&#x27;shop_price_mean&#x27;</span>]-df[<span class="string">&#x27;item_price_fill&#x27;</span>]</span><br><span class="line">df[<span class="string">&#x27;item_price_diff&#x27;</span>]=df[<span class="string">&#x27;item_price_mean&#x27;</span>]-df[<span class="string">&#x27;item_price_fill&#x27;</span>]</span><br><span class="line">df[<span class="string">&#x27;cat_price_diff&#x27;</span>]=df[<span class="string">&#x27;category_price_mean&#x27;</span>]-df[<span class="string">&#x27;item_price_fill&#x27;</span>]</span><br><span class="line">df[<span class="string">&#x27;shop_cat_price_diff&#x27;</span>]=df[<span class="string">&#x27;shop_cat_price_mean&#x27;</span>]-df[<span class="string">&#x27;item_price_fill&#x27;</span>]</span><br><span class="line">df[<span class="string">&#x27;shop_item_price_diff&#x27;</span>]=df[<span class="string">&#x27;shop_item_price_mean&#x27;</span>]-df[<span class="string">&#x27;item_price_fill&#x27;</span>]</span><br><span class="line"><span class="comment"># 当前价格与上周价格的差值，当前价格与上个月价格均值的差值</span></span><br><span class="line">df[<span class="string">&#x27;week_price_diff&#x27;</span>]=df.groupby([<span class="string">&#x27;shop_id&#x27;</span>,<span class="string">&#x27;item_id&#x27;</span>])[<span class="string">&#x27;item_price_fill&#x27;</span>].apply(<span class="keyword">lambda</span> x: x-x.shift(<span class="number">1</span>))</span><br><span class="line">df[<span class="string">&#x27;month_price_diff&#x27;</span>]=df.groupby([<span class="string">&#x27;shop_id&#x27;</span>,<span class="string">&#x27;item_id&#x27;</span>])[<span class="string">&#x27;item_price_fill&#x27;</span>].apply(<span class="keyword">lambda</span> x: x-x.shift(<span class="number">1</span>).rolling(<span class="number">4</span>).mean())</span><br><span class="line"><span class="comment"># 销量的滞后特征，对于每个item、item_cat、shop的聚合平均值</span></span><br><span class="line"><span class="keyword">for</span> lag <span class="keyword">in</span> [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">16</span>)]:</span><br><span class="line">    df[<span class="string">f&#x27;item_lag_<span class="subst">&#123;lag&#125;</span>&#x27;</span>]=df.groupby([<span class="string">&#x27;item_id&#x27;</span>,<span class="string">&#x27;week&#x27;</span>])[<span class="string">f&#x27;lag_<span class="subst">&#123;lag&#125;</span>&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">    df[<span class="string">f&#x27;cat_lag_<span class="subst">&#123;lag&#125;</span>&#x27;</span>]=df.groupby([<span class="string">&#x27;item_category_id&#x27;</span>,<span class="string">&#x27;week&#x27;</span>])[<span class="string">f&#x27;lag_<span class="subst">&#123;lag&#125;</span>&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">    df[<span class="string">f&#x27;shop_lag_<span class="subst">&#123;lag&#125;</span>&#x27;</span>]=df.groupby([<span class="string">&#x27;shop_id&#x27;</span>,<span class="string">&#x27;week&#x27;</span>])[<span class="string">f&#x27;lag_<span class="subst">&#123;lag&#125;</span>&#x27;</span>].transform(<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line"></span><br><span class="line">df.to_pickle(<span class="string">&#x27;data.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure><p><a name="UicNz"></a></p><h2 id="模型-2">模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">df=pd.read_pickle(<span class="string">&#x27;data.pkl&#x27;</span>)</span><br><span class="line"><span class="comment"># 三折交叉</span></span><br><span class="line">cvs=[<span class="number">32</span>,<span class="number">31</span>,<span class="number">30</span>]</span><br><span class="line">params = &#123;</span><br><span class="line">        <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;tweedie&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;tweedie_variance_power&#x27;</span>:<span class="number">1.6</span>,</span><br><span class="line">        <span class="string">&#x27;metric&#x27;</span>: <span class="string">&#x27;mse&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;num_leaves&#x27;</span>: <span class="number">2</span>**<span class="number">7</span>-<span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;reg_lambda&#x27;</span>: <span class="number">50</span>,</span><br><span class="line">        <span class="string">&#x27;colsample_bytree&#x27;</span>: <span class="number">0.6</span>,</span><br><span class="line">        <span class="string">&#x27;subsample&#x27;</span>: <span class="number">0.6</span>,</span><br><span class="line">        <span class="string">&#x27;subsample_freq&#x27;</span>: <span class="number">4</span>,</span><br><span class="line">        <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.015</span>,</span><br><span class="line">        <span class="string">&#x27;n_estimators&#x27;</span>:<span class="number">2000</span>,</span><br><span class="line">        <span class="string">&#x27;seed&#x27;</span>: <span class="number">1024</span>,</span><br><span class="line">        <span class="string">&#x27;n_jobs&#x27;</span>:-<span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;silent&#x27;</span>: <span class="literal">True</span>,</span><br><span class="line">        <span class="string">&#x27;verbose&#x27;</span>: -<span class="number">1</span>,</span><br><span class="line">    &#125;</span><br><span class="line">y_preds=[]</span><br><span class="line">scores=[]</span><br><span class="line"><span class="keyword">for</span> cv <span class="keyword">in</span> cvs:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>*<span class="number">10</span>+<span class="built_in">str</span>(cv)+<span class="string">&#x27;=&#x27;</span>*<span class="number">10</span>)</span><br><span class="line">    train=df[df[<span class="string">&#x27;week&#x27;</span>]&lt;cv]</span><br><span class="line">    val=df[df[<span class="string">&#x27;week&#x27;</span>]==cv]</span><br><span class="line">    test=df[df[<span class="string">&#x27;week&#x27;</span>]==<span class="number">33</span>]</span><br><span class="line">    X_train=train.drop(columns=[<span class="string">&#x27;weekly_sales&#x27;</span>])</span><br><span class="line">    y_train=train[<span class="string">&#x27;weekly_sales&#x27;</span>]</span><br><span class="line">    X_test=test.drop(columns=[<span class="string">&#x27;weekly_sales&#x27;</span>]</span><br><span class="line">    y_test=test[<span class="string">&#x27;weekly_sales&#x27;</span>]</span><br><span class="line">    X_val=val.drop(columns=[<span class="string">&#x27;weekly_sales&#x27;</span>])</span><br><span class="line">    y_val=val[<span class="string">&#x27;weekly_sales&#x27;</span>]</span><br><span class="line">    model=lgb.LGBMRegressor(**params)</span><br><span class="line">    model.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_val,y_val)],eval_metric=[<span class="string">&#x27;mse&#x27;</span>],verbose=<span class="literal">False</span>,categorical_feature=[<span class="string">&#x27;shop_id&#x27;</span>,<span class="string">&#x27;item_id&#x27;</span>,<span class="string">&#x27;item_category_id&#x27;</span>],early_stopping_rounds=<span class="number">100</span>)</span><br><span class="line">    val_pred=model.predict(X_val)*<span class="number">0.995</span></span><br><span class="line">    mse=mean_squared_error(y_val,val_pred)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;MSE: <span class="subst">&#123;mse&#125;</span>&#x27;</span>)</span><br><span class="line">    scores.append(mse)</span><br><span class="line">    y_pred=model.predict(X_test)</span><br><span class="line">    y_preds.append(y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;三折交叉的score<span class="subst">&#123;scores&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;三折交叉平均score<span class="subst">&#123;np.mean(scores)&#125;</span>&#x27;</span>)</span><br><span class="line">y_pred=np.zeros_like(y_pred)</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> y_preds:</span><br><span class="line">    y_pred+=t*<span class="number">1</span>/<span class="number">3</span></span><br><span class="line">sample_submit = pd.read_csv(<span class="string">&#x27;./线下商店销量预测_数据集/sample_submit.csv&#x27;</span>)</span><br><span class="line">sample_submit[<span class="string">&#x27;weekly_sales&#x27;</span>] = y_pred</span><br><span class="line">sample_submit[<span class="string">&#x27;weekly_sales&#x27;</span>] = sample_submit[<span class="string">&#x27;weekly_sales&#x27;</span>].apply(<span class="keyword">lambda</span> x:x <span class="keyword">if</span> x&gt;<span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>).values</span><br><span class="line">sample_submit.to_csv(<span class="string">&#x27;submit.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近参加了科大讯飞的线下商店销量预测挑战赛，线上成绩0.66，最终排名第七，这里把自己的方案分享出来，欢迎大家交流讨论！代码和数据均已上传到GitHub：&lt;br&gt;&lt;a href=&quot;https://github.com/Smallviller/KDXF_sales_forecast_competition&quot;&gt;https://github.com/Smallviller/KDXF_sales_forecast_competition&lt;/a&gt; &lt;a name=&quot;hjSac&quot;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="比赛" scheme="https://lukan217.github.io/categories/%E6%AF%94%E8%B5%9B/"/>
    
    
    <category term="时间序列" scheme="https://lukan217.github.io/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
    <category term="销量预测" scheme="https://lukan217.github.io/tags/%E9%94%80%E9%87%8F%E9%A2%84%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>逻辑回归的交叉熵损失函数原理</title>
    <link href="https://lukan217.github.io/2021/08/07/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%8E%9F%E7%90%86/"/>
    <id>https://lukan217.github.io/2021/08/07/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%8E%9F%E7%90%86/</id>
    <published>2021-08-06T17:54:19.354Z</published>
    <updated>2022-05-14T16:23:26.955Z</updated>
    
    <content type="html"><![CDATA[<p>前阵子两次面试，都被问到了逻辑回归的损失函数是什么，我知道是交叉熵，也很顺利的脱口说出了他的函数表达式，但是接下来被问到了为什么要用这个损失函数，我之前见过那张图，就是这个交叉熵函数的曲面是比平方损失函数（MSE）的曲面要陡峭，更方便梯度下降算法的迭代求解，但是再被往下深挖，问还有别的原因吗，这背后的存在的数学逻辑是什么？接着又被问了一堆的极大似然估计啥啥啥数理统计的东西，就有点说不出来了，所以查了一些资料，顺便写篇文章总结一下加深下理解。 <a name="lnsnU"></a></p><h1 id="交叉熵损失函数">交叉熵损失函数</h1><p>先来熟悉下他的定义和函数形式，交叉熵（Cross Entropy）损失函数，也被称为对数损失函数，logloss，表现形式如下：</p><p><span class="math display">\[L=-[y\log(\hat y)+(1-y)log(1-\hat y)]\\\]</span></p><p>这里的<span class="math inline">\(y\)</span>代表真实值，0或1，$y $代表预测值/估计值，值为一个概率，取值范围0~1，一般大于0.5我们就判定这个样本为1，小于0.5就把这个样本归为0。</p><p>从函数的形式上，我们可以看出，无论真实的<span class="math inline">\(y\)</span>取0或1，这个加号两边的取值必有一个为0，假设<span class="math inline">\(y=1\)</span>，那么此时<span class="math inline">\(L=-\log(\hat y)\)</span>，此时损失函数代表预测为1的概率取负，如果<span class="math inline">\(y=0\)</span>，那么<span class="math inline">\(L=-log(1-\hat y)\)</span>，此时损失函数代表预测为0的概率取负，那么问题就简单了，直观上来理解这个损失函数，就是，要使得每一个样本属于其真实值的概率最大化。</p><p>虽然直观上理解这个损失函数代表的意义没有问题，但是其是怎么推导出来的呢？这样的形式会有什么样的优点呢？这里就有两种方式来理解这个损失函数了，一个是从数理统计的极大似然估计出发，另一个是从KL散度的角度出发。</p><p><a name="9rx1K"></a></p><h1 id="从极大似然估计角度理解">从极大似然估计角度理解</h1><h2 id="极大似然估计">极大似然估计</h2><p>首先需要复习一下极大似然估计是什么玩意？这个东西虽然在本科的概率论和数理统计课程中就学过了，但是还是有那么一点一知半解。</p><p>要理解极大似然估计，就得先知道这个似然函数<span class="math inline">\(p(x|\theta)\)</span>的概念，这个比较容易和概率函数搞混，因为表达式都是：<span class="math inline">\(p(x|\theta)\)</span>，但实际上似然函数（likelihood function ）与概率函数（probability function）是完全不一样的两个东西。</p><p>如果<span class="math inline">\(p(x|\theta)\)</span>中<span class="math inline">\(\theta\)</span>是已知确定的，<span class="math inline">\(x\)</span>是变量的话，那么这个函数就叫做概率函数，他描述在给定的模型参数<span class="math inline">\(\theta\)</span>下，对于不同的样本点<span class="math inline">\(x\)</span>，其出现的概率是多少，比如对于身高的正态函数，给定参数均值170和标准差10，那么就可以计算出现身高为180的人的概率有多少。</p><p>反过来，如果<span class="math inline">\(p(x|\theta)\)</span>中<span class="math inline">\(x\)</span>是已知确定的，<span class="math inline">\(\theta\)</span>是变量的话，那么这个函数就叫做似然函数，他描述对于不同的模型参数<span class="math inline">\(\theta\)</span>，出现$x $这个样本的概率是多少，还是身高的那个例子，如果给定一个样本身高为180，那么就可以计算不同的均值和标准差参数组合下出现这个样本的概率。</p><p>那么，极大似然估计是什么意思呢？就是<strong>利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值，</strong>举个例子，我给了一堆人的身高，这些样本都是独立同分布的，然后知道身高是符合正态分布的，我想要推出人群中身高的均值和标准差是多少，那么就可以通过遍历每一个参数值，然后根据似然函数算出每一个人身高对应的概率是多少，因为是这些人是独立同分布的，所以就可以通过把这些概率乘起来的方式，来计算出一个出现这些样本的概率，然后选取最大概率对应的那个均值和标准差，这个均值和标准差就是想要的结果了。 <a name="rH0z9"></a></p><h2 id="逻辑回归参数的极大似然估计">逻辑回归参数的极大似然估计</h2><p>了解了极大似然估计，接下来就可以说一下啊逻辑回归的参数是怎么通过极大似然估计来进行估计的了。首先，根据逻辑回归的计算公式，我们可以知道对应为1和0的样本的概率：</p><p><span class="math display">\[\begin{align*}P(Y=1|x)&amp;=\frac{e^{wx+b}}{1+e^{wx+b}}=p(x)\\P(Y=0|x)&amp;=\frac{1}{1+e^{wx+b}}=1-p(x)\end{align*}\]</span></p><p>然后就可以计算出现这些样本的似然函数，就是把每一个样本的概率乘起来：</p><p><span class="math display">\[L(w;b)=\prod_{i=1}^{n}[p(x_i)^{y_i}(1-p(x_i))^{1-y_i}\]</span></p><p>但是这个形式是连乘的，并不好求，所以一般我们会把他取对数，转化为累加的形式，就得到对数似然函数：</p><p><span class="math display">\[L&#39;(w;b)=\sum_{i=1}^{n}[y_i\log(p(x_i))+(1-y_i)log(1-p(x_i))]\\\]</span></p><p>这时候呢，我们就可以通过最大化这个对数似然函数的方式来求得逻辑回归模型中的<span class="math inline">\(w\)</span>和<span class="math inline">\(b\)</span>，把上面的式子加个负号，就是通过最小化这个负对数似然函数来求得<span class="math inline">\(w\)</span>和<span class="math inline">\(b\)</span>，就可以通过梯度下降法来进行求解了。</p><p>可以发现，通过数理统计中的极大似然估计方法，也可以得到逻辑回归的损失函数。 <a name="8zkfK"></a></p><h1 id="从kl散度的角度理解">从KL散度的角度理解</h1><p>交叉熵是信息论里面的概念，要理解这里的交叉熵是怎么推出来的，就得先理解以下一个叫做KL散度（相对熵）的东西。</p><p>如果对于同一个随机变量<span class="math inline">\(X\)</span>有两个单独的概率分布<span class="math inline">\(p(X)\)</span>和<span class="math inline">\(q(X)\)</span>，那么我们就可以<strong>用KL散度来衡量这两个分布的差异</strong>：</p><p><span class="math display">\[D_{KL}(p||q)=\sum_{i=1}^{n}p(x_i)\log(\frac{p(x_i)}{q(x_i)})\\\]</span></p><p>我们将<span class="math inline">\(p(x)\)</span>定义为真实的概率分布，<span class="math inline">\(q(x)\)</span>定义为模型预测的概率分布，我们希望预测的概率分布与真实的概率分布差异越小越好，也就是使得KL散度越小越好，而<span class="math inline">\(p(x)\)</span>是在数据集确定之后就确定下来的了，所以我们只要使得<span class="math inline">\(q(x)\)</span>尽可能地接近<span class="math inline">\(p(x)\)</span>就可以了。</p><p>将这个KL散度的公式展开可以得到：</p><p><span class="math display">\[\begin{align*}D_{KL}(p||q)&amp;=\sum_{i=1}^{n}p(x_i)\log(\frac{p(x_i)}{q(x_i)})\\&amp;=\sum_{i=1}^{n}p(x_i)\log(p(x_i))-\sum_{i=1}^{n}p(x_i)\log(q(x_i))\\&amp;=-H(p(x))-\sum_{i=1}^{n}p(x_i)\log(q(x_i))\end{align*}\]</span></p><p>学过信息论的可能会知道，<span class="math inline">\(-\log(p(x))\)</span>代表的就是<strong>信息量</strong>，某一随机事件发生的概率越小，反映的信息量就越大，比如新冠疫情的发生，概率很小，但是蕴含的信息量就很大，而这个<span class="math inline">\(-\sum_{i=1}^{n}p(x)\log(p(x))\)</span>代表的就是信息量的期望，也就是<strong>信息熵</strong>，然后如果把这个<span class="math inline">\(log\)</span>里面的<span class="math inline">\(p(x)\)</span>换成另一个分布的概率<span class="math inline">\(q(x)\)</span>，也就是<span class="math inline">\(-\sum_{i=1}^{n}p(x)\log(q(x))\)</span>，这个就是<strong>交叉熵。</strong></p><p>所以根据上面那个展开的公式，就可以发现<strong>KL散度=交叉熵-真实分布的信息熵</strong>，而这个真实分布的信息熵是根据<span class="math inline">\(p(x)\)</span>计算得到的，而这个<span class="math inline">\(p(x)\)</span>是在数据集确定之后就确定下来的了，这一项就可以当成一个常数项，所以我们如果想让KL散度越小，只需要让交叉熵越小越好了，因此就可以直接将逻辑回归的损失函数直接定义为交叉熵。 <a name="pihcD"></a></p><h1 id="使用交叉熵作为损失函数的好处">使用交叉熵作为损失函数的好处</h1><p>从上面的两个角度，我们就可以理解为什么逻辑回归要用交叉熵来作为损失函数了，但是，使用交叉熵背后的数学逻辑是明白了，那么，反映到实际里面，交叉熵到底有着什么样的优越性呢？</p><p>这里使用之前自己上数据挖掘课程ppt里的一张图来说明这个问题，可以看到，交叉熵函数的曲面是非常陡峭的，在模型效果差的时候学习速度比较快，是非常有利于梯度下降的迭代的，所以逻辑回归里面使用交叉熵作为损失函数而不是使用均方误差作为损失函数，这个也可以通过求导的方式来证明，不过限于个人水平，这里就不展开了，具体可以间文末列出的的第三篇参考资料。<img src="https://cdn.nlark.com/yuque/0/2021/png/764062/1625298163597-63b86d09-180b-4c0d-a6e3-ab1cab0f20d9.png" alt="image.png" /> <a name="I1fZO"></a></p><h1 id="总结">总结</h1><p>本文主要从两个角度——数理统计的极大似然估计以及信息论中的KL散度，来说明逻辑回归中交叉熵函数背后的数学逻辑，同时也简单说明了交叉熵函数在逻辑回归中相对于均方误差函数的优势。 <a name="7WUkf"></a></p><h1 id="参考">参考</h1><p><a href="https://mp.weixin.qq.com/s/LPfrzLCVBj3SUQAf9fnlmA">为什么逻辑回归的损失函数是交叉熵？</a></p><p><a href="https://zhuanlan.zhihu.com/p/26614750">一文搞懂极大似然估计</a></p><p><a href="https://zhuanlan.zhihu.com/p/35709485">损失函数|交叉熵损失函数</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;前阵子两次面试，都被问到了逻辑回归的损失函数是什么，我知道是交叉熵，也很顺利的脱口说出了他的函数表达式，但是接下来被问到了为什么要用这个损失函数，我之前见过那张图，就是这个交叉熵函数的曲面是比平方损失函数（MSE）的曲面要陡峭，更方便梯度下降算法的迭代求解，但是再被往下深挖，问还有别的原因吗，这背后的存在的数学逻辑是什么？接着又被问了一堆的极大似然估计啥啥啥数理统计的东西，就有点说不出来了，所以查了一些资料，顺便写篇文章总结一下加深下理解。 &lt;a name=&quot;lnsnU&quot;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://lukan217.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="逻辑回归" scheme="https://lukan217.github.io/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    
    <category term="损失函数" scheme="https://lukan217.github.io/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>时间序列的多步预测方法总结</title>
    <link href="https://lukan217.github.io/2021/08/07/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E7%9A%84%E5%A4%9A%E6%AD%A5%E9%A2%84%E6%B5%8B%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    <id>https://lukan217.github.io/2021/08/07/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E7%9A%84%E5%A4%9A%E6%AD%A5%E9%A2%84%E6%B5%8B%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/</id>
    <published>2021-08-06T17:54:19.202Z</published>
    <updated>2022-05-14T16:24:12.613Z</updated>
    
    <content type="html"><![CDATA[<p>在时间序列预测中，预测的horizon往往是一段时间，比如下一周的股票价格、销量、天气等等，但是，在将时间序列数据转化为有监督学习时，往往会构造很多特征，其中一个很重要的就是滞后值特征和滑动窗口统计特征，一旦加入这些特征，就会导致有监督学习的多步预测出现问题，比如，我需要构造了一个滞后一天的特征lag1，需要预测接下来两天的值，那么，第一天的是很好预测的，因为我有昨天的值，但是第二天的预测就有问题了，因为昨天的观测值是不知道的啊，在上一篇文章中，我提到了一个递归预测法，但这两天看了一下，其实解决这个问题的方法还不少，所以写篇文章总结下吧。 <a name="kfo8C"></a></p><h1 id="直接预测法">直接预测法</h1><p>直接预测法（Direct Multi-step Forecast Strategy），这种方法的思路呢就是，如果不能使用lag特征，那我干脆就不用了。这种方法的可操作空间还是挺大的，可以分为只使用1个模型，使用n个模型（n为需要预测的天数），使用1-n个模型。接下来详细说明下每一种方法。 <a name="bDO6i"></a></p><h2 id="只使用一个模型">只使用一个模型</h2><p>举个例子，现有7月10号-7月15号的数据，需要预测未来3天的销量，那么，我就不能用lag1和lag2作为特征，但是可以用lag3呀，所以就用lag3作为特征构建一个模型：<br /><img src="https://cdn.nlark.com/yuque/0/2021/png/764062/1626280659659-db52b363-6f31-44e1-96a7-5d33e8b327f5.png#align=left&amp;display=inline&amp;height=224" alt="image.png" /><br />这种是只使用一个模型来预测的，但是呢，缺点是特征居然要构造到lag3，lag1和lag2的信息完全没用到，所以就有人提出了一种思路，就是对于每一天都构建一个模型。 <a name="bxmLJ"></a></p><h2 id="使用n个模型">使用n个模型</h2><p>这个的思路呢，就是想能够尽可能多的用到lag的信息，所以，对于每一天都构建一个模型，比如对于15号，构建模型1，使用了lag1，lag2和lag3作为特征来训练，然后对于16号，因为不能用到lag1的信息了，但是lag2和lag3还是能用到的，所以就用lag2和lag3作为特征，再训练一个模型2，17号的话，就只有lag3能用了，所以就直接用lag3作为特征来训练一个模型3，然后模型123分别就可以输出每一天的预测值了。<br /><strong><img src="https://cdn.nlark.com/yuque/0/2021/png/764062/1626281132143-f39be164-ed9e-4fe7-815e-97fa8cd78b73.png#align=left&amp;display=inline&amp;height=227" alt="image.png" /></strong><br />这种方法的优势是最大可能的用到了lag的信息，但是缺陷也非常明显，就是因为对于每一天都需要构建一个模型的话，那预测的天数一长，数据一多，那计算量是没法想象的，所以也有人提出了一个这种的方案，就不是对每一天构建一个模型了，而是每几天构建一个模型。 <a name="yyygU"></a></p><h2 id="使用1-n个模型">使用1-n个模型</h2><p>还是上面那个例子，这次把数据改变一下，预测四天吧，有10号-15号的数据，构建了lag1-5的特征，需要预测16号-19号的数据，那么我们知道16号和17号是都可以用到lag2和lag3的特征的，那么为这两天构建一个模型1，而18号和19号是可以用到lag4和lag5的特征的，那么为这两天构建一个模型2，所以最后就是模型1输出16号和17号的预测值，模型2输出18号和19号的值。<br /><img src="https://cdn.nlark.com/yuque/0/2021/png/764062/1626282065731-86deeff3-8259-4320-998c-5fc639e8b0a4.png" alt="image.png" /><br />可以发现，这样的话，我们虽然没有尽最大可能的去使用lag特征，但是，计算量相比于使用n个模型直接小了一半。这是<a href="https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/163216">kaggle M5比赛第四名</a>的思路。 <a name="M1d8v"></a></p><h1 id="递归预测法">递归预测法</h1><p>然后是递归预测法（Recursive Multi-step Forecast），不知道预测值对应的滞后值怎么办？就用之前的预测值当真实值呗！举个例子，有10号-15号的数据，构建了lag1特征，需要预测未来3天的销量，那么15号的lag1特征可以直接用14号的值，假设预测出来结果是150，那么，在16号，lag1的真实值也就是15号的值虽然不知道，但是可以直接用15号的预测值填充呀，依次类推，17号的lag1也可以直接用16号的预测值填充，这就是递归预测法。<br /><img src="https://cdn.nlark.com/yuque/0/2021/png/764062/1626279980227-c5384d4d-b533-45e2-89d6-37a16c66b09d.png" alt="image.png" /><br />但是，这种方法有一个缺陷就是会造成误差累计，还是上面那个例子，假设我15号那天预测错了，那么16号那天的输入就也是错的，那用来预测就更错了啊，所以，使用这种方法的话，一旦预测出错就会越错越离谱，这种方法会有着较高的偏差。 <a name="p5e7m"></a></p><h1 id="直接-递归混合预测法">直接-递归混合预测法</h1><p>直接预测法使用到的lag信息少，并且需要建的模型多，方差较大，递归预测法只使用了一个模型，并且lag的信息也全用上了，但是容易造成误差累计，偏差较大。所以，有人把上面两种方法直接结合了起来，试图平衡方差和偏差，这里就叫直接-递归混合预测法吧，混合的方式还挺多的，我看到的就三种了。 <a name="4dR72"></a></p><h2 id="混合一">混合一</h2><p>同时使用直接法和递归法，分别得出一个预测值，然后做个简单平均，这个思路也就是采用了模型融合的平均法的思想，一个高方差，一个高偏差，那么我把两个合起来取个平均方差和偏差不就小了吗，这个方法是<a href="https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/163684">kaggle M5比赛top1</a>用的解决方案。 <a name="HVhMA"></a></p><h2 id="混合二">混合二</h2><p>这种方法是这篇论文提出的：《Recursive and direct multi-step forecasting: the best of both worlds》，有兴趣可以自己去读下，大概说的就是先使用递归法进行预测，然后再用直接法去训练递归法的残差，有点像boosting的思想，论文花了挺大篇幅说了这种方法的无偏性，不过，这种方法也就是存在论文中，暂时没见到人使用，具体效果还不知道。<br /> <a name="XT4Vm"></a></p><h2 id="混合三">混合三</h2><p>简单来说就是使用到了所有的lag信息，同时也建立了很多模型，还是这个例子，首先用10号-14号的数据训练模型1，得到15号的预测值，然后将15号的预测值作为16号的特征，同时用10号-15号的数据训练模型2，得到16号的预测值，最后使用16号的预测值作为17号的特征，使用10号-16号的数据训练模型3，得到17号的预测值。<br /><img src="https://cdn.nlark.com/yuque/0/2021/png/764062/1626279980227-c5384d4d-b533-45e2-89d6-37a16c66b09d.png#align=left&amp;display=inline&amp;height=228、" alt="image.png" /><br />这种方法说实话我不能很get到他的好处在哪，相比于递归预测法，不就是训练时多了几条数据吗？还是会有误差累计的问题吧，或许是我没有理解明白吧，<a href="https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47582">kaggle favorita-grocery第一名</a>的方案好像也使用的这个 <a name="mlt1S"></a></p><h1 id="多输出法">多输出法</h1><p>在传统的机器学习中，是无法实现多输出的，只能输出一个值，但是在深度学习的模型中，就可以通过调节输出神经元的个数，从而实现多输出的功能，还有一些是使用seq2seq结构的，深度这块的时间序列预测目前了解的比较少，这里不再展开了。 <a name="h7wpx"></a></p><h1 id="总结">总结</h1><p>目前针对时间序列预测的多步输出问题大概就这几种方法，其中针对机器学习的直接法、递归法还有直接-递归混合法，这几种方法在kaggle上都有应用，也没有说哪种方法就一定好，这个需要就具体问题具体分析，多尝试一下才能知道在某种问题上哪种方法表现更好。 <a name="mSH2v"></a></p><h1 id="参考">参考</h1><ol type="1"><li><a href="https://machinelearningmastery.com/multi-step-time-series-forecasting/">4 Strategies for Multi-Step Time Series Forecasting</a></li><li><a href="https://zhuanlan.zhihu.com/p/308764952">时间序列多步预测的五种策略</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;在时间序列预测中，预测的horizon往往是一段时间，比如下一周的股票价格、销量、天气等等，但是，在将时间序列数据转化为有监督学习时，往往会构造很多特征，其中一个很重要的就是滞后值特征和滑动窗口统计特征，一旦加入这些特征，就会导致有监督学习的多步预测出现问题，比如，我需要构造了一个滞后一天的特征lag1，需要预测接下来两天的值，那么，第一天的是很好预测的，因为我有昨天的值，但是第二天的预测就有问题了，因为昨天的观测值是不知道的啊，在上一篇文章中，我提到了一个递归预测法，但这两天看了一下，其实解决这个问题的方法还不少，所以写篇文章总结下吧。 &lt;a name=&quot;kfo8C&quot;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://lukan217.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="https://lukan217.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="时间序列" scheme="https://lukan217.github.io/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
  </entry>
  
</feed>
